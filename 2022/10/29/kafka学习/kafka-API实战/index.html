<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.13.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="这是文章开头，显示在主页面，详情请点击此处。">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka_API实战">
<meta property="og:url" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/index.html">
<meta property="og:site_name" content="Tiger_pop&#39;s Blog">
<meta property="og:description" content="这是文章开头，显示在主页面，详情请点击此处。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-27%2020.01.33-7029089.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-02%2012.03.58.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-02%2012.04.13.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-02%2020.48.36.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-02%2020.58.11.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-02%2022.31.40.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2021.51.21.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2022.00.13.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2021.52.30.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2022.08.15.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2010.11.53.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2010.12.29.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2016.21.52.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2016.23.12.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2016.47.30.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2017.43.08.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2017.57.47.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.02.38.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.10.58.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.50.16.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.51.00.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.52.31.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.52.58.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.56.36.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2018.29.16.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2018.31.31.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-01%2013.08.56.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-01%2013.09.16.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-01%2013.15.50.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2017.25.37.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2017.20.29.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2017.52.04.jpg">
<meta property="og:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2018.10.35.jpg">
<meta property="article:published_time" content="2022-10-29T07:41:53.000Z">
<meta property="article:modified_time" content="2022-10-29T07:52:35.475Z">
<meta property="article:author" content="陈宇韶chenyushao">
<meta property="article:tag" content="kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-27%2020.01.33-7029089.jpg">


<link rel="canonical" href="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/","path":"2022/10/29/kafka学习/kafka-API实战/","title":"kafka_API实战"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>kafka_API实战 | Tiger_pop's Blog</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Tiger_pop's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Tiger_pop's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">tiger_pop 的博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#python%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.</span> <span class="nav-text">python实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-number">1.1.</span> <span class="nav-text">生产者与消费者</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-number">1.1.1.</span> <span class="nav-text">生产者</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%A6%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-number">1.1.2.</span> <span class="nav-text">带回调函数的生产者</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-number">1.1.3.</span> <span class="nav-text">消费者</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%87%E7%BA%A7%E7%89%88%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-number">1.1.4.</span> <span class="nav-text">升级版消费者</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97kafka%E5%A0%86%E7%A7%AF%E5%89%A9%E4%BD%99%E9%87%8F"><span class="nav-number">1.1.5.</span> <span class="nav-text">计算kafka堆积剩余量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8B%A6%E6%88%AA%E5%99%A8"><span class="nav-number">1.1.6.</span> <span class="nav-text">拦截器</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%BBkafka-python%E6%BA%90%E7%A0%81%EF%BC%88kafkaproducer%EF%BC%89"><span class="nav-number">2.</span> <span class="nav-text">读kafka-python源码（kafkaproducer）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%BB%E6%BA%90%E7%A0%81%E5%89%8D%E5%A5%8F%EF%BC%9A%E6%9B%B4%E6%94%B9%E9%BB%98%E8%AE%A4%E5%8F%91%E9%80%81%E5%8E%BB%E5%93%AA%E4%B8%AA%E5%88%86%E5%8C%BA%E7%9A%84%E7%AE%97%E6%B3%95"><span class="nav-number">2.1.</span> <span class="nav-text">读源码前奏：更改默认发送去哪个分区的算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AD%A3%E5%BC%8F%E8%AF%BB%E6%BA%90%E7%A0%81"><span class="nav-number">2.2.</span> <span class="nav-text">正式读源码</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%BBjava%E6%BA%90%E7%A0%81%E6%97%B6%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E7%82%B9"><span class="nav-number">3.</span> <span class="nav-text">读java源码时要注意的点</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#java%E5%8A%A8%E6%80%81%E7%BB%91%E5%AE%9A%E6%9C%BA%E5%88%B6%EF%BC%88%E9%87%8D%E5%86%99%E6%96%B9%E6%B3%95%E6%97%B6%E5%B8%B8%E7%94%A8%EF%BC%89"><span class="nav-number">3.1.</span> <span class="nav-text">java动态绑定机制（重写方法时常用）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#java%E6%96%B9%E6%B3%95%E9%87%8D%E8%BD%BD"><span class="nav-number">3.2.</span> <span class="nav-text">java方法重载</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="陈宇韶chenyushao"
      src="/images/my.jpg">
  <p class="site-author-name" itemprop="name">陈宇韶chenyushao</p>
  <div class="site-description" itemprop="description">爱学习、爱工作、爱生活;         微信号: Tiger_and_master;         手机号码:18515678348 </div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">429</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">205</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my.jpg">
      <meta itemprop="name" content="陈宇韶chenyushao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tiger_pop's Blog">
      <meta itemprop="description" content="爱学习、爱工作、爱生活;         微信号: Tiger_and_master;         手机号码:18515678348 ">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="kafka_API实战 | Tiger_pop's Blog">
      <meta itemprop="description" content="这是文章开头，显示在主页面，详情请点击此处。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          kafka_API实战
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-10-29 15:41:53 / 修改时间：15:52:35" itemprop="dateCreated datePublished" datetime="2022-10-29T15:41:53+08:00">2022-10-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/kafka/" itemprop="url" rel="index"><span itemprop="name">kafka</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">这是文章开头，显示在主页面，详情请点击此处。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>简介 <span id="more"></span></p>
<h1 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a>python实现</h1><p>​		网上有很多kafka的java 操作的教程、文档，但是我这里想要把学习笔记统一成python的，简单易读人生苦短嘛。</p>
<p>​		用python操作kafka 有两个选择，一个是pykafka，另一个是kafka- python，pykafka 很久没有更新了，所以咱们用 kafka- python。</p>
<p>​		以下是 kafka- python的文档，看起来满屏的英文其实还是挺好读的。</p>
<p><a target="_blank" rel="noopener" href="https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html">https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html</a></p>
<p>​		知乎中的前人的总结，可以和kafka- python的文档 配合着看。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/279784873?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=1082949711211810816&amp;utm_campaign=shareopn">https://zhuanlan.zhihu.com/p/279784873?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=1082949711211810816&amp;utm_campaign=shareopn</a></p>
<p>​		</p>
<h2 id="生产者与消费者"><a href="#生产者与消费者" class="headerlink" title="生产者与消费者"></a>生产者与消费者</h2><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install kafka-python</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf8</span></span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaProducer</span><br><span class="line"><span class="keyword">from</span> kafka.errors <span class="keyword">import</span> kafka_errors</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_producer</span>():</span><br><span class="line">  	<span class="comment"># 假设生产的消息为键值对（不是一定要键值对），且序列化方式为json</span></span><br><span class="line">    producer = KafkaProducer(</span><br><span class="line">        bootstrap_servers=[<span class="string">&#x27;node01:9092&#x27;</span>],</span><br><span class="line">        acks=<span class="number">1</span>,</span><br><span class="line">        key_serializer=<span class="keyword">lambda</span> k: json.dumps(k).encode(),</span><br><span class="line">        value_serializer=<span class="keyword">lambda</span> v: json.dumps(v).encode()</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">10</span>):</span><br><span class="line">      	<span class="comment"># send（）return 一个future metadata类型。</span></span><br><span class="line">        future = producer.send(</span><br><span class="line">            <span class="string">&#x27;test-topic&#x27;</span>,</span><br><span class="line">            key=<span class="string">&#x27;count_num&#x27;</span>,  <span class="comment"># 同一个key值，会被送至同一个分区</span></span><br><span class="line">            value=<span class="built_in">str</span>(i),</span><br><span class="line">            partition=<span class="number">2</span>   <span class="comment"># 向分区2发送消息</span></span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;send &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(i)))</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">          	<span class="comment"># 有 get() 就会变成同步操作，一定要等反馈才会发送下一条消息</span></span><br><span class="line">            <span class="comment"># 无 get() 是异步操作，无需等待反馈直接发送消息</span></span><br><span class="line">            <span class="comment"># get() 会触发真实_send(),像把锁，锁住下个真实的_send()</span></span><br><span class="line">            <span class="comment"># get() 返回的是recordmetadata类型，可以看数据到底是发送到了哪个分区，偏移量是多少。</span></span><br><span class="line">            future.get(timeout=<span class="number">10</span>)  <span class="comment"># 监控是否发送成功   </span></span><br><span class="line">            <span class="built_in">print</span>( <span class="string">&#x27;producer send %d is ok! &#x27;</span>%(i))</span><br><span class="line">            <span class="built_in">print</span>(<span class="built_in">type</span>(future))  <span class="comment"># FutureRecordMetadata 类型</span></span><br><span class="line">        <span class="keyword">except</span> kafka_errors:</span><br><span class="line">            traceback.format_exc()</span><br><span class="line">		producer.close()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    create_producer()</span><br></pre></td></tr></table></figure>

<p><code>kafka-consumer-groups.sh --bootstrap-server node01:9092 --list</code></p>
<p><code>kafka-consumer-groups.sh --bootstrap-server node01:9092 --describe --group test-consumer-group</code></p>
<p>​		可以看见生产者发送完数据后，消费者从各个partition中消费完offset偏移量的变化。</p>
<h3 id="带回调函数的生产者"><a href="#带回调函数的生产者" class="headerlink" title="带回调函数的生产者"></a>带回调函数的生产者</h3><p>python <a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=kafka&spm=1001.2101.3001.7020">kafka</a> 生产者发送数据的三种方式:</p>
<p>​		1、sync同步发送（等）</p>
<p>​		2、asyn异步发送（不等）</p>
<p>​		3、异步+回调处理（综合前两者）较快、不丢数据</p>
<p>​				异步+回调函数模式，send方法发送消息的同时，send的返回对象FutureRecordMetadata 指定一个回调函数，服务器在返回响应时会调用该回调函数，通过回调函数能够对异常情况进行处理，当调用了回调函数时，只有回调函数执行完毕生产者才会结束，否则一直会阻塞。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 比起java 实现回调函数 ，要在send（）参数内 new 一个callback对象并重写方法实现接口，python的 写法更加易读易理解逻辑，python 对send（）的返回结果 追加一个callback。</span></span><br><span class="line"><span class="comment"># 写代码时记得常用 ctrl+command+点击 在idea 中查看源码，学会使用没见过的方法。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># coding:utf8</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaProducer</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Producer</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,bootstrap_servers,topic,acks</span>):</span><br><span class="line">        self.producer = KafkaProducer(</span><br><span class="line">            bootstrap_servers = bootstrap_servers,</span><br><span class="line">            value_serializer = <span class="keyword">lambda</span> v: json.dumps(v).encode(),</span><br><span class="line">            acks = acks)</span><br><span class="line">        self.topic = topic</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 同步发送 数据</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sync_producer</span>(<span class="params">self,data_list</span>):</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_list:</span><br><span class="line">            future = self.producer.send(self.topic,data)</span><br><span class="line">            record_metadata = future.get(timeout=<span class="number">10</span>)</span><br><span class="line">            partition = record_metadata.partition</span><br><span class="line">            offset = record_metadata.offset</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;save success,partition:&#123;&#125;,offset:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(partition,offset))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 异步发送数据</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">asyn_producer</span>(<span class="params">self,data_list</span>):</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_list:</span><br><span class="line">            self.producer.send(self.topic,data)</span><br><span class="line">        self.producer.flush()  <span class="comment"># 批量提交，触发真实_send()。多线程flush的话，一个flush在阻塞状态，不影响别的线程提交。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 异步发送数据 + 用回调函数 调用指定方法。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">asyn_producer_callback</span>(<span class="params">self,data_list</span>):</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_list:</span><br><span class="line">            self.producer.send(self.topic,data).\</span><br><span class="line">                add_callback(self.send_ok).\</span><br><span class="line">                add_errback(self.send_no_ok)</span><br><span class="line">        self.producer.flush()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># this mathod must have args! otherwise the mathod no run.</span></span><br><span class="line">    <span class="comment"># 被回调函数调用的方法一定要有参数，此参数就是返回的recordmetadata类型数据，可以直接看partition和offset 等信息。此参数相当于同步发送时用get()后的返回值，可以看数据到底是发送到了哪个分区，偏移量是多少。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">send_ok</span>(<span class="params">self,record_meta</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;异步发送成功回调函数&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;asyn_callback save sucess&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">type</span>(record_meta),<span class="string">&#x27;\n&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;partition:&#123;&#125;,offset:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(record_meta.partition,record_meta.offset))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">send_no_ok</span>(<span class="params">self, *args, **kwargs</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;异步发送错误回调函数&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;asyn_callback save error&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_proceder</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.producer.close()</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;close producer false&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data_list = [<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>]</span><br><span class="line">		</span><br><span class="line">    <span class="comment"># 同步发送</span></span><br><span class="line">    <span class="comment"># P = Producer(topic=&#x27;test-topic&#x27;,bootstrap_servers=&#x27;node01:9092&#x27;,acks=-1)</span></span><br><span class="line">    <span class="comment"># P.sync_producer(data_list)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 异步发送</span></span><br><span class="line">    <span class="comment"># P = Producer(topic=&#x27;test-topic&#x27;,bootstrap_servers=&#x27;node01:9092&#x27;,acks=0)</span></span><br><span class="line">    <span class="comment"># P.asyn_producer(data_list)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 异步 + 回调</span></span><br><span class="line">    P = Producer(topic=<span class="string">&#x27;test-topic&#x27;</span>,bootstrap_servers=<span class="string">&#x27;node01:9092&#x27;</span>,acks=<span class="number">1</span>)</span><br><span class="line">    P.asyn_producer_callback(data_list)</span><br><span class="line">		</span><br><span class="line">    <span class="comment"># 关闭producer。 </span></span><br><span class="line">    P.close_proceder()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># output</span></span><br><span class="line">asyn_callback save sucess</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;kafka.producer.future.RecordMetadata&#x27;</span>&gt; </span><br><span class="line"> partition:<span class="number">1</span>,offset:<span class="number">36</span></span><br><span class="line">asyn_callback save sucess</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;kafka.producer.future.RecordMetadata&#x27;</span>&gt; </span><br><span class="line"> partition:<span class="number">1</span>,offset:<span class="number">37</span></span><br><span class="line">asyn_callback save sucess</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;kafka.producer.future.RecordMetadata&#x27;</span>&gt; </span><br><span class="line"> partition:<span class="number">1</span>,offset:<span class="number">38</span></span><br><span class="line">asyn_callback save sucess</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;kafka.producer.future.RecordMetadata&#x27;</span>&gt; </span><br><span class="line"> partition:<span class="number">0</span>,offset:<span class="number">107</span></span><br><span class="line">asyn_callback save sucess</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;kafka.producer.future.RecordMetadata&#x27;</span>&gt; </span><br><span class="line"> partition:<span class="number">2</span>,offset:<span class="number">161</span></span><br></pre></td></tr></table></figure>

<p>消费者组可以查看偏移量情况，可见current-offset偏移量正好接上。</p>
<p><code>kafka-consumer-groups.sh --bootstrap-server node01:9092 --describe --group test-consumer-group</code></p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-27%2020.01.33-7029089.jpg" alt="截屏2022-04-27 20.01.33"></p>
<p>​		</p>
<h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h3><p>​		idea中点击源码可见KafkaConsumer继承了一个迭代器。这样就好理解了。	</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf8</span></span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaConsumer,TopicPartition</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Consumer</span>():</span><br><span class="line">    <span class="comment"># 看源码可知 KafkaConsumer 参数 topics 要后期订阅。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,topics,bootstrap_servers,group_id,consumer_id</span>):</span><br><span class="line">        self.consumer = KafkaConsumer(</span><br><span class="line">            bootstrap_servers=bootstrap_servers,</span><br><span class="line">            group_id = group_id)</span><br><span class="line">        self.topics = topics</span><br><span class="line">        self.consumer_id = consumer_id</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">simple_consumer</span>(<span class="params">self</span>):</span><br><span class="line">        self.consumer.subscribe(self.topics)</span><br><span class="line">        <span class="keyword">for</span> message <span class="keyword">in</span> self.consumer:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;consumer_id=&#123;&#125;--&gt;receive,key:&#123;&#125;,value:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(self.consumer_id,message.key,message.value))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  </span><br><span class="line">    consumer = Consumer(topics = <span class="string">&#x27;consumer_test&#x27;</span>,</span><br><span class="line">                        bootstrap_servers=<span class="string">&quot;node01:9092,node02:9092,node03:9092&quot;</span>,</span><br><span class="line">                        group_id=<span class="string">&#x27;consumer_group_test&#x27;</span>,</span><br><span class="line">                        consumer_id=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(consumer),<span class="string">&#x27;\n&#x27;</span>,consumer)</span><br><span class="line">    consumer.simple_consumer()</span><br></pre></td></tr></table></figure>

<p>​		在node02开一个窗口版的kafka生产者</p>
<p>​		<code>kafka-console-producer.sh --broker-list node01:9092,node02:9092,node03:9092 --topic consumer_test</code></p>
<p>​		输入 消息内容。ok1 ok2 … ok11 </p>
<p>​		在node01内赋值上述脚本两份，一份consumer_id&#x3D;1，一份consumer_id&#x3D;2，实现消费者组。两份脚本同时运行上面消费者代码，可见如下：</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-02%2012.03.58.jpg" alt="截屏2022-05-02 12.03.58"></p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-02%2012.04.13.jpg" alt="截屏2022-05-02 12.04.13"></p>
<h3 id="升级版消费者"><a href="#升级版消费者" class="headerlink" title="升级版消费者"></a>升级版消费者</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf8</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaConsumer,TopicPartition</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Consumer</span>():</span><br><span class="line">    <span class="comment"># 看源码可知 KafkaConsumer 参数 topics不是直接赋值，而是后期订阅或者分配。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,bootstrap_servers,group_id,consumer_id</span>):</span><br><span class="line">        self.consumer = KafkaConsumer(</span><br><span class="line">            bootstrap_servers=bootstrap_servers,</span><br><span class="line">            group_id = group_id,</span><br><span class="line">            enable_auto_commit = <span class="literal">False</span>) <span class="comment"># 关闭自动提交消费者数据到集群，集群没接到commit就不会把position下次消费的offset指针往后移。手动提交的好处之一就是 避免数据重读，在自动提交情况下一旦读取数据但是还没提交，此时partition挂掉了，很可能导致下次消费者重读一遍，而手动提交如果发现partition挂掉会抛出异常，阻塞，一直试到发送成功。</span></span><br><span class="line">        self.consumer_id = consumer_id</span><br><span class="line">		</span><br><span class="line">    <span class="comment"># 定单个topic的分区，分配给消费者，然后seek指定offset偏移量，一个一个顺序消费。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">user_defined_offset_consume</span>(<span class="params">self,topic,partition</span>):</span><br><span class="line">        tp = TopicPartition(topic,partition)</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">type</span>(tp),tp)</span><br><span class="line">        <span class="comment"># it is not possible to use both manual partition assignment with assign()</span></span><br><span class="line">        <span class="comment"># and group assignment with subscribe().</span></span><br><span class="line">        <span class="comment"># 订阅和分配只能二选一。</span></span><br><span class="line">        self.consumer.assign([tp])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>,<span class="number">30</span>):</span><br><span class="line">            self.consumer.seek(tp,i)</span><br><span class="line">            consumer_data = <span class="built_in">next</span>(self.consumer) <span class="comment"># 注意：使用next后，偏移量自动+1</span></span><br><span class="line">            <span class="built_in">print</span>(consumer_data)</span><br><span class="line">            self.consumer.commit()</span><br><span class="line">		</span><br><span class="line">		<span class="comment"># 指定多个topic分区，分配给消费者，用position找到消费者下次即将消费的offset位置，再用seek指定到此位置开始消费。</span></span><br><span class="line">    <span class="comment"># 但是要注意到：consumer.assign()多个分区, seek 再指定的情况，会让consumer 随机一个分区逐个消费数据，直到最新数据，然后随机切换到另一个分区从指定位置消费,不会一直在一个分区消费！！！</span></span><br><span class="line">    <span class="comment"># 注意：会在多个分区中切换着消费，直到生产者的end—offset位置，如果不断有新消息到不同分区，还会不停的切换着分区消费！！！</span></span><br><span class="line">    <span class="comment"># 错误的写法结果：在循环到第一个分区时，就因为调用了consumer消费，在不同分区（seek的起始位置～生产者最新写入的offset位置）中消费，直到消费到各个分区的生产者最新写入的offset位置。</span></span><br><span class="line">    <span class="comment"># 正确的写法结果：循环完三个分区，显示完了各个分区消费到哪个offset位置了，再调用consumer消费，在不同分区（seek的起始位置～生产者最新写入的offset位置）中消费，直到消费到各个分区的生产者最新写入的offset位置。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_next_offset_consume</span>(<span class="params">self,topic</span>):</span><br><span class="line">        tps = [TopicPartition(topic,p) <span class="keyword">for</span> p <span class="keyword">in</span> self.consumer.partitions_for_topic(topic)]</span><br><span class="line">        self.consumer.assign(tps)</span><br><span class="line">        <span class="keyword">for</span> tp <span class="keyword">in</span> tps:</span><br><span class="line">            next_offset = self.consumer.position(tp)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;分区 :&#123;&#125; ,的将要消费的offset是&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(tp.partition,next_offset))</span><br><span class="line">            self.consumer.seek(tp,next_offset)</span><br><span class="line">            <span class="comment"># 错误写法</span></span><br><span class="line">            <span class="comment"># for message in self.consumer:</span></span><br><span class="line">            <span class="comment">#     print(message)</span></span><br><span class="line">            <span class="comment">#     self.consumer.commit()</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;~~~~~~~~~~~~~~~~~~~~~&#x27;</span>)</span><br><span class="line">        <span class="comment"># 正确写法。</span></span><br><span class="line">        <span class="keyword">for</span> message <span class="keyword">in</span> self.consumer:</span><br><span class="line">            <span class="built_in">print</span>(message)</span><br><span class="line">						self.consumer.commit()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">simple_consumer</span>(<span class="params">self,topic</span>):</span><br><span class="line">        self.consumer.subscribe(topic)</span><br><span class="line">        <span class="keyword">for</span> message <span class="keyword">in</span> self.consumer:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;consumer_id=&#123;&#125;--&gt;receive,key:&#123;&#125;,value:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(self.consumer_id,message.key,message.value))</span><br><span class="line">						self.consumer.commit()</span><br><span class="line">            </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    consumer = Consumer(bootstrap_servers=<span class="string">&quot;node01:9092,node02:9092,node03:9092&quot;</span>,</span><br><span class="line">                        group_id=<span class="string">&quot;consumer_group_multifunction_test&quot;</span>,</span><br><span class="line">                        consumer_id=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># consumer.simple_consumer(topic=&#x27;consumer_test&#x27;)</span></span><br><span class="line">    <span class="comment"># consumer.user_defined_offset_consume(topic=&#x27;consumer_test&#x27;,partition=0)</span></span><br><span class="line">    consumer.from_next_offset_consume(topic=<span class="string">&#x27;consumer_test&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># output 指定单个topic的分区，分配给消费者，然后seek指定offset偏移量，一个一个顺序消费。</span></span><br><span class="line"><span class="comment"># def user_defined_offset_consume(self,topic,partition):consumer.user_defined_offset_consume(topic=&#x27;consumer_test&#x27;,partition=0)</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;kafka.structs.TopicPartition&#x27;</span>&gt; TopicPartition(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">12</span>, timestamp=<span class="number">1651463940201</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok2&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">13</span>, timestamp=<span class="number">1651464157363</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok5&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">14</span>, timestamp=<span class="number">1651464161278</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok7&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">15</span>, timestamp=<span class="number">1651470871128</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok12&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">16</span>, timestamp=<span class="number">1651476914181</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok14&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">17</span>, timestamp=<span class="number">1651478269618</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok17&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">18</span>, timestamp=<span class="number">1651478733176</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok21&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">19</span>, timestamp=<span class="number">1651478792011</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok24&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">20</span>, timestamp=<span class="number">1651479887199</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok26&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">21</span>, timestamp=<span class="number">1651480351104</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok3&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># output </span></span><br><span class="line"><span class="comment"># def from_next_offset_consume(self,topic):</span></span><br><span class="line"><span class="comment"># 正确写法结果。</span></span><br><span class="line">分区 :<span class="number">0</span> ,的将要消费的offset是<span class="number">20</span></span><br><span class="line">分区 :<span class="number">1</span> ,的将要消费的offset是<span class="number">21</span></span><br><span class="line">分区 :<span class="number">2</span> ,的将要消费的offset是<span class="number">17</span></span><br><span class="line">~~~~~~~~~~~~~~~~~~~~~</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">20</span>, timestamp=<span class="number">1651479887199</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok26&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">21</span>, timestamp=<span class="number">1651480351104</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok3&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">1</span>, offset=<span class="number">21</span>, timestamp=<span class="number">1651479980961</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok38&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">1</span>, offset=<span class="number">22</span>, timestamp=<span class="number">1651480349866</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok2&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">1</span>, offset=<span class="number">23</span>, timestamp=<span class="number">1651480522299</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok4&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">2</span>, offset=<span class="number">17</span>, timestamp=<span class="number">1651479870173</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok25&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">2</span>, offset=<span class="number">18</span>, timestamp=<span class="number">1651479910881</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok27&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">2</span>, offset=<span class="number">19</span>, timestamp=<span class="number">1651480348243</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok1&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># output </span></span><br><span class="line"><span class="comment"># def from_next_offset_consume(self,topic):</span></span><br><span class="line"><span class="comment"># 错误写法结果。</span></span><br><span class="line">分区 :<span class="number">0</span> ,的将要消费的offset是<span class="number">20</span></span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">2</span>, offset=<span class="number">17</span>, timestamp=<span class="number">1651479870173</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok25&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">2</span>, offset=<span class="number">18</span>, timestamp=<span class="number">1651479910881</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok27&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">2</span>, offset=<span class="number">19</span>, timestamp=<span class="number">1651480348243</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok1&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">1</span>, offset=<span class="number">21</span>, timestamp=<span class="number">1651479980961</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok38&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">1</span>, offset=<span class="number">22</span>, timestamp=<span class="number">1651480349866</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok2&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">1</span>, offset=<span class="number">23</span>, timestamp=<span class="number">1651480522299</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok4&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">20</span>, timestamp=<span class="number">1651479887199</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok26&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">4</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line">ConsumerRecord(topic=<span class="string">&#x27;consumer_test&#x27;</span>, partition=<span class="number">0</span>, offset=<span class="number">21</span>, timestamp=<span class="number">1651480351104</span>, timestamp_type=<span class="number">0</span>, key=<span class="literal">None</span>, value=<span class="string">b&#x27;ok3&#x27;</span>, headers=[], checksum=<span class="literal">None</span>, serialized_key_size=-<span class="number">1</span>, serialized_value_size=<span class="number">3</span>, serialized_header_size=-<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​		运行前，没有提交时，用消费者组看消费情况</p>
<p><code>kafka-consumer-groups.sh --bootstrap-server node01:9092 --describe --group consumer_group_multifunction_test</code></p>
<p>​		运行完，提交之后，再查看消费情况。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-02%2020.48.36.jpg" alt="截屏2022-05-02 20.48.36"></p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-02%2020.58.11.jpg" alt="截屏2022-05-02 20.58.11"></p>
<p>​		</p>
<h3 id="计算kafka堆积剩余量"><a href="#计算kafka堆积剩余量" class="headerlink" title="计算kafka堆积剩余量"></a>计算kafka堆积剩余量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># conding:utf8</span></span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaConsumer,TopicPartition</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">view_accumulation</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,topic,bootstrap_servers,group_id</span>):</span><br><span class="line">        self.topic = topic</span><br><span class="line">        self.group_id = group_id</span><br><span class="line">        self.consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers,group_id=self.group_id)</span><br><span class="line">        self.tps = [TopicPartition(self.topic,p) <span class="keyword">for</span> p <span class="keyword">in</span> self.consumer.partitions_for_topic(self.topic)]</span><br><span class="line">        self.calculation_allowance()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">producer_write_offset</span>(<span class="params">self</span>):</span><br><span class="line">        p_offset = self.consumer.end_offsets(self.tps)</span><br><span class="line">        <span class="built_in">print</span>(p_offset) <span class="comment"># &#123;TopicPartition(topic=&#x27;consumer_test&#x27;, partition=0): 23, TopicPartition(topic=&#x27;consumer_test&#x27;, partition=1): 25, TopicPartition(topic=&#x27;consumer_test&#x27;, partition=2): 21&#125;</span></span><br><span class="line">        p_offset = [(key.partition,p_offset[key]) <span class="keyword">for</span> key <span class="keyword">in</span> p_offset.keys()]</span><br><span class="line">        <span class="built_in">print</span>(p_offset) <span class="comment"># [(0, 23), (1, 25), (2, 21)]</span></span><br><span class="line">        <span class="keyword">return</span> p_offset</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">consumer_read_offset</span>(<span class="params">self</span>):</span><br><span class="line">        c_offset = [(tp.partition,self.consumer.committed(tp)) <span class="keyword">for</span> tp <span class="keyword">in</span> self.tps] <span class="comment"># return None if there was no prior commit.</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>,c_offset)  <span class="comment">#  [(0, 22), (1, 24), (2, 20)]</span></span><br><span class="line">        <span class="keyword">return</span> c_offset</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calculation_allowance</span>(<span class="params">self</span>):</span><br><span class="line">        sum_of_p_offset = <span class="built_in">sum</span>([x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> self.producer_write_offset()])</span><br><span class="line">        sum_of_c_offset = <span class="built_in">sum</span>([x[<span class="number">1</span>] <span class="keyword">if</span> x[<span class="number">1</span>]!=<span class="literal">None</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> self.consumer_read_offset() ])</span><br><span class="line">        allowance = sum_of_p_offset-sum_of_c_offset</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\n kafka accumulate space except_group_id &#123;&#125; is: \n&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(self.group_id,allowance))</span><br><span class="line">        <span class="keyword">return</span> allowance</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    v = view_accumulation(bootstrap_servers=<span class="string">&quot;node01:9092,node02:9092,node03:9092&quot;</span>,</span><br><span class="line">                          topic=<span class="string">&#x27;consumer_test&#x27;</span>,</span><br><span class="line">                          group_id=<span class="string">&quot;consumer_group_multifunction_test&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>     我在生产者输入6个消息调用上述计算kafka 堆积量的脚步，可见。
</code></pre>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-02%2022.31.40.jpg" alt="截屏2022-05-02 22.31.40"></p>
<h3 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h3><p>​		kafka-python 并没有实现 interceptor拦截器。拦截器主要是做producer的 send 之前和callback回调 之后的数据过滤或者加工的，python实际上很擅长干数据过滤加工相关的活，不用interceptor 也是可以实现拦截器的功能的。</p>
<h1 id="读kafka-python源码（kafkaproducer）"><a href="#读kafka-python源码（kafkaproducer）" class="headerlink" title="读kafka-python源码（kafkaproducer）"></a>读kafka-python源码（kafkaproducer）</h1><p>​		所有细节都看明白不容易，但是一些模块化很强的地方是容易理解的。在idea中读源码可以用快捷键查 <code>ctrl + command + 点击</code> 看源码；<code>ctrl+command+h</code> 看继承关系；<code>alt+上下键</code> 方法上下切换；<code>alt+左右键</code> idea中模块左右切换；<code>选中类+alt+7 </code> 还能看见类下所有方法…等等。也可以不用idea直接看 kafka- python的文档，我还是喜欢idea读一些。</p>
<h2 id="读源码前奏：更改默认发送去哪个分区的算法"><a href="#读源码前奏：更改默认发送去哪个分区的算法" class="headerlink" title="读源码前奏：更改默认发送去哪个分区的算法"></a>读源码前奏：更改默认发送去哪个分区的算法</h2><p>​		ctrl+command+点击 kafkaproducer() ,跳转至kafka.py模块，点击 self.config 可见一个dict 存放了大量待调用属性和方法；</p>
<p>​		ctrl + f  搜索 partition 可以见 default—config 中有 如下键值对。以及筛选方法。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2021.51.21.jpg" alt="截屏2022-04-28 21.51.21"></p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2022.00.13.jpg" alt="截屏2022-04-28 22.00.13"></p>
<p>​		ctrl+command+点击  defaultpartitioner() ,跳转至 default.py 模块。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2021.52.30.jpg" alt="截屏2022-04-28 21.52.30"></p>
<p>​		读一读就明白了，原来这里是决定发送到哪一个分区的算法，defaultpartitioner  类 内部有 一个被类方法修饰过的 <code>__call__()</code>方法，此方法是将原本不可以调用的类对象，变成可以直接调用的对象（把类变得和方法一样可以调用），并且每一次调用，会自动运行<code>__call__()</code>下的代码。</p>
<p>​		这样一来，如果我们把<code>__call__()</code> 方法下的内容改为 <code>return all_partitions[0]</code>  ，以后只要不在send()加partition参数，都会调用此修改后的方法把消息发送到 topic的 0号分区。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2022.08.15.jpg" alt="截屏2022-04-28 22.08.15"></p>
<p>​		补充一点：idea中不能直接修改源码，会提示revert changes修改被还原，cd 到指定文件夹，chmod 更改模块的权限，用vim 进行编辑。	</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/anaconda3/lib/python3.8/site-packages/kafka/partitioner/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在kafka中打开一个消费者组，检查消费者组的消费情况。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">发现发来的消息确实全部发送进了 partition 0 分区，消费者都从这个分区内拿数据。</span></span><br><span class="line">kafka-consumer-groups.sh --bootstrap-server node01:9092 --describe --group console-consumer-44048</span><br></pre></td></tr></table></figure>

<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2010.11.53.jpg" alt="截屏2022-04-29 10.11.53"></p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2010.12.29.jpg" alt="截屏2022-04-29 10.12.29"></p>
<p>​		消费者组都是从partition0 中消费，offset变更都发生在partition0。</p>
<h2 id="正式读源码"><a href="#正式读源码" class="headerlink" title="正式读源码"></a>正式读源码</h2><p>​		ctrl + command + 点击 KafkaProducer<img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2016.21.52.jpg" alt="截屏2022-04-28 16.21.52"></p>
<p>​		可见kafkaproducer 的构造方法。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2016.23.12.jpg" alt="截屏2022-04-28 16.23.12"></p>
<p>​		先复制一份默认配置文件到self.config, 里面长这样。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2016.47.30.jpg" alt="截屏2022-04-28 16.47.30"></p>
<p>​		收集参数 **configs ，把我们输入进来的 参数变成字典形式的configs。</p>
<p>​		遍历默认配置文件的key，看看哪些被我们用到了。</p>
<p>​		用到了哪些key，就把默认的self.config 相应的字典键值对修改成我们输入的内容。		<img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2017.43.08.jpg" alt="截屏2022-04-28 17.43.08"></p>
<p>​		如果 <code>__init__</code>构造函数传入的参数**configs 被上一步 遍历完，不断的pop弹出 后，还有未弹出的 字典 键值对，我们就用断言抛出 Unrecognized configs:。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2017.57.47.jpg" alt="截屏2022-04-28 17.57.47"></p>
<p>​		如果client_id的值是空的，就在 <code>kafka-python-producer-</code> 后面自增一个整数。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.02.38.jpg" alt="截屏2022-04-28 18.02.38"></p>
<p>​		配置metrics指标标签，设置好最大阻塞时间等信息，调用kafkaclient 生成client信息。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.10.58.jpg" alt="截屏2022-04-28 18.10.58"></p>
<hr>
<p>————————————————分叉阅读开始—————————————</p>
<p>​		我们好奇Metrics() 是什么，点进去看。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> kafka.metrics <span class="keyword">import</span> AnonMeasurable, KafkaMetric, MetricConfig, MetricName</span><br><span class="line"><span class="keyword">from</span> kafka.metrics.stats <span class="keyword">import</span> Sensor</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Metrics</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, default_config=<span class="literal">None</span>, reporters=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 enable_expiration=<span class="literal">False</span></span>):</span><br><span class="line">        </span><br><span class="line">        self._lock = threading.RLock()</span><br><span class="line">        self._config = default_config <span class="keyword">or</span> MetricConfig()</span><br><span class="line">        self._sensors = &#123;&#125;</span><br><span class="line">        self._metrics = &#123;&#125;</span><br><span class="line">        self._children_sensors = &#123;&#125;</span><br><span class="line">        self._reporters = reporters <span class="keyword">or</span> []</span><br><span class="line">        <span class="keyword">for</span> reporter <span class="keyword">in</span> self._reporters:</span><br><span class="line">            reporter.init([])</span><br><span class="line">            </span><br><span class="line"><span class="comment"># 开启一个守护进程，每隔30秒就run一下。</span></span><br><span class="line">        <span class="keyword">if</span> enable_expiration:</span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">expire_loop</span>():</span><br><span class="line">                <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                    <span class="comment"># delay 30 seconds</span></span><br><span class="line">                    time.sleep(<span class="number">30</span>)</span><br><span class="line">                    self.ExpireSensorTask.run(self)</span><br><span class="line">            metrics_scheduler = threading.Thread(target=expire_loop)</span><br><span class="line">            <span class="comment"># Creating a daemon thread to not block shutdown</span></span><br><span class="line">            metrics_scheduler.daemon = <span class="literal">True</span></span><br><span class="line">            metrics_scheduler.start()</span><br><span class="line"></span><br><span class="line">        self.add_metric(self.metric_name(<span class="string">&#x27;count&#x27;</span>, <span class="string">&#x27;kafka-metrics-count&#x27;</span>,</span><br><span class="line">                                         <span class="string">&#x27;total number of registered metrics&#x27;</span>),</span><br><span class="line">                        AnonMeasurable(<span class="keyword">lambda</span> config, now: <span class="built_in">len</span>(self._metrics)))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">config</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._config</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">metrics</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Get all the metrics currently maintained and indexed by metricName</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self._metrics</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">metric_name</span>(<span class="params">self, name, group, description=<span class="string">&#x27;&#x27;</span>, tags=<span class="literal">None</span></span>):</span><br><span class="line">        </span><br><span class="line">        combined_tags = <span class="built_in">dict</span>(self.config.tags)</span><br><span class="line">        combined_tags.update(tags <span class="keyword">or</span> &#123;&#125;)</span><br><span class="line">        <span class="keyword">return</span> MetricName(name, group, description, combined_tags)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_sensor</span>(<span class="params">self, name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Get the sensor with the given name if it exists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Arguments:</span></span><br><span class="line"><span class="string">            name (str): The name of the sensor</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Sensor: The sensor or None if no such sensor exists</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> name:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;name must be non-empty&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> self._sensors.get(name, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sensor</span>(<span class="params">self, name, config=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">               inactive_sensor_expiration_time_seconds=sys.maxsize,</span></span><br><span class="line"><span class="params">               parents=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Get or create a sensor with the given unique name and zero or</span></span><br><span class="line"><span class="string">        more parent sensors. All parent sensors will receive every value</span></span><br><span class="line"><span class="string">        recorded with this sensor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Arguments:</span></span><br><span class="line"><span class="string">            name (str): The name of the sensor</span></span><br><span class="line"><span class="string">            config (MetricConfig, optional): A default configuration to use</span></span><br><span class="line"><span class="string">                for this sensor for metrics that don&#x27;t have their own config</span></span><br><span class="line"><span class="string">            inactive_sensor_expiration_time_seconds (int, optional):</span></span><br><span class="line"><span class="string">                If no value if recorded on the Sensor for this duration of</span></span><br><span class="line"><span class="string">                time, it is eligible for removal</span></span><br><span class="line"><span class="string">            parents (list of Sensor): The parent sensors</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Sensor: The sensor that is created</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        sensor = self.get_sensor(name)</span><br><span class="line">        <span class="keyword">if</span> sensor:</span><br><span class="line">            <span class="keyword">return</span> sensor</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> self._lock:</span><br><span class="line">            sensor = self.get_sensor(name)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> sensor:</span><br><span class="line">              <span class="comment"># 点进去可以看sensor.py 模块的内容。</span></span><br><span class="line">                sensor = Sensor(self, name, parents, config <span class="keyword">or</span> self.config,</span><br><span class="line">                                inactive_sensor_expiration_time_seconds)</span><br><span class="line">                self._sensors[name] = sensor</span><br><span class="line">                <span class="keyword">if</span> parents:</span><br><span class="line">                    <span class="keyword">for</span> parent <span class="keyword">in</span> parents:</span><br><span class="line">                        children = self._children_sensors.get(parent)</span><br><span class="line">                        <span class="keyword">if</span> <span class="keyword">not</span> children:</span><br><span class="line">                            children = []</span><br><span class="line">                            self._children_sensors[parent] = children</span><br><span class="line">                        children.append(sensor)</span><br><span class="line">                logger.debug(<span class="string">&#x27;Added sensor with name %s&#x27;</span>, name)</span><br><span class="line">            <span class="keyword">return</span> sensor</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">remove_sensor</span>(<span class="params">self, name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Remove a sensor (if it exists), associated metrics and its children.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Arguments:</span></span><br><span class="line"><span class="string">            name (str): The name of the sensor to be removed</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        sensor = self._sensors.get(name)</span><br><span class="line">        <span class="keyword">if</span> sensor:</span><br><span class="line">            child_sensors = <span class="literal">None</span></span><br><span class="line">            <span class="keyword">with</span> sensor._lock:</span><br><span class="line">                <span class="keyword">with</span> self._lock:</span><br><span class="line">                    val = self._sensors.pop(name, <span class="literal">None</span>)</span><br><span class="line">                    <span class="keyword">if</span> val <span class="keyword">and</span> val == sensor:</span><br><span class="line">                        <span class="keyword">for</span> metric <span class="keyword">in</span> sensor.metrics:</span><br><span class="line">                            self.remove_metric(metric.metric_name)</span><br><span class="line">                        logger.debug(<span class="string">&#x27;Removed sensor with name %s&#x27;</span>, name)</span><br><span class="line">                        child_sensors = self._children_sensors.pop(sensor, <span class="literal">None</span>)</span><br><span class="line">            <span class="keyword">if</span> child_sensors:</span><br><span class="line">                <span class="keyword">for</span> child_sensor <span class="keyword">in</span> child_sensors:</span><br><span class="line">                    self.remove_sensor(child_sensor.name)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_metric</span>(<span class="params">self, metric_name, measurable, config=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Add a metric to monitor an object that implements measurable.</span></span><br><span class="line"><span class="string">        This metric won&#x27;t be associated with any sensor.</span></span><br><span class="line"><span class="string">        This is a way to expose existing values as metrics.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Arguments:</span></span><br><span class="line"><span class="string">            metricName (MetricName): The name of the metric</span></span><br><span class="line"><span class="string">            measurable (AbstractMeasurable): The measurable that will be</span></span><br><span class="line"><span class="string">                measured by this metric</span></span><br><span class="line"><span class="string">            config (MetricConfig, optional): The configuration to use when</span></span><br><span class="line"><span class="string">                measuring this measurable</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># NOTE there was a lock here, but i don&#x27;t think it&#x27;s needed</span></span><br><span class="line">        metric = KafkaMetric(metric_name, measurable, config <span class="keyword">or</span> self.config)</span><br><span class="line">        self.register_metric(metric)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">remove_metric</span>(<span class="params">self, metric_name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Remove a metric if it exists and return it. Return None otherwise.</span></span><br><span class="line"><span class="string">        If a metric is removed, `metric_removal` will be invoked</span></span><br><span class="line"><span class="string">        for each reporter.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Arguments:</span></span><br><span class="line"><span class="string">            metric_name (MetricName): The name of the metric</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            KafkaMetric: the removed `KafkaMetric` or None if no such</span></span><br><span class="line"><span class="string">                metric exists</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> self._lock:</span><br><span class="line">            metric = self._metrics.pop(metric_name, <span class="literal">None</span>)</span><br><span class="line">            <span class="keyword">if</span> metric:</span><br><span class="line">                <span class="keyword">for</span> reporter <span class="keyword">in</span> self._reporters:</span><br><span class="line">                    reporter.metric_removal(metric)</span><br><span class="line">            <span class="keyword">return</span> metric</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_reporter</span>(<span class="params">self, reporter</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Add a MetricReporter&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> self._lock:</span><br><span class="line">            reporter.init(<span class="built_in">list</span>(self.metrics.values()))</span><br><span class="line">            self._reporters.append(reporter)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">register_metric</span>(<span class="params">self, metric</span>):</span><br><span class="line">        <span class="keyword">with</span> self._lock:</span><br><span class="line">            <span class="keyword">if</span> metric.metric_name <span class="keyword">in</span> self.metrics:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&#x27;A metric named &quot;%s&quot; already exists, cannot&#x27;</span></span><br><span class="line">                                 <span class="string">&#x27; register another one.&#x27;</span> % (metric.metric_name,))</span><br><span class="line">            self.metrics[metric.metric_name] = metric</span><br><span class="line">            <span class="keyword">for</span> reporter <span class="keyword">in</span> self._reporters:</span><br><span class="line">                reporter.metric_change(metric)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">ExpireSensorTask</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        This iterates over every Sensor and triggers a remove_sensor</span></span><br><span class="line"><span class="string">        if it has expired. Package private for testing</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"><span class="meta">        @staticmethod</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">metrics</span>):</span><br><span class="line">            items = <span class="built_in">list</span>(metrics._sensors.items())</span><br><span class="line">            <span class="keyword">for</span> name, sensor <span class="keyword">in</span> items:</span><br><span class="line">                <span class="comment"># remove_sensor also locks the sensor object. This is fine</span></span><br><span class="line">                <span class="comment"># because synchronized is reentrant. There is however a minor</span></span><br><span class="line">                <span class="comment"># race condition here. Assume we have a parent sensor P and</span></span><br><span class="line">                <span class="comment"># child sensor C. Calling record on C would cause a record on</span></span><br><span class="line">                <span class="comment"># P as well. So expiration time for P == expiration time for C.</span></span><br><span class="line">                <span class="comment"># If the record on P happens via C just after P is removed,</span></span><br><span class="line">                <span class="comment"># that will cause C to also get removed. Since the expiration</span></span><br><span class="line">                <span class="comment"># time is typically high it is not expected to be a significant</span></span><br><span class="line">                <span class="comment"># concern and thus not necessary to optimize</span></span><br><span class="line">                <span class="keyword">with</span> sensor._lock:</span><br><span class="line">                    <span class="keyword">if</span> sensor.has_expired():</span><br><span class="line">                        logger.debug(<span class="string">&#x27;Removing expired sensor %s&#x27;</span>, name)</span><br><span class="line">                        metrics.remove_sensor(name)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Close this metrics repository.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> reporter <span class="keyword">in</span> self._reporters:</span><br><span class="line">            reporter.close()</span><br><span class="line"></span><br><span class="line">        self._metrics.clear()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​		我们好奇这个kafkaclient（）是什么 点进去可见</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.50.16.jpg" alt="截屏2022-04-28 18.50.16"></p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.51.00.jpg" alt="截屏2022-04-28 18.51.00"></p>
<p>​		kafkaclient（）里面是包含 clustermetadata 集群元数据的，我们又好奇clustermetadata是什么，再点开，可见kafka集群的信息都被包含在其中了。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.52.31.jpg" alt="截屏2022-04-28 18.52.31"></p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.52.58.jpg" alt="截屏2022-04-28 18.52.58"></p>
<p>————————————————分叉阅读结束—————————————</p>
<hr>
<p>​		选压缩类型</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-28%2018.56.36.jpg" alt="截屏2022-04-28 18.56.36"></p>
<p>​		接下来是比较关键的部分</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2018.29.16.jpg" alt="截屏2022-04-29 18.29.16"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">message_version = self._max_usable_produce_magic()</span><br><span class="line">self._accumulator = RecordAccumulator(message_version=message_version, metrics=self._metrics, **self.config)</span><br><span class="line">self._metadata = client.cluster</span><br><span class="line">guarantee_message_order = <span class="built_in">bool</span>(self.config[<span class="string">&#x27;max_in_flight_requests_per_connection&#x27;</span>] == <span class="number">1</span>)</span><br><span class="line">self._sender = Sender(client, self._metadata,</span><br><span class="line">                      self._accumulator, self._metrics,</span><br><span class="line">                      guarantee_message_order=guarantee_message_order,</span><br><span class="line">                      **self.config)</span><br><span class="line">self._sender.daemon = <span class="literal">True</span></span><br><span class="line">self._sender.start()</span><br><span class="line">self._closed = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">self._cleanup = self._cleanup_factory()</span><br><span class="line">atexit.register(self._cleanup)</span><br><span class="line">log.debug(<span class="string">&quot;Kafka producer started&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>​		我们看看self._max_usable_produce_magic() 是个啥。嗷，就是确定消息版本。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2018.31.31.jpg" alt="截屏2022-04-29 18.31.31"></p>
<p>​		我们看看recordaccumulator 是个啥。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-01%2013.08.56.jpg" alt="截屏2022-05-01 13.08.56"></p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-01%2013.09.16.jpg" alt="截屏2022-05-01 13.09.16">		这个recordaccumulator 累加器中有一个方法append（)值得读一遍。它创造了一个双端队列dq。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">append</span>(<span class="params">self, tp, timestamp_ms, key, value, headers, max_time_to_block_ms,</span></span><br><span class="line"><span class="params">           estimated_size=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Add a record to the accumulator, return the append result.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The append result will contain the future metadata, and flag for</span></span><br><span class="line"><span class="string">    whether the appended batch is full or a new batch is created</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        tp (TopicPartition): The topic/partition to which this record is</span></span><br><span class="line"><span class="string">            being sent</span></span><br><span class="line"><span class="string">        timestamp_ms (int): The timestamp of the record (epoch ms)</span></span><br><span class="line"><span class="string">        key (bytes): The key for the record</span></span><br><span class="line"><span class="string">        value (bytes): The value for the record</span></span><br><span class="line"><span class="string">        headers (List[Tuple[str, bytes]]): The header fields for the record</span></span><br><span class="line"><span class="string">        max_time_to_block_ms (int): The maximum time in milliseconds to</span></span><br><span class="line"><span class="string">            block for buffer memory to be available</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tuple: (future, batch_is_full, new_batch_created)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(tp, TopicPartition), <span class="string">&#x27;not TopicPartition&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="keyword">not</span> self._closed, <span class="string">&#x27;RecordAccumulator is closed&#x27;</span></span><br><span class="line">    <span class="comment"># We keep track of the number of appending thread to make sure we do</span></span><br><span class="line">    <span class="comment"># not miss batches in abortIncompleteBatches().</span></span><br><span class="line">    self._appends_in_progress.increment()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> tp <span class="keyword">not</span> <span class="keyword">in</span> self._tp_locks:</span><br><span class="line">            <span class="keyword">with</span> self._tp_locks[<span class="literal">None</span>]:</span><br><span class="line">                <span class="keyword">if</span> tp <span class="keyword">not</span> <span class="keyword">in</span> self._tp_locks:</span><br><span class="line">                    self._tp_locks[tp] = threading.Lock()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> self._tp_locks[tp]:</span><br><span class="line">            <span class="comment"># check if we have an in-progress batch</span></span><br><span class="line">            dq = self._batches[tp]</span><br><span class="line">            <span class="keyword">if</span> dq:</span><br><span class="line">                last = dq[-<span class="number">1</span>]</span><br><span class="line">                future = last.try_append(timestamp_ms, key, value, headers)</span><br><span class="line">                <span class="keyword">if</span> future <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    batch_is_full = <span class="built_in">len</span>(dq) &gt; <span class="number">1</span> <span class="keyword">or</span> last.records.is_full()</span><br><span class="line">                    <span class="keyword">return</span> future, batch_is_full, <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        size = <span class="built_in">max</span>(self.config[<span class="string">&#x27;batch_size&#x27;</span>], estimated_size)</span><br><span class="line">        log.debug(<span class="string">&quot;Allocating a new %d byte message buffer for %s&quot;</span>, size, tp) <span class="comment"># trace</span></span><br><span class="line">        buf = self._free.allocate(size, max_time_to_block_ms)</span><br><span class="line">        <span class="keyword">with</span> self._tp_locks[tp]:</span><br><span class="line">            <span class="comment"># Need to check if producer is closed again after grabbing the</span></span><br><span class="line">            <span class="comment"># dequeue lock.</span></span><br><span class="line">            <span class="keyword">assert</span> <span class="keyword">not</span> self._closed, <span class="string">&#x27;RecordAccumulator is closed&#x27;</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> dq:</span><br><span class="line">                last = dq[-<span class="number">1</span>]</span><br><span class="line">                future = last.try_append(timestamp_ms, key, value, headers)</span><br><span class="line">                <span class="keyword">if</span> future <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="comment"># Somebody else found us a batch, return the one we</span></span><br><span class="line">                    <span class="comment"># waited for! Hopefully this doesn&#x27;t happen often...</span></span><br><span class="line">                    self._free.deallocate(buf)</span><br><span class="line">                    batch_is_full = <span class="built_in">len</span>(dq) &gt; <span class="number">1</span> <span class="keyword">or</span> last.records.is_full()</span><br><span class="line">                    <span class="keyword">return</span> future, batch_is_full, <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            records = MemoryRecordsBuilder(</span><br><span class="line">                self.config[<span class="string">&#x27;message_version&#x27;</span>],</span><br><span class="line">                self.config[<span class="string">&#x27;compression_attrs&#x27;</span>],</span><br><span class="line">                self.config[<span class="string">&#x27;batch_size&#x27;</span>]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            batch = ProducerBatch(tp, records, buf)</span><br><span class="line">            future = batch.try_append(timestamp_ms, key, value, headers)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> future:</span><br><span class="line">                <span class="keyword">raise</span> Exception()</span><br><span class="line"></span><br><span class="line">            dq.append(batch)</span><br><span class="line">            self._incomplete.add(batch)</span><br><span class="line">            batch_is_full = <span class="built_in">len</span>(dq) &gt; <span class="number">1</span> <span class="keyword">or</span> batch.records.is_full()</span><br><span class="line">            <span class="keyword">return</span> future, batch_is_full, <span class="literal">True</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        self._appends_in_progress.decrement()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​		我们看看sender这个类中有啥</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-05-01%2013.15.50.jpg" alt="截屏2022-05-01 13.15.50"></p>
<p>​		读读sender中的 run_once 方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_once</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Run a single iteration of sending.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">while</span> self._topics_to_add:</span><br><span class="line">        self._client.add_topic(self._topics_to_add.pop())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get the list of partitions with data ready to send</span></span><br><span class="line">    result = self._accumulator.ready(self._metadata)</span><br><span class="line">    ready_nodes, next_ready_check_delay, unknown_leaders_exist = result</span><br><span class="line"></span><br><span class="line">    <span class="comment"># if there are any partitions whose leaders are not known yet, force</span></span><br><span class="line">    <span class="comment"># metadata update</span></span><br><span class="line">    <span class="keyword">if</span> unknown_leaders_exist:</span><br><span class="line">        log.debug(<span class="string">&#x27;Unknown leaders exist, requesting metadata update&#x27;</span>)</span><br><span class="line">        self._metadata.request_update()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># remove any nodes we aren&#x27;t ready to send to</span></span><br><span class="line">    not_ready_timeout = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> <span class="built_in">list</span>(ready_nodes):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._client.is_ready(node):</span><br><span class="line">            log.debug(<span class="string">&#x27;Node %s not ready; delaying produce of accumulated batch&#x27;</span>, node)</span><br><span class="line">            self._client.maybe_connect(node, wakeup=<span class="literal">False</span>)</span><br><span class="line">            ready_nodes.remove(node)</span><br><span class="line">            not_ready_timeout = <span class="built_in">min</span>(not_ready_timeout,</span><br><span class="line">                                    self._client.connection_delay(node))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create produce requests</span></span><br><span class="line">    batches_by_node = self._accumulator.drain(</span><br><span class="line">        self._metadata, ready_nodes, self.config[<span class="string">&#x27;max_request_size&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.config[<span class="string">&#x27;guarantee_message_order&#x27;</span>]:</span><br><span class="line">        <span class="comment"># Mute all the partitions drained</span></span><br><span class="line">        <span class="keyword">for</span> batch_list <span class="keyword">in</span> six.itervalues(batches_by_node):</span><br><span class="line">            <span class="keyword">for</span> batch <span class="keyword">in</span> batch_list:</span><br><span class="line">                self._accumulator.muted.add(batch.topic_partition)</span><br><span class="line"></span><br><span class="line">    expired_batches = self._accumulator.abort_expired_batches(</span><br><span class="line">        self.config[<span class="string">&#x27;request_timeout_ms&#x27;</span>], self._metadata)</span><br><span class="line">    <span class="keyword">for</span> expired_batch <span class="keyword">in</span> expired_batches:</span><br><span class="line">        self._sensors.record_errors(expired_batch.topic_partition.topic, expired_batch.record_count)</span><br><span class="line"></span><br><span class="line">    self._sensors.update_produce_request_metrics(batches_by_node)</span><br><span class="line">    requests = self._create_produce_requests(batches_by_node)</span><br><span class="line">    <span class="comment"># If we have any nodes that are ready to send + have sendable data,</span></span><br><span class="line">    <span class="comment"># poll with 0 timeout so this can immediately loop and try sending more</span></span><br><span class="line">    <span class="comment"># data. Otherwise, the timeout is determined by nodes that have</span></span><br><span class="line">    <span class="comment"># partitions with data that isn&#x27;t yet sendable (e.g. lingering, backing</span></span><br><span class="line">    <span class="comment"># off). Note that this specifically does not include nodes with</span></span><br><span class="line">    <span class="comment"># sendable data that aren&#x27;t ready to send since they would cause busy</span></span><br><span class="line">    <span class="comment"># looping.</span></span><br><span class="line">    poll_timeout_ms = <span class="built_in">min</span>(next_ready_check_delay * <span class="number">1000</span>, not_ready_timeout)</span><br><span class="line">    <span class="keyword">if</span> ready_nodes:</span><br><span class="line">        log.debug(<span class="string">&quot;Nodes with data ready to send: %s&quot;</span>, ready_nodes) <span class="comment"># trace</span></span><br><span class="line">        log.debug(<span class="string">&quot;Created %d produce requests: %s&quot;</span>, <span class="built_in">len</span>(requests), requests) <span class="comment"># trace</span></span><br><span class="line">        poll_timeout_ms = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> node_id, request <span class="keyword">in</span> six.iteritems(requests):</span><br><span class="line">        batches = batches_by_node[node_id]</span><br><span class="line">        log.debug(<span class="string">&#x27;Sending Produce Request: %r&#x27;</span>, request)</span><br><span class="line">        (self._client.send(node_id, request, wakeup=<span class="literal">False</span>)</span><br><span class="line">             .add_callback(</span><br><span class="line">                 self._handle_produce_response, node_id, time.time(), batches)</span><br><span class="line">             .add_errback(</span><br><span class="line">                 self._failed_produce, batches, node_id))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># if some partitions are already ready to be sent, the select time</span></span><br><span class="line">    <span class="comment"># would be 0; otherwise if some partition already has some data</span></span><br><span class="line">    <span class="comment"># accumulated but not ready yet, the select time will be the time</span></span><br><span class="line">    <span class="comment"># difference between now and its linger expiry time; otherwise the</span></span><br><span class="line">    <span class="comment"># select time will be the time difference between now and the</span></span><br><span class="line">    <span class="comment"># metadata expiry time</span></span><br><span class="line">    self._client.poll(timeout_ms=poll_timeout_ms)</span><br><span class="line"></span><br></pre></td></tr></table></figure>







<p>​		</p>
<h1 id="读java源码时要注意的点"><a href="#读java源码时要注意的点" class="headerlink" title="读java源码时要注意的点"></a>读java源码时要注意的点</h1><h2 id="java动态绑定机制（重写方法时常用）"><a href="#java动态绑定机制（重写方法时常用）" class="headerlink" title="java动态绑定机制（重写方法时常用）"></a>java动态绑定机制（重写方法时常用）</h2><p>​		java多态的一个经典情形，aa对象有两个getresult() 方法！！！优先调用new后的 getresult()方法，并且会因为调用这个方法而使用这个对象。注意： 变量没有这个特点，这个动态绑定时针对方法而言的，变量在哪里声明就在哪里使用！！！</p>
<p>​		读java版本源码（真实源码，毕竟kafka时java写的）要注意。<img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2017.25.37.jpg" alt="截屏2022-04-29 17.25.37"></p>
<p>​		优先调用了 BB内的 getresult 方法。BB内的 getresult 方法内使用了 i 这个变量，i 变量是在BB() 中声明过，变量在哪里声明哪里用。使用了 new BB() 对象的 i&#x3D;20；20+20&#x3D;40</p>
<p>​		结果是 40</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2017.20.29.jpg" alt="截屏2022-04-29 17.20.29"></p>
<p>​		BB() 中的同名方法被注销，动态绑定依旧还在  ，但是aa 中只有了一个AA() 的 getresult() 方法，别无选择，动态绑定原则，AA() 的 getresult() 方法内调用的 i 变量是在AA() 内声明的，变量哪里声明哪里用。调用了 AA() 中的 i&#x3D;10 ，10+10&#x3D;20。</p>
<p>​		结果是20。</p>
<p><img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2017.52.04.jpg" alt="截屏2022-04-29 17.52.04"></p>
<p>​		以上情况，首先调用是 AA() 的 getresult() 方法，因为没得选只有它，然后在里面需要 geti() 方法，动态绑定原则 优先去 new BB() 里面去找，用到了BB内的 geti() 方法，geti() 方法用到了BB() 中声明的变量 i ，i&#x3D;20 作为geti（）的返回值 传给 AA() 的 getresult() 方法，20+10&#x3D;30。</p>
<p>​		结果是30。</p>
<p>​		以上的变量哪里声明哪里使用要灵活用，不是只能调用自己类内的变量，如果用了 super.i 那用的就是父类的 i 了，i 其实都是this.i 的简写，哪里声明哪里使用变量并不是固定的。</p>
<p>​		</p>
<h2 id="java方法重载"><a href="#java方法重载" class="headerlink" title="java方法重载"></a>java方法重载</h2><p>​		<img src="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka-API%E5%AE%9E%E6%88%98/%E6%88%AA%E5%B1%8F2022-04-29%2018.10.35.jpg" alt="截屏2022-04-29 18.10.35"></p>
<p>​		和 new BBB() 根本没关系，完全由aaa 前面声明的类型 来决定选哪一个test() 方法。</p>
<p>​		</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/kafka/" rel="tag"># kafka</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka%E5%86%99%E5%85%A5-%E5%AD%98%E5%82%A8-%E6%B6%88%E8%B4%B9%E6%B5%81%E7%A8%8B/" rel="prev" title="kafka写入_存储_消费流程">
                  <i class="fa fa-chevron-left"></i> kafka写入_存储_消费流程
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/10/29/kafka%E5%AD%A6%E4%B9%A0/kafka%E5%92%8Cflume%E7%9A%84%E9%9B%86%E6%88%90/" rel="next" title="kafka和flume的集成">
                  kafka和flume的集成 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">陈宇韶chenyushao</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
