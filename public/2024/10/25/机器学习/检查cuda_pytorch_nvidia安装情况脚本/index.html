<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.13.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="这是文章开头，显示在主页面，详情请点击此处。">
<meta property="og:type" content="article">
<meta property="og:title" content="检查cuda_pytorch_nvidia安装情况脚本">
<meta property="og:url" content="http://example.com/2024/10/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A3%80%E6%9F%A5cuda_pytorch_nvidia%E5%AE%89%E8%A3%85%E6%83%85%E5%86%B5%E8%84%9A%E6%9C%AC/index.html">
<meta property="og:site_name" content="Tiger_pop&#39;s Blog">
<meta property="og:description" content="这是文章开头，显示在主页面，详情请点击此处。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2024/10/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A3%80%E6%9F%A5cuda_pytorch_nvidia%E5%AE%89%E8%A3%85%E6%83%85%E5%86%B5%E8%84%9A%E6%9C%AC/image-20240929085301281.png">
<meta property="og:image" content="http://example.com/2024/10/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A3%80%E6%9F%A5cuda_pytorch_nvidia%E5%AE%89%E8%A3%85%E6%83%85%E5%86%B5%E8%84%9A%E6%9C%AC/ddp.jpg">
<meta property="article:published_time" content="2024-10-25T03:12:13.000Z">
<meta property="article:modified_time" content="2024-11-11T00:45:40.419Z">
<meta property="article:author" content="陈宇韶chenyushao">
<meta property="article:tag" content="cuda">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="Nvidia驱动">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/10/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A3%80%E6%9F%A5cuda_pytorch_nvidia%E5%AE%89%E8%A3%85%E6%83%85%E5%86%B5%E8%84%9A%E6%9C%AC/image-20240929085301281.png">


<link rel="canonical" href="http://example.com/2024/10/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A3%80%E6%9F%A5cuda_pytorch_nvidia%E5%AE%89%E8%A3%85%E6%83%85%E5%86%B5%E8%84%9A%E6%9C%AC/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2024/10/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A3%80%E6%9F%A5cuda_pytorch_nvidia%E5%AE%89%E8%A3%85%E6%83%85%E5%86%B5%E8%84%9A%E6%9C%AC/","path":"2024/10/25/机器学习/检查cuda_pytorch_nvidia安装情况脚本/","title":"检查cuda_pytorch_nvidia安装情况脚本"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>检查cuda_pytorch_nvidia安装情况脚本 | Tiger_pop's Blog</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Tiger_pop's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Tiger_pop's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">tiger_pop 的博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E7%89%88%E6%9C%AC"><span class="nav-number">1.</span> <span class="nav-text">测试版本</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%80%9A%E7%94%A8%E7%89%88%E6%9C%AC"><span class="nav-number">2.</span> <span class="nav-text">通用版本</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%B9%E5%8A%A8%E6%80%BB%E7%BB%93%EF%BC%9A"><span class="nav-number">2.1.</span> <span class="nav-text">改动总结：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%9AGPU%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD%E7%89%88%E6%9C%AC"><span class="nav-number">3.</span> <span class="nav-text">多GPU并行计算性能版本</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81pytorch%E4%B8%8B%E7%9A%84GPU%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%EF%BC%8C%E4%B8%BE%E4%BE%8B%E4%B8%A4%E4%B8%AA%E6%A0%87%E5%87%86%E6%96%B9%E6%B3%95"><span class="nav-number">3.1.</span> <span class="nav-text">一、pytorch下的GPU并行计算，举例两个标准方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-torch-multiprocessing-mp"><span class="nav-number">3.1.1.</span> <span class="nav-text">1. torch.multiprocessing (mp)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Data-Parallelism%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C-ddp"><span class="nav-number">3.1.2.</span> <span class="nav-text">2. Data Parallelism数据并行 (ddp)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81mp-%E7%B2%BE%E7%AE%80%E9%80%BB%E8%BE%91"><span class="nav-number">3.2.</span> <span class="nav-text">二、mp-精简逻辑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E3%80%81mp-%E5%8F%AF%E7%94%A8%E4%BB%A3%E7%A0%81"><span class="nav-number">3.3.</span> <span class="nav-text">三、mp-可用代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9B%E3%80%81ddp%E7%B2%BE%E7%AE%80%E9%80%BB%E8%BE%91"><span class="nav-number">3.4.</span> <span class="nav-text">四、ddp精简逻辑</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9D%97%E5%8C%96%E7%9A%84%E9%80%BB%E8%BE%91%E8%AF%B4%E6%98%8E"><span class="nav-number">3.4.1.</span> <span class="nav-text">模块化的逻辑说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E7%A8%8B-setup-%E5%87%BD%E6%95%B0"><span class="nav-number">3.4.2.</span> <span class="nav-text">1. 初始化分布式进程 (setup 函数)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E5%B0%81%E8%A3%85-DDP-%E5%8C%85%E8%A3%85%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.4.3.</span> <span class="nav-text">2. 模型的分布式封装 (DDP 包装模型)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%8C%96-DistributedSampler"><span class="nav-number">3.4.4.</span> <span class="nav-text">3. 数据并行化 (DistributedSampler)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E8%87%AA%E5%8A%A8%E6%A2%AF%E5%BA%A6%E5%90%8C%E6%AD%A5%E5%92%8C%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0"><span class="nav-number">3.4.5.</span> <span class="nav-text">4. 自动梯度同步和参数更新</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E7%BB%93%E6%9D%9F%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83-cleanup"><span class="nav-number">3.4.6.</span> <span class="nav-text">5. 结束分布式训练 (cleanup)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E6%88%91%E7%BB%8F%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="nav-number">4.</span> <span class="nav-text">一个我经常用的例子</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="陈宇韶chenyushao"
      src="/images/my.jpg">
  <p class="site-author-name" itemprop="name">陈宇韶chenyushao</p>
  <div class="site-description" itemprop="description">爱学习、爱工作、爱生活;         微信号: Tiger_and_master;         手机号码:18515678348 </div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">378</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">138</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/10/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A3%80%E6%9F%A5cuda_pytorch_nvidia%E5%AE%89%E8%A3%85%E6%83%85%E5%86%B5%E8%84%9A%E6%9C%AC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my.jpg">
      <meta itemprop="name" content="陈宇韶chenyushao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tiger_pop's Blog">
      <meta itemprop="description" content="爱学习、爱工作、爱生活;         微信号: Tiger_and_master;         手机号码:18515678348 ">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="检查cuda_pytorch_nvidia安装情况脚本 | Tiger_pop's Blog">
      <meta itemprop="description" content="这是文章开头，显示在主页面，详情请点击此处。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          检查cuda_pytorch_nvidia安装情况脚本
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-10-25 11:12:13" itemprop="dateCreated datePublished" datetime="2024-10-25T11:12:13+08:00">2024-10-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-11-11 08:45:40" itemprop="dateModified" datetime="2024-11-11T08:45:40+08:00">2024-11-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">这是文章开头，显示在主页面，详情请点击此处。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="测试版本"><a href="#测试版本" class="headerlink" title="测试版本"></a>测试版本</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models, transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> ResNet50_Weights</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查并安装 tqdm</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">install_tqdm</span>():</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">import</span> tqdm</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;tqdm 已安装，不需要重复安装。&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> ModuleNotFoundError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;tqdm 未安装，正在使用 pip 自动安装...&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            subprocess.check_call([<span class="string">f&quot;<span class="subst">&#123;os.getenv(<span class="string">&#x27;CONDA_PREFIX&#x27;</span>)&#125;</span>/bin/pip&quot;</span>, <span class="string">&quot;install&quot;</span>, <span class="string">&quot;tqdm&quot;</span>, <span class="string">&quot;-i&quot;</span>, <span class="string">&quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;</span>])</span><br><span class="line">            <span class="keyword">import</span> tqdm  <span class="comment"># 确保安装成功</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;tqdm 安装成功！&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;tqdm 安装失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查系统信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">system_info</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;系统信息:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;操作系统: <span class="subst">&#123;platform.system()&#125;</span> <span class="subst">&#123;platform.release()&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取 Ubuntu 版本</span></span><br><span class="line">    <span class="keyword">if</span> platform.system() == <span class="string">&#x27;Linux&#x27;</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;/etc/os-release&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                    <span class="keyword">if</span> <span class="string">&quot;PRETTY_NAME&quot;</span> <span class="keyword">in</span> line:</span><br><span class="line">                        ubuntu_version = line.split(<span class="string">&quot;=&quot;</span>)[<span class="number">1</span>].strip().strip(<span class="string">&#x27;&quot;&#x27;</span>)</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;Ubuntu 版本: <span class="subst">&#123;ubuntu_version&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;无法获取 Ubuntu 版本信息: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Ubuntu 版本: N/A&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Python 版本: <span class="subst">&#123;platform.python_version()&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Conda 虚拟环境: <span class="subst">&#123;os.getenv(<span class="string">&#x27;CONDA_DEFAULT_ENV&#x27;</span>, <span class="string">&#x27;Not in a conda environment&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 PyTorch 和 CUDA 信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pytorch_cuda_info</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;PyTorch 和 CUDA 信息:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 版本: <span class="subst">&#123;torch.__version__&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;CUDA 可用性: <span class="subst">&#123;torch.cuda.is_available()&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;CUDA 版本: <span class="subst">&#123;torch.version.cuda&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;cuDNN 版本: <span class="subst">&#123;torch.backends.cudnn.version()&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;GPU 名称: <span class="subst">&#123;torch.cuda.get_device_name(<span class="number">0</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;CUDA 未启用，请检查 CUDA 安装&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 PyTorch 是否调用了虚拟环境中的版本</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_virtual_env</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在检查是否使用虚拟环境中的 PyTorch 版本...&quot;</span>)</span><br><span class="line">    conda_env = os.getenv(<span class="string">&#x27;CONDA_DEFAULT_ENV&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> conda_env:</span><br><span class="line">        pytorch_path = torch.__file__</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 安装路径: <span class="subst">&#123;pytorch_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> conda_env <span class="keyword">in</span> pytorch_path:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 来自虚拟环境 &#x27;<span class="subst">&#123;conda_env&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;警告: PyTorch 没有来自当前虚拟环境&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未在 Conda 虚拟环境中运行&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 大量图片运算测试函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_computation_test</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始大量图片运算测试...&quot;</span>)</span><br><span class="line">    device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    model = models.resnet50(weights=ResNet50_Weights.DEFAULT).to(device)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用本地图片</span></span><br><span class="line">    img_path = <span class="string">&quot;picture_env_check.jpg&quot;</span>  <span class="comment"># 本地图片的路径</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 图片预处理</span></span><br><span class="line">    preprocess = transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打开图片并处理</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(img_path):</span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">        img_tensor = preprocess(img).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line"></span><br><span class="line">        start_time = time.time()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设置迭代次数模拟大量计算</span></span><br><span class="line">        iterations = <span class="number">8000</span>  <span class="comment"># 修改迭代次数以控制测试的规模</span></span><br><span class="line">        success = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm  <span class="comment"># 在此处导入 tqdm，确保已经安装</span></span><br><span class="line">            <span class="comment"># 使用 tqdm 进度条</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(iterations), desc=<span class="string">&quot;图片运算中&quot;</span>):</span><br><span class="line">                <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                    output = model(img_tensor)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;运算失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            success = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        end_time = time.time()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出结果</span></span><br><span class="line">        <span class="keyword">if</span> success:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;运算结束，处理了 <span class="subst">&#123;iterations&#125;</span> 次图片，耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;运算成功！&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;运算失败&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;图片 &#x27;<span class="subst">&#123;img_path&#125;</span>&#x27; 未找到，请检查路径。&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    install_tqdm()  <span class="comment"># 安装 tqdm</span></span><br><span class="line">    system_info()  <span class="comment"># 输出系统信息</span></span><br><span class="line">    pytorch_cuda_info()  <span class="comment"># 输出 PyTorch 和 CUDA 信息</span></span><br><span class="line">    check_virtual_env()  <span class="comment"># 检查 PyTorch 是否来自虚拟环境</span></span><br><span class="line">    image_computation_test()  <span class="comment"># 运行大量图片运算测试</span></span><br></pre></td></tr></table></figure>



<p><img src="/2024/10/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A3%80%E6%9F%A5cuda_pytorch_nvidia%E5%AE%89%E8%A3%85%E6%83%85%E5%86%B5%E8%84%9A%E6%9C%AC/image-20240929085301281.png" alt="image-20240929085301281"></p>
<h1 id="通用版本"><a href="#通用版本" class="headerlink" title="通用版本"></a>通用版本</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models, transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> ResNet50_Weights</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查并安装 tqdm</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">install_tqdm</span>():</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">import</span> tqdm</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;tqdm 已安装，不需要重复安装。&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> ModuleNotFoundError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;tqdm 未安装，正在使用 pip 自动安装...&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            subprocess.check_call([<span class="string">f&quot;<span class="subst">&#123;os.getenv(<span class="string">&#x27;CONDA_PREFIX&#x27;</span>)&#125;</span>/bin/pip&quot;</span>, <span class="string">&quot;install&quot;</span>, <span class="string">&quot;tqdm&quot;</span>, <span class="string">&quot;-i&quot;</span>, <span class="string">&quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;</span>])</span><br><span class="line">            <span class="keyword">import</span> tqdm  <span class="comment"># 确保安装成功</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;tqdm 安装成功！&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;tqdm 安装失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查系统信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">system_info</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;系统信息:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;操作系统: <span class="subst">&#123;platform.system()&#125;</span> <span class="subst">&#123;platform.release()&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取 Ubuntu 版本</span></span><br><span class="line">    <span class="keyword">if</span> platform.system() == <span class="string">&#x27;Linux&#x27;</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;/etc/os-release&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                    <span class="keyword">if</span> <span class="string">&quot;PRETTY_NAME&quot;</span> <span class="keyword">in</span> line:</span><br><span class="line">                        ubuntu_version = line.split(<span class="string">&quot;=&quot;</span>)[<span class="number">1</span>].strip().strip(<span class="string">&#x27;&quot;&#x27;</span>)</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;Ubuntu 版本: <span class="subst">&#123;ubuntu_version&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;无法获取 Ubuntu 版本信息: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Ubuntu 版本: N/A&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Python 版本: <span class="subst">&#123;platform.python_version()&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Conda 虚拟环境: <span class="subst">&#123;os.getenv(<span class="string">&#x27;CONDA_DEFAULT_ENV&#x27;</span>, <span class="string">&#x27;Not in a conda environment&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 PyTorch 和 CUDA 信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pytorch_cuda_info</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;PyTorch 和 CUDA 信息:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 版本: <span class="subst">&#123;torch.__version__&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;CUDA 可用性: <span class="subst">&#123;torch.cuda.is_available()&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;CUDA 版本: <span class="subst">&#123;torch.version.cuda&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;cuDNN 版本: <span class="subst">&#123;torch.backends.cudnn.version()&#125;</span>&quot;</span>)</span><br><span class="line">        gpu_count = torch.cuda.device_count()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;检测到 <span class="subst">&#123;gpu_count&#125;</span> 个 GPU&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 无论 GPU 数量如何，都打印 GPU 名称</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(gpu_count):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;GPU <span class="subst">&#123;i&#125;</span> 名称: <span class="subst">&#123;torch.cuda.get_device_name(i)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;CUDA 未启用，请检查 CUDA 安装&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 PyTorch 是否调用了虚拟环境中的版本</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_virtual_env</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在检查是否使用虚拟环境中的 PyTorch 版本...&quot;</span>)</span><br><span class="line">    conda_env = os.getenv(<span class="string">&#x27;CONDA_DEFAULT_ENV&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> conda_env:</span><br><span class="line">        pytorch_path = torch.__file__</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 安装路径: <span class="subst">&#123;pytorch_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> conda_env <span class="keyword">in</span> pytorch_path:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 来自虚拟环境 &#x27;<span class="subst">&#123;conda_env&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;警告: PyTorch 没有来自当前虚拟环境&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未在 Conda 虚拟环境中运行&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 大量图片运算测试函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_computation_test</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始大量图片运算测试...&quot;</span>)</span><br><span class="line">    device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 检查 GPU 数量，使用多个 GPU</span></span><br><span class="line">    gpu_count = torch.cuda.device_count()</span><br><span class="line">    <span class="keyword">if</span> gpu_count &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;使用 <span class="subst">&#123;gpu_count&#125;</span> 个 GPU 进行并行运算&quot;</span>)</span><br><span class="line">        model = models.resnet50(weights=ResNet50_Weights.DEFAULT)</span><br><span class="line">        model = nn.DataParallel(model)  <span class="comment"># 使用多个 GPU</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;只有一个 GPU，使用单 GPU 运算&quot;</span>)</span><br><span class="line">        model = models.resnet50(weights=ResNet50_Weights.DEFAULT)</span><br><span class="line">    </span><br><span class="line">    model = model.to(device)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用本地图片</span></span><br><span class="line">    img_path = <span class="string">&quot;picture_env_check.jpg&quot;</span>  <span class="comment"># 本地图片的路径</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 图片预处理</span></span><br><span class="line">    preprocess = transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打开图片并处理</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(img_path):</span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">        img_tensor = preprocess(img).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line"></span><br><span class="line">        start_time = time.time()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设置迭代次数模拟大量计算</span></span><br><span class="line">        iterations = <span class="number">8000</span>  <span class="comment"># 修改迭代次数以控制测试的规模</span></span><br><span class="line">        success = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm  <span class="comment"># 在此处导入 tqdm，确保已经安装</span></span><br><span class="line">            <span class="comment"># 使用 tqdm 进度条</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(iterations), desc=<span class="string">&quot;图片运算中&quot;</span>):</span><br><span class="line">                <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                    output = model(img_tensor)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;运算失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            success = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        end_time = time.time()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出结果</span></span><br><span class="line">        <span class="keyword">if</span> success:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;运算结束，处理了 <span class="subst">&#123;iterations&#125;</span> 次图片，耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;运算成功！&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;运算失败&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;图片 &#x27;<span class="subst">&#123;img_path&#125;</span>&#x27; 未找到，请检查路径。&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    install_tqdm()  <span class="comment"># 安装 tqdm</span></span><br><span class="line">    system_info()  <span class="comment"># 输出系统信息</span></span><br><span class="line">    pytorch_cuda_info()  <span class="comment"># 输出 PyTorch 和 CUDA 信息</span></span><br><span class="line">    check_virtual_env()  <span class="comment"># 检查 PyTorch 是否来自虚拟环境</span></span><br><span class="line">    image_computation_test()  <span class="comment"># 运行大量图片运算测试</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="改动总结："><a href="#改动总结：" class="headerlink" title="改动总结："></a>改动总结：</h2><ul>
<li>在 <code>pytorch_cuda_info</code> 函数中，无论检测到多少 GPU 都会打印 GPU 名称。</li>
<li>其他部分代码保持不变，确保可以在多 GPU 或单 GPU 情况下正常运行。</li>
</ul>
<p>以后如果要在其他脚本中加入类似的逻辑，只需在调用 GPU 相关的地方进行以下调整：</p>
<ol>
<li>使用 <code>torch.cuda.device_count()</code> 检查 GPU 数量。</li>
<li>在需要多个 GPU 并行运算时，使用 <code>nn.DataParallel()</code> 包装模型。</li>
<li>确保在任何情况下都打印出每个 GPU 的名称。</li>
</ol>
<h1 id="多GPU并行计算性能版本"><a href="#多GPU并行计算性能版本" class="headerlink" title="多GPU并行计算性能版本"></a>多GPU并行计算性能版本</h1><h2 id="一、pytorch下的GPU并行计算，举例两个标准方法"><a href="#一、pytorch下的GPU并行计算，举例两个标准方法" class="headerlink" title="一、pytorch下的GPU并行计算，举例两个标准方法"></a>一、pytorch下的GPU并行计算，举例两个标准方法</h2><h3 id="1-torch-multiprocessing-mp"><a href="#1-torch-multiprocessing-mp" class="headerlink" title="1. torch.multiprocessing (mp)"></a>1. <strong><code>torch.multiprocessing</code> (mp)</strong></h3><ul>
<li><strong>优点</strong>：<ul>
<li>支持多进程并行，可以在多个 GPU 上并行处理不同的数据。</li>
<li>每个进程有独立的 Python 解释器，这意味着每个进程可以独立地加载模型和数据，避免了全局解释器锁（GIL）的影响。</li>
<li>可以利用 NVIDIA NCCL 后端实现高效的跨 GPU 通信。</li>
</ul>
</li>
<li><strong>缺点</strong>：<ul>
<li>启动和管理多个进程的开销可能相对较高，特别是在小规模任务中。</li>
<li>需要处理进程间的通信，可能会增加代码的复杂性。</li>
</ul>
</li>
</ul>
<h3 id="2-Data-Parallelism数据并行-ddp"><a href="#2-Data-Parallelism数据并行-ddp" class="headerlink" title="2. Data Parallelism数据并行 (ddp)"></a>2. <strong>Data Parallelism数据并行 (ddp)</strong></h3><ul>
<li>使用 <code>torch.nn.DataParallel</code> 或 <code>torch.nn.parallel.DistributedDataParallel</code> 实现数据并行。</li>
<li><strong>优点</strong>：<ul>
<li><code>DataParallel</code> 在多个 GPU 上并行计算每个 mini-batch 的损失和梯度，使用简单。</li>
<li><code>DistributedDataParallel</code> 更加高效，适合大规模分布式训练，减少了跨 GPU 的通信开销。</li>
</ul>
</li>
<li><strong>缺点</strong>：<ul>
<li>在小型模型或小批量数据时，可能不会看到显著的性能提升。</li>
<li>在某些情况下，<code>DataParallel</code> 的效率较低，因为它在主 GPU 上聚合梯度，可能成为瓶颈。</li>
</ul>
</li>
</ul>
<h2 id="二、mp-精简逻辑"><a href="#二、mp-精简逻辑" class="headerlink" title="二、mp-精简逻辑"></a>二、mp-精简逻辑</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">import</span> torch.multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">setup_ddp</span>(<span class="params">rank, world_size</span>):</span><br><span class="line">    os.environ[<span class="string">&#x27;MASTER_ADDR&#x27;</span>] = <span class="string">&#x27;localhost&#x27;</span>  <span class="comment"># 在本机运行。</span></span><br><span class="line">    os.environ[<span class="string">&#x27;MASTER_PORT&#x27;</span>] = <span class="string">&#x27;12355&#x27;</span>      <span class="comment"># 可以自己换端口，保证用一个空闲端口就行。</span></span><br><span class="line">    dist.init_process_group(<span class="string">&quot;nccl&quot;</span>, rank=rank, world_size=world_size)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computation_function</span>(<span class="params">rank, world_size</span>):     </span><br><span class="line">    setup_ddp(rank, world_size)</span><br><span class="line">    <span class="comment"># 这里可以放置模型训练或推理的逻辑</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;rank&#125;</span> 正在执行计算逻辑。&quot;</span>)</span><br><span class="line">    <span class="comment"># 其他计算逻辑...</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    world_size = <span class="number">4</span>  <span class="comment"># 假设有4个进程</span></span><br><span class="line">    mp.spawn(computation_function, args=(world_size,), nprocs=world_size, join=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>**<code>setup_ddp</code>**：设置分布式处理环境。</p>
<p>rank在多个方法中传递并标识，在的计算方法调用 setup_ddp 来进行环境设置，mp.spawn会自动生成一个rank到 计算方法中。这样就能确保每个进程都能正确地进行分布式计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">setup_ddp</span>(<span class="params">rank, world_size</span>):</span><br><span class="line">    os.environ[<span class="string">&#x27;MASTER_ADDR&#x27;</span>] = <span class="string">&#x27;localhost&#x27;</span></span><br><span class="line">    os.environ[<span class="string">&#x27;MASTER_PORT&#x27;</span>] = <span class="string">&#x27;12355&#x27;</span></span><br><span class="line">    dist.init_process_group(<span class="string">&quot;nccl&quot;</span>, rank=rank, world_size=world_size)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computation</span>(<span class="params">rank, world_size, elapsed_times, img_paths</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;具体计算函数，替换为所需的计算逻辑&quot;&quot;&quot;</span></span><br><span class="line">    setup_ddp(rank, world_size)</span><br><span class="line">    start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理分配给该进程的图片</span></span><br><span class="line">    <span class="keyword">for</span> img_path <span class="keyword">in</span> img_paths:</span><br><span class="line">        <span class="comment"># 这里添加处理逻辑，例如加载图片并进行计算</span></span><br><span class="line">        <span class="keyword">pass</span>  <span class="comment"># 替换为你的计算逻辑</span></span><br><span class="line"></span><br><span class="line">    elapsed_times[rank] = time.time() - start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;rank&#125;</span> 耗时: <span class="subst">&#123;elapsed_times[rank]:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">start_multiprocessing</span>(<span class="params">computation_func, img_paths</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;启动多进程并行计算&quot;&quot;&quot;</span></span><br><span class="line">    world_size = torch.cuda.device_count()</span><br><span class="line">    elapsed_times = mp.Manager().<span class="built_in">list</span>([<span class="number">0</span>] * world_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 任务划分</span></span><br><span class="line">    images_per_rank = <span class="built_in">len</span>(img_paths) // world_size</span><br><span class="line">    extra_images = <span class="built_in">len</span>(img_paths) % world_size</span><br><span class="line">    image_lists = [img_paths[i * images_per_rank + <span class="built_in">min</span>(i, extra_images):(i + <span class="number">1</span>) * images_per_rank + <span class="built_in">min</span>(i + <span class="number">1</span>, extra_images)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(world_size)]</span><br><span class="line"></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    mp.spawn(computation_func, args=(world_size, elapsed_times, image_lists), nprocs=world_size, join=<span class="literal">True</span>)</span><br><span class="line">    end_time = time.time()</span><br><span class="line"></span><br><span class="line">    total_time = <span class="built_in">sum</span>(elapsed_times)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;总共实际耗时: <span class="subst">&#123;end_time - start_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;所有 GPU 总共耗时: <span class="subst">&#123;total_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 示例图片路径列表</span></span><br><span class="line">    img_paths = [<span class="string">&quot;image1.jpg&quot;</span>, <span class="string">&quot;image2.jpg&quot;</span>, <span class="string">&quot;image3.jpg&quot;</span>, <span class="string">&quot;image4.jpg&quot;</span>]  <span class="comment"># 你可以根据需要填充图片路径</span></span><br><span class="line">    start_multiprocessing(computation, img_paths)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>mp.spawn</code> 是 PyTorch 的多进程模块提供的一个函数，用于方便地启动多个子进程（workers）。这个函数会为每个子进程调用指定的目标函数，并传递相应的参数。</li>
</ul>
<p><strong><code>args=(world_size, elapsed_times) + args</code></strong>:</p>
<ul>
<li><p>这个参数定义了要传递给 <code>computation_func</code></p>
<p> 的参数。它由几个部分组成：</p>
<ul>
<li>**<code>world_size</code>**：当前可用的 GPU 数量，作为第一个参数传递给 <code>computation_func</code>。</li>
<li>**<code>elapsed_times</code>**：共享的列表，用于存储每个进程的计算耗时，也是作为第二个参数传递。</li>
<li>**<code>+ args</code>**：<code>args</code> 是一个可变参数列表，代表在调用 <code>start_multiprocessing</code> 时传递给函数的任何额外参数。这些参数会被附加到 <code>world_size</code> 和 <code>elapsed_times</code> 之后一起传递给 <code>computation_func</code>。</li>
</ul>
</li>
</ul>
<p><strong><code>nprocs=world_size</code></strong>:</p>
<ul>
<li>这个参数指定要启动的子进程数量。通常，<code>world_size</code> 是可用 GPU 的数量，所以这个参数表示我们希望在每个可用的 GPU 上启动一个进程，从而实现并行处理。</li>
</ul>
<p><strong><code>join=True</code></strong>:</p>
<ul>
<li>这个参数控制 <code>mp.spawn</code> 的行为。当设置为 <code>True</code> 时，主进程会等待所有的子进程完成后再继续执行后续代码。如果设置为 <code>False</code>，主进程将不会等待子进程的完成。</li>
<li>一般来说，建议设置为 <code>True</code>，以确保主进程在所有子进程完成后再进行后续处理，比如计算总耗时等。</li>
</ul>
<h2 id="三、mp-可用代码"><a href="#三、mp-可用代码" class="headerlink" title="三、mp-可用代码"></a>三、mp-可用代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">import</span> torch.multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models, transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> ResNet50_Weights</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查并安装 tqdm</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">install_tqdm</span>():</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">import</span> tqdm</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;tqdm 已安装，不需要重复安装。&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> ModuleNotFoundError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;tqdm 未安装，正在使用 pip 自动安装...&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            subprocess.check_call([<span class="string">f&quot;<span class="subst">&#123;os.getenv(<span class="string">&#x27;CONDA_PREFIX&#x27;</span>)&#125;</span>/bin/pip&quot;</span>, <span class="string">&quot;install&quot;</span>, <span class="string">&quot;tqdm&quot;</span>, <span class="string">&quot;-i&quot;</span>, <span class="string">&quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;</span>])</span><br><span class="line">            <span class="keyword">import</span> tqdm</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;tqdm 安装成功！&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;tqdm 安装失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查系统信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">system_info</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;系统信息:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;操作系统: <span class="subst">&#123;platform.system()&#125;</span> <span class="subst">&#123;platform.release()&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> platform.system() == <span class="string">&#x27;Linux&#x27;</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;/etc/os-release&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                    <span class="keyword">if</span> <span class="string">&quot;PRETTY_NAME&quot;</span> <span class="keyword">in</span> line:</span><br><span class="line">                        ubuntu_version = line.split(<span class="string">&quot;=&quot;</span>)[<span class="number">1</span>].strip().strip(<span class="string">&#x27;&quot;&#x27;</span>)</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;Ubuntu 版本: <span class="subst">&#123;ubuntu_version&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;无法获取 Ubuntu 版本信息: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Ubuntu 版本: N/A&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Python 版本: <span class="subst">&#123;platform.python_version()&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Conda 虚拟环境: <span class="subst">&#123;os.getenv(<span class="string">&#x27;CONDA_DEFAULT_ENV&#x27;</span>, <span class="string">&#x27;Not in a conda environment&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 PyTorch 和 CUDA 信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pytorch_cuda_info</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;PyTorch 和 CUDA 信息:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 版本: <span class="subst">&#123;torch.__version__&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;CUDA 可用性: <span class="subst">&#123;torch.cuda.is_available()&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;CUDA 版本: <span class="subst">&#123;torch.version.cuda&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;cuDNN 版本: <span class="subst">&#123;torch.backends.cudnn.version()&#125;</span>&quot;</span>)</span><br><span class="line">        gpu_count = torch.cuda.device_count()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;检测到 <span class="subst">&#123;gpu_count&#125;</span> 个 GPU&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(gpu_count):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;GPU <span class="subst">&#123;i&#125;</span> 名称: <span class="subst">&#123;torch.cuda.get_device_name(i)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;CUDA 未启用，请检查 CUDA 安装&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 PyTorch 是否调用了虚拟环境中的版本</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_virtual_env</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在检查是否使用虚拟环境中的 PyTorch 版本...&quot;</span>)</span><br><span class="line">    conda_env = os.getenv(<span class="string">&#x27;CONDA_DEFAULT_ENV&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> conda_env:</span><br><span class="line">        pytorch_path = torch.__file__</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 安装路径: <span class="subst">&#123;pytorch_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> conda_env <span class="keyword">in</span> pytorch_path:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 来自虚拟环境 &#x27;<span class="subst">&#123;conda_env&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;警告: PyTorch 没有来自当前虚拟环境&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未在 Conda 虚拟环境中运行&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 DDP</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">setup_ddp</span>(<span class="params">rank, world_size</span>):</span><br><span class="line">    os.environ[<span class="string">&#x27;MASTER_ADDR&#x27;</span>] = <span class="string">&#x27;localhost&#x27;</span></span><br><span class="line">    os.environ[<span class="string">&#x27;MASTER_PORT&#x27;</span>] = <span class="string">&#x27;12355&#x27;</span></span><br><span class="line">    dist.init_process_group(<span class="string">&quot;nccl&quot;</span>, rank=rank, world_size=world_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 任务划分</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">divide_images</span>(<span class="params">img_paths, world_size</span>):</span><br><span class="line">    total_images = <span class="built_in">len</span>(img_paths)</span><br><span class="line">    base_count = total_images // world_size</span><br><span class="line">    extra_count = total_images % world_size</span><br><span class="line">    </span><br><span class="line">    image_lists = []</span><br><span class="line">    start_index = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(world_size):</span><br><span class="line">        <span class="comment"># 每个 GPU 分配基本数量 + 可能的额外图片</span></span><br><span class="line">        end_index = start_index + base_count + (<span class="number">1</span> <span class="keyword">if</span> i &lt; extra_count <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">        image_lists.append(img_paths[start_index:end_index])</span><br><span class="line">        start_index = end_index</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> image_lists</span><br><span class="line"></span><br><span class="line"><span class="comment"># 大量图片运算测试函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_computation_test</span>(<span class="params">rank, world_size, img_paths, elapsed_times</span>):</span><br><span class="line">    setup_ddp(rank, world_size)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;rank&#125;</span>/<span class="subst">&#123;world_size&#125;</span> 开始工作...&quot;</span>)</span><br><span class="line">    device = <span class="string">f&quot;cuda:<span class="subst">&#123;rank&#125;</span>&quot;</span>  <span class="comment"># 每个进程使用不同的 GPU</span></span><br><span class="line">    </span><br><span class="line">    model = models.resnet50(weights=ResNet50_Weights.DEFAULT).to(device)</span><br><span class="line">    model = nn.parallel.DistributedDataParallel(model, device_ids=[rank])</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 图片预处理</span></span><br><span class="line">    preprocess = transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分配给当前 rank 的图片</span></span><br><span class="line">    assigned_images = img_paths[rank]  <span class="comment"># 从分配的图片列表中获取</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> img_path <span class="keyword">in</span> assigned_images:</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(img_path):</span><br><span class="line">            img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">            img_tensor = preprocess(img).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 设置迭代次数模拟大量计算</span></span><br><span class="line">            iterations = <span class="number">8000</span></span><br><span class="line">            success = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(iterations), desc=<span class="string">f&quot;处理 <span class="subst">&#123;img_path&#125;</span>&quot;</span>):</span><br><span class="line">                    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                        output = model(img_tensor)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;运算失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">                success = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> success:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;rank&#125;</span> 运算结束，处理了 <span class="subst">&#123;iterations&#125;</span> 次图片 &#x27;<span class="subst">&#123;img_path&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;rank&#125;</span> 图片 &#x27;<span class="subst">&#123;img_path&#125;</span>&#x27; 运算失败&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;图片 &#x27;<span class="subst">&#123;img_path&#125;</span>&#x27; 未找到，请检查路径。&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    elapsed = time.time() - start_time</span><br><span class="line">    elapsed_times[rank] = elapsed</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;rank&#125;</span> 总耗时: <span class="subst">&#123;elapsed:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动多进程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">start_multiprocessing</span>():</span><br><span class="line">    world_size = torch.cuda.device_count()</span><br><span class="line">    <span class="keyword">if</span> world_size &lt; <span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;没有可用的 GPU，退出。&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;可用 GPU 数量: <span class="subst">&#123;world_size&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    img_paths = glob.glob(<span class="string">&quot;*.jpg&quot;</span>) + glob.glob(<span class="string">&quot;*.png&quot;</span>)  <span class="comment"># 获取所有图片</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> img_paths:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;没有找到任何图片，请检查路径。&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将图片划分为每个进程的任务</span></span><br><span class="line">    image_lists = divide_images(img_paths, world_size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建一个共享列表来存储每个进程的耗时</span></span><br><span class="line">    elapsed_times = mp.Manager().<span class="built_in">list</span>([<span class="number">0</span>] * world_size)</span><br><span class="line">    </span><br><span class="line">    start_time = time.time()  <span class="comment"># 记录并行计算开始时间</span></span><br><span class="line">    mp.spawn(image_computation_test, args=(world_size, image_lists, elapsed_times), nprocs=world_size, join=<span class="literal">True</span>)</span><br><span class="line">    end_time = time.time()  <span class="comment"># 记录并行计算结束时间</span></span><br><span class="line"></span><br><span class="line">    total_time = <span class="built_in">sum</span>(elapsed_times)</span><br><span class="line">    parallel_elapsed_time = end_time - start_time  <span class="comment"># 计算并行计算的耗时</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n并行计算耗时: <span class="subst">&#123;parallel_elapsed_time:<span class="number">.2</span>f&#125;</span> 秒，（若仅有一个GPU，仅看Rank耗时即可，此项统计可忽略。）&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;所有 GPU 总共耗时: <span class="subst">&#123;total_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> rank, elapsed <span class="keyword">in</span> <span class="built_in">enumerate</span>(elapsed_times):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;rank&#125;</span> 耗时: <span class="subst">&#123;elapsed:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line"></span><br><span class="line">    total_elapsed_time = end_time - start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n总共实际耗时: <span class="subst">&#123;total_elapsed_time:<span class="number">.2</span>f&#125;</span> 秒； （若仅有一个GPU，仅看Rank耗时即可，此项统计可忽略。）&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    install_tqdm()  <span class="comment"># 安装 tqdm</span></span><br><span class="line">    system_info()  <span class="comment"># 输出系统信息</span></span><br><span class="line">    pytorch_cuda_info()  <span class="comment"># 输出 PyTorch 和 CUDA 信息</span></span><br><span class="line">    check_virtual_env()  <span class="comment"># 检查 PyTorch 是否来自虚拟环境</span></span><br><span class="line">    </span><br><span class="line">    start_multiprocessing()  <span class="comment"># 启动多进程运算</span></span><br></pre></td></tr></table></figure>



<h2 id="四、ddp精简逻辑"><a href="#四、ddp精简逻辑" class="headerlink" title="四、ddp精简逻辑"></a>四、ddp精简逻辑</h2><p>以下是精简的 DDP 结构示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">import</span> torch.multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel <span class="keyword">as</span> DDP</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, DistributedSampler, TensorDataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化分布式训练环境</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">setup</span>(<span class="params">rank, world_size</span>):</span><br><span class="line">    os.environ[<span class="string">&#x27;MASTER_ADDR&#x27;</span>] = <span class="string">&#x27;localhost&#x27;</span></span><br><span class="line">    os.environ[<span class="string">&#x27;MASTER_PORT&#x27;</span>] = <span class="string">&#x27;12355&#x27;</span></span><br><span class="line">    dist.init_process_group(<span class="string">&quot;nccl&quot;</span>, rank=rank, world_size=world_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 销毁进程组</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cleanup</span>():</span><br><span class="line">    dist.destroy_process_group()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型（替换成你自己的模型）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_model</span>():</span><br><span class="line">    <span class="keyword">return</span> nn.Linear(<span class="number">10</span>, <span class="number">2</span>)  <span class="comment"># 简单线性层示例</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义数据加载（替换成你自己的数据加载逻辑）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataloader</span>(<span class="params">rank, world_size</span>):</span><br><span class="line">    data = torch.randn(<span class="number">1000</span>, <span class="number">10</span>)  <span class="comment"># 假设 1000 个样本，每个 10 个特征</span></span><br><span class="line">    labels = torch.randint(<span class="number">0</span>, <span class="number">2</span>, (<span class="number">1000</span>,))  <span class="comment"># 假设二分类</span></span><br><span class="line">    dataset = TensorDataset(data, labels)</span><br><span class="line">    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)</span><br><span class="line">    <span class="keyword">return</span> DataLoader(dataset, batch_size=<span class="number">32</span>, sampler=sampler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练逻辑（替换成你自己的训练逻辑）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">rank, world_size</span>):</span><br><span class="line">    setup(rank, world_size)</span><br><span class="line">    device = torch.device(<span class="string">f&quot;cuda:<span class="subst">&#123;rank&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化模型和数据</span></span><br><span class="line">    model = create_model().to(device)</span><br><span class="line">    model = DDP(model, device_ids=[rank])</span><br><span class="line">    dataloader = create_dataloader(rank, world_size)</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练循环</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># 假设 5 个训练轮次</span></span><br><span class="line">        <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloader:</span><br><span class="line">            inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;rank&#125;</span>, Epoch <span class="subst">&#123;epoch&#125;</span>, Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    cleanup()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动多进程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    world_size = torch.cuda.device_count()</span><br><span class="line">    mp.spawn(train, args=(world_size,), nprocs=world_size, join=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h3 id="模块化的逻辑说明"><a href="#模块化的逻辑说明" class="headerlink" title="模块化的逻辑说明"></a>模块化的逻辑说明</h3><ol>
<li>**<code>setup</code> 和 <code>cleanup</code>**：用于初始化和销毁分布式进程组。</li>
<li>**<code>create_model</code>**：定义模型结构，直接替换成你自己的模型。</li>
<li>**<code>create_dataloader</code>**：创建数据加载器，使用 <code>DistributedSampler</code> 确保每个进程获得数据的不同部分。</li>
<li>**<code>train</code>**：封装训练逻辑。模型、数据、损失函数和优化器定义在此函数中。训练代码逻辑直接可以替换。</li>
</ol>
<p>这个结构方便修改模型和数据加载逻辑，同时保留 DDP 的核心初始化和训练逻辑。</p>
<p>以下是 DDP 在代码中的核心环节，以及实现效果的关键代码讲解：</p>
<h3 id="1-初始化分布式进程-setup-函数"><a href="#1-初始化分布式进程-setup-函数" class="headerlink" title="1. 初始化分布式进程 (setup 函数)"></a>1. 初始化分布式进程 (<code>setup</code> 函数)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">setup</span>(<span class="params">rank, world_size</span>):</span><br><span class="line">    os.environ[<span class="string">&#x27;MASTER_ADDR&#x27;</span>] = <span class="string">&#x27;localhost&#x27;</span>      <span class="comment"># 设置主节点地址</span></span><br><span class="line">    os.environ[<span class="string">&#x27;MASTER_PORT&#x27;</span>] = <span class="string">&#x27;12355&#x27;</span>          <span class="comment"># 设置主节点端口</span></span><br><span class="line">    dist.init_process_group(<span class="string">&quot;nccl&quot;</span>, rank=rank, world_size=world_size)  <span class="comment"># 初始化进程组</span></span><br></pre></td></tr></table></figure>

<ul>
<li>**<code>MASTER_ADDR</code> 和 <code>MASTER_PORT</code>**：指定主进程的地址和端口，以便所有 GPU 进程能通过这个主节点进行通信。这里设置为本地通信（<code>localhost</code>），适合单机多卡情况。</li>
<li>**<code>dist.init_process_group</code>**：初始化分布式进程组，指定使用 <code>&quot;nccl&quot;</code> 后端（针对 GPU 的高效通信框架）。这个过程会在每个 GPU 上创建一个进程，参与模型的同步。</li>
</ul>
<blockquote>
<p><strong>作用</strong>：在 DDP 中，必须在每个 GPU 进程上初始化一个分布式进程组。<code>nccl</code> 能更高效地处理 GPU 间通信。</p>
</blockquote>
<h3 id="2-模型的分布式封装-DDP-包装模型"><a href="#2-模型的分布式封装-DDP-包装模型" class="headerlink" title="2. 模型的分布式封装 (DDP 包装模型)"></a>2. 模型的分布式封装 (<code>DDP</code> 包装模型)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">f&quot;cuda:<span class="subst">&#123;rank&#125;</span>&quot;</span>)</span><br><span class="line">model = create_model().to(device)</span><br><span class="line">model = DDP(model, device_ids=[rank])</span><br></pre></td></tr></table></figure>

<ul>
<li>**<code>to(device)</code>**：将模型移到指定的 GPU 上，确保每个进程在特定的 GPU（由 <code>rank</code> 指定）上执行。</li>
<li>**<code>DDP(model, device_ids=[rank])</code>**：通过 <code>DDP</code> 封装模型，以便在训练过程中自动处理梯度同步。每次反向传播后，DDP 会自动在每个 GPU 进程之间同步梯度。</li>
</ul>
<blockquote>
<p><strong>作用</strong>：封装后的模型会在每个 GPU 之间自动同步参数。每次 <code>backward()</code> 调用时，DDP 会收集所有 GPU 的梯度并计算平均值，再将平均后的梯度分发到每个 GPU，确保模型参数在所有设备上一致。</p>
</blockquote>
<h3 id="3-数据并行化-DistributedSampler"><a href="#3-数据并行化-DistributedSampler" class="headerlink" title="3. 数据并行化 (DistributedSampler)"></a>3. 数据并行化 (<code>DistributedSampler</code>)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">32</span>, sampler=sampler)</span><br></pre></td></tr></table></figure>

<ul>
<li>**<code>DistributedSampler</code>**：数据加载器的采样器，确保每个 GPU 进程读取数据集的不同部分，避免数据重复。</li>
<li>**<code>num_replicas=world_size</code>**：指定进程数量，保证数据集分配给所有进程。</li>
<li>**<code>rank=rank</code>**：指定当前进程的 GPU ID，使每个 GPU 加载不同的样本。</li>
</ul>
<blockquote>
<p><strong>作用</strong>：确保每个进程处理数据集的不同部分，从而充分利用多 GPU 资源。同时避免多 GPU 处理相同数据的重复计算。</p>
</blockquote>
<h3 id="4-自动梯度同步和参数更新"><a href="#4-自动梯度同步和参数更新" class="headerlink" title="4. 自动梯度同步和参数更新"></a>4. 自动梯度同步和参数更新</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloader:</span><br><span class="line">    inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()   <span class="comment"># 自动同步梯度</span></span><br><span class="line">    optimizer.step()   <span class="comment"># 参数更新</span></span><br></pre></td></tr></table></figure>

<ul>
<li>**<code>loss.backward()</code>**：反向传播时，DDP 会自动将各 GPU 进程的梯度同步并计算平均值。每个 GPU 上的模型参数通过梯度更新保持一致。</li>
<li>**<code>optimizer.step()</code>**：在所有进程中执行参数更新，确保下一步前参数保持同步。</li>
</ul>
<blockquote>
<p><strong>作用</strong>：在反向传播的同时完成梯度同步，确保各个 GPU 进程的模型更新一致，实现真正的分布式数据并行。</p>
</blockquote>
<h3 id="5-结束分布式训练-cleanup"><a href="#5-结束分布式训练-cleanup" class="headerlink" title="5. 结束分布式训练 (cleanup)"></a>5. 结束分布式训练 (<code>cleanup</code>)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cleanup</span>():</span><br><span class="line">    dist.destroy_process_group()</span><br></pre></td></tr></table></figure>

<ul>
<li>**<code>dist.destroy_process_group()</code>**：销毁进程组，释放 GPU 资源，结束分布式训练。</li>
</ul>
<blockquote>
<p><strong>作用</strong>：在训练完成后清理资源，避免 GPU 资源占用或潜在的内存泄漏。</p>
</blockquote>
<h1 id="一个我经常用的例子"><a href="#一个我经常用的例子" class="headerlink" title="一个我经常用的例子"></a>一个我经常用的例子</h1><p>这个是做 环境部署和GPU性能检测的。<img src="/2024/10/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A3%80%E6%9F%A5cuda_pytorch_nvidia%E5%AE%89%E8%A3%85%E6%83%85%E5%86%B5%E8%84%9A%E6%9C%AC/ddp.jpg" alt="ddp"></p>
<p><code>ddp5_env_check.py</code>  </p>
<blockquote>
<p>他会检测 驱动 torch conda等情况，并用此脚本文件夹中图片做多GPU测试。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">import</span> torch.multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models, transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> ResNet50_Weights</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="comment"># from tqdm import tqdm</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader, DistributedSampler</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查并安装 tqdm</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">install_tqdm</span>():</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">import</span> tqdm</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;tqdm 已安装，不需要重复安装。&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> ModuleNotFoundError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;tqdm 未安装，正在使用 pip 自动安装...&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            subprocess.check_call([<span class="string">f&quot;<span class="subst">&#123;os.getenv(<span class="string">&#x27;CONDA_PREFIX&#x27;</span>)&#125;</span>/bin/pip&quot;</span>, <span class="string">&quot;install&quot;</span>, <span class="string">&quot;tqdm&quot;</span>, <span class="string">&quot;-i&quot;</span>, <span class="string">&quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;</span>])</span><br><span class="line">            <span class="keyword">import</span> tqdm</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;tqdm 安装成功！&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;tqdm 安装失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查系统信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">system_info</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;系统信息:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;操作系统: <span class="subst">&#123;platform.system()&#125;</span> <span class="subst">&#123;platform.release()&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> platform.system() == <span class="string">&#x27;Linux&#x27;</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;/etc/os-release&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                    <span class="keyword">if</span> <span class="string">&quot;PRETTY_NAME&quot;</span> <span class="keyword">in</span> line:</span><br><span class="line">                        ubuntu_version = line.split(<span class="string">&quot;=&quot;</span>)[<span class="number">1</span>].strip().strip(<span class="string">&#x27;&quot;&#x27;</span>)</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;Ubuntu 版本: <span class="subst">&#123;ubuntu_version&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;无法获取 Ubuntu 版本信息: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Ubuntu 版本: N/A&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Python 版本: <span class="subst">&#123;platform.python_version()&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Conda 虚拟环境: <span class="subst">&#123;os.getenv(<span class="string">&#x27;CONDA_DEFAULT_ENV&#x27;</span>, <span class="string">&#x27;Not in a conda environment&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 PyTorch 和 CUDA 信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pytorch_cuda_info</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;PyTorch 和 CUDA 信息:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 版本: <span class="subst">&#123;torch.__version__&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;CUDA 可用性: <span class="subst">&#123;torch.cuda.is_available()&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;CUDA 版本: <span class="subst">&#123;torch.version.cuda&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;cuDNN 版本: <span class="subst">&#123;torch.backends.cudnn.version()&#125;</span>&quot;</span>)</span><br><span class="line">        gpu_count = torch.cuda.device_count()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;检测到 <span class="subst">&#123;gpu_count&#125;</span> 个 GPU&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(gpu_count):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;GPU <span class="subst">&#123;i&#125;</span> 名称: <span class="subst">&#123;torch.cuda.get_device_name(i)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;CUDA 未启用，请检查 CUDA 安装&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 PyTorch 是否调用了虚拟环境中的版本</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_virtual_env</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在检查是否使用虚拟环境中的 PyTorch 版本...&quot;</span>)</span><br><span class="line">    conda_env = os.getenv(<span class="string">&#x27;CONDA_DEFAULT_ENV&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> conda_env:</span><br><span class="line">        pytorch_path = torch.__file__</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 安装路径: <span class="subst">&#123;pytorch_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> conda_env <span class="keyword">in</span> pytorch_path:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;PyTorch 来自虚拟环境 &#x27;<span class="subst">&#123;conda_env&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;警告: PyTorch 没有来自当前虚拟环境&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未在 Conda 虚拟环境中运行&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ImageDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_paths, transform</span>):</span><br><span class="line">        self.img_paths = img_paths</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_paths)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        img_path = self.img_paths[idx]</span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line">        <span class="keyword">return</span> img, img_path</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_computation_test</span>(<span class="params">local_rank, args</span>):</span><br><span class="line">    <span class="comment"># 初始化进程组</span></span><br><span class="line">    torch.cuda.set_device(local_rank)</span><br><span class="line">    dist.init_process_group(backend=<span class="string">&quot;nccl&quot;</span>, </span><br><span class="line">                          init_method=<span class="string">f&quot;env://&quot;</span>,</span><br><span class="line">                          world_size=args.n_gpus,</span><br><span class="line">                          rank=local_rank)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;local_rank&#125;</span>/<span class="subst">&#123;args.n_gpus&#125;</span> 开始工作...&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化模型</span></span><br><span class="line">    model = models.resnet50(weights=ResNet50_Weights.DEFAULT).cuda(local_rank)</span><br><span class="line">    model = nn.parallel.DistributedDataParallel(model, device_ids=[local_rank])</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 图片预处理</span></span><br><span class="line">    preprocess = transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建数据集和数据加载器</span></span><br><span class="line">    dataset = ImageDataset(args.img_paths, preprocess)</span><br><span class="line">    sampler = DistributedSampler(dataset)</span><br><span class="line">    dataloader = DataLoader(dataset, </span><br><span class="line">                          batch_size=args.batch_size,</span><br><span class="line">                          sampler=sampler,</span><br><span class="line">                          num_workers=args.num_workers,</span><br><span class="line">                          pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="keyword">if</span> local_rank == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;\nEpoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;args.epochs&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        sampler.set_epoch(epoch)  <span class="comment"># 确保每个epoch的数据顺序不同</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> img_tensor, img_path <span class="keyword">in</span> dataloader:</span><br><span class="line">            img_tensor = img_tensor.cuda(local_rank)</span><br><span class="line">            iterations = args.iterations</span><br><span class="line">            success = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(iterations), </span><br><span class="line">                            desc=<span class="string">f&quot;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>, 处理 <span class="subst">&#123;img_path[<span class="number">0</span>]&#125;</span>&quot;</span>, </span><br><span class="line">                            disable=local_rank!=<span class="number">0</span>):</span><br><span class="line">                    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                        output = model(img_tensor)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;运算失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">                success = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> success:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;local_rank&#125;</span> 运算结束，处理了 <span class="subst">&#123;iterations&#125;</span> 次图片 &#x27;<span class="subst">&#123;img_path[<span class="number">0</span>]&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;local_rank&#125;</span> 图片 &#x27;<span class="subst">&#123;img_path[<span class="number">0</span>]&#125;</span>&#x27; 运算失败&quot;</span>)</span><br><span class="line"></span><br><span class="line">    elapsed = time.time() - start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;local_rank&#125;</span> 总耗时: <span class="subst">&#123;elapsed:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 同步所有进程的时间</span></span><br><span class="line">    elapsed_tensor = torch.tensor([elapsed], device=<span class="string">f&quot;cuda:<span class="subst">&#123;local_rank&#125;</span>&quot;</span>)</span><br><span class="line">    gathered_times = [torch.zeros_like(elapsed_tensor) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_gpus)]</span><br><span class="line">    dist.all_gather(gathered_times, elapsed_tensor)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> local_rank == <span class="number">0</span>:</span><br><span class="line">        total_time = <span class="built_in">sum</span>(t.item() <span class="keyword">for</span> t <span class="keyword">in</span> gathered_times)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n并行计算耗时: <span class="subst">&#123;elapsed:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;所有 GPU 总共耗时: <span class="subst">&#123;total_time:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> rank, time_val <span class="keyword">in</span> <span class="built_in">enumerate</span>(gathered_times):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Rank <span class="subst">&#123;rank&#125;</span> 耗时: <span class="subst">&#123;time_val.item():<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n总共实际耗时: <span class="subst">&#123;elapsed:<span class="number">.2</span>f&#125;</span> 秒&quot;</span>)</span><br><span class="line"></span><br><span class="line">    dist.destroy_process_group()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;多GPU分布式图像处理测试&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分布式训练相关参数</span></span><br><span class="line">    <span class="comment"># parser.add_argument(&#x27;--local_rank&#x27;, type=int, default=-1,</span></span><br><span class="line">    <span class="comment">#                     help=&#x27;DDP参数，由torch.distributed.launch自动传入&#x27;)</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--n_gpus&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;使用的GPU数量&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 数据加载相关参数</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;每个GPU的batch size&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_workers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;数据加载的worker数量&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 训练相关参数</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;运行的epoch数量&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--iterations&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8000</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;每张图片的处理迭代次数&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 其他参数</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--seed&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">42</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;随机种子&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    args.local_rank = <span class="built_in">int</span>(os.environ[<span class="string">&quot;LOCAL_RANK&quot;</span>])   <span class="comment"># 将环境变量中的 local_rank 添加到 args</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置随机种子</span></span><br><span class="line">    torch.manual_seed(args.seed)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        torch.cuda.manual_seed_all(args.seed)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.local_rank == <span class="number">0</span>:</span><br><span class="line">        install_tqdm()</span><br><span class="line">        system_info()</span><br><span class="line">        pytorch_cuda_info()</span><br><span class="line">        check_virtual_env()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> torch.cuda.is_available():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;没有可用的 GPU，退出。&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.local_rank == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;使用 GPU 数量: <span class="subst">&#123;args.n_gpus&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取所有图片路径</span></span><br><span class="line">    img_paths = glob.glob(<span class="string">&quot;*.jpg&quot;</span>) + glob.glob(<span class="string">&quot;*.png&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> img_paths:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;没有找到任何图片，请检查路径。&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    args.img_paths = img_paths</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 运行计算测试</span></span><br><span class="line">    image_computation_test(args.local_rank, args)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">【使用方法】</span></span><br><span class="line"><span class="string">(淘汰)</span></span><br><span class="line"><span class="string">python -m torch.distributed.launch \</span></span><br><span class="line"><span class="string">    --nproc_per_node=4 \</span></span><br><span class="line"><span class="string">    --master_port=29500 \</span></span><br><span class="line"><span class="string">    script_name.py \</span></span><br><span class="line"><span class="string">    --n_gpus=4 \</span></span><br><span class="line"><span class="string">    --batch_size=32 \</span></span><br><span class="line"><span class="string">    --epochs=10 \</span></span><br><span class="line"><span class="string">    --num_workers=4 \</span></span><br><span class="line"><span class="string">    --iterations=8000</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">torchrun \</span></span><br><span class="line"><span class="string">    --nproc_per_node=4 \</span></span><br><span class="line"><span class="string">    --master_port=29500 \</span></span><br><span class="line"><span class="string">    script_name.py \</span></span><br><span class="line"><span class="string">    --n_gpus=4 \</span></span><br><span class="line"><span class="string">    --batch_size=32 \</span></span><br><span class="line"><span class="string">    --epochs=10 \</span></span><br><span class="line"><span class="string">    --num_workers=4 \</span></span><br><span class="line"><span class="string">    --iterations=8000</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">实际上发生的是：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">整个脚本会被启动4次（假设使用4个GPU）</span></span><br><span class="line"><span class="string">每次启动都是完整的脚本</span></span><br><span class="line"><span class="string">每个进程都有不同的 local_rank 值（0,1,2,3）</span></span><br><span class="line"><span class="string">每个进程被分配到不同的 GPU</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<p><code>start_ddp.sh</code> 平时运行它、修改它就好了。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------------------------</span></span><br><span class="line"><span class="comment"># 分布式训练启动脚本</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># 当使用 torch.distributed.launch 启动时：</span></span><br><span class="line"><span class="comment"># 1. 这个命令会自动启动n个进程(n=nproc_per_node指定的数量)</span></span><br><span class="line"><span class="comment"># 2. 每个进程都会运行同一个Python脚本(multi_gpu_process.py)</span></span><br><span class="line"><span class="comment"># 3. 每个进程会被自动分配一个local_rank(0,1,2,3...)</span></span><br><span class="line"><span class="comment"># 4. 每个进程会被自动分配到对应的GPU上</span></span><br><span class="line"><span class="comment"># ---------------------------------------------</span></span><br><span class="line"></span><br><span class="line">torchrun \</span><br><span class="line">   --nproc_per_node=2 \</span><br><span class="line">   --master_port=29501 \</span><br><span class="line">   ddp5_env_check.py \</span><br><span class="line">   --n_gpus=2 \</span><br><span class="line">   --batch_size=32 \</span><br><span class="line">   --epochs=10 \</span><br><span class="line">   --num_workers=4 \</span><br><span class="line">   --iterations=800</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------------------------</span></span><br><span class="line"><span class="comment"># 参数说明：</span></span><br><span class="line"><span class="comment"># --nproc_per_node: 要启动的进程数，通常等于GPU数量</span></span><br><span class="line"><span class="comment"># --master_port: 主进程的通信端口</span></span><br><span class="line"><span class="comment"># --n_gpus: 传递给Python脚本的GPU数量参数</span></span><br><span class="line"><span class="comment"># --batch_size: 每个GPU的批处理大小</span></span><br><span class="line"><span class="comment"># --epochs: 训练轮数</span></span><br><span class="line"><span class="comment"># --num_workers: 数据加载的工作进程数</span></span><br><span class="line"><span class="comment"># --iterations: 每张图片的处理迭代次数</span></span><br><span class="line"><span class="comment"># ---------------------------------------------</span></span><br></pre></td></tr></table></figure>

<p> 以上 例子 需要说明的是 ddp 方式 来做 多进程的 GPU 操作，是不存在主进程的，实际是 用 rank0 所在的进程兼职了主进程，它一边运行着自己的GPU训练一边兼职了主进程的活。所以 我们上面写的 统计 总共用时的写法 是不准确的，事实上也只会 体现出 rank0的 运行时间，但是 我没有想看那么精确 也就没有改了。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/cuda/" rel="tag"># cuda</a>
              <a href="/tags/pytorch/" rel="tag"># pytorch</a>
              <a href="/tags/Nvidia%E9%A9%B1%E5%8A%A8/" rel="tag"># Nvidia驱动</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/10/21/%E8%A3%85%E6%9C%BA/%E4%B8%A4%E4%B8%AA20T%E7%A1%AC%E7%9B%98%E5%81%9Araid/" rel="prev" title="两个20T硬盘做raid">
                  <i class="fa fa-chevron-left"></i> 两个20T硬盘做raid
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/10/28/windows_ubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F/ubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F%E4%B8%ADboot%E6%89%BE%E4%B8%8D%E5%88%B0Windows/" rel="next" title="ubuntu双系统中boot找不到Windows">
                  ubuntu双系统中boot找不到Windows <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">陈宇韶chenyushao</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
