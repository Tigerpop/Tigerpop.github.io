<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.13.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="这是文章开头，显示在主页面，详情请点击此处。">
<meta property="og:type" content="article">
<meta property="og:title" content="huggingface安装安全模型">
<meta property="og:url" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="Tiger_pop&#39;s Blog">
<meta property="og:description" content="这是文章开头，显示在主页面，详情请点击此处。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E6%88%AA%E5%B1%8F2025-05-17%2020.50.49-7573165.jpg">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E6%88%AA%E5%B1%8F2025-05-17%2020.52.58-7573165.jpg">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518161721_699-7573165.png">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518160752_692-7573165.png">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518204609_714-7573165.png">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518204702_704-7573165.png">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518204726_50-7573165.png">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518204804_715-7573165.png">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250519182104_778.png">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E6%88%AA%E5%B1%8F2025-05-19%2018.30.42.jpg">
<meta property="og:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E6%88%AA%E5%B1%8F2025-05-19%2018.25.39.jpg">
<meta property="article:published_time" content="2025-05-18T12:27:21.000Z">
<meta property="article:modified_time" content="2025-05-19T10:39:29.405Z">
<meta property="article:author" content="陈宇韶chenyushao">
<meta property="article:tag" content="dify">
<meta property="article:tag" content=" 网络安全模型">
<meta property="article:tag" content="chat-template">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E6%88%AA%E5%B1%8F2025-05-17%2020.50.49-7573165.jpg">


<link rel="canonical" href="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/","path":"2025/05/18/机器学习/huggingface安装安全模型/","title":"huggingface安装安全模型"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>huggingface安装安全模型 | Tiger_pop's Blog</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Tiger_pop's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Tiger_pop's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">tiger_pop 的博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%83%8C%E6%99%AF"><span class="nav-number">1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%BB%E6%96%87%E6%A1%A3"><span class="nav-number">2.</span> <span class="nav-text">读文档</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%80%9A%E8%BF%87%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%94%B9%E9%80%A0%E5%87%BAyaml%E6%96%87%E4%BB%B6"><span class="nav-number">3.</span> <span class="nav-text">通过大语言模型改造出yaml文件</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%88%91%E7%9A%84%E9%9C%80%E6%B1%82%E5%91%8A%E7%9F%A5%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.1.</span> <span class="nav-text">我的需求告知大模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BF%AE%E6%94%B9"><span class="nav-number">3.2.</span> <span class="nav-text">自定义修改</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4"><span class="nav-number">3.3.</span> <span class="nav-text">使用步骤</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%80%9A%E8%BF%87Dify-%E5%8F%91%E5%B8%83"><span class="nav-number">4.</span> <span class="nav-text">通过Dify 发布</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A0%87%E5%87%86%E4%BA%A4%E4%BA%92"><span class="nav-number">5.</span> <span class="nav-text">标准交互</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="陈宇韶chenyushao"
      src="/images/my.jpg">
  <p class="site-author-name" itemprop="name">陈宇韶chenyushao</p>
  <div class="site-description" itemprop="description">爱学习、爱工作、爱生活;         微信号: Tiger_and_master;         手机号码:18515678348 </div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">427</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">201</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my.jpg">
      <meta itemprop="name" content="陈宇韶chenyushao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tiger_pop's Blog">
      <meta itemprop="description" content="爱学习、爱工作、爱生活;         微信号: Tiger_and_master;         手机号码:18515678348 ">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="huggingface安装安全模型 | Tiger_pop's Blog">
      <meta itemprop="description" content="这是文章开头，显示在主页面，详情请点击此处。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          huggingface安装安全模型
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-05-18 20:27:21" itemprop="dateCreated datePublished" datetime="2025-05-18T20:27:21+08:00">2025-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-19 18:39:29" itemprop="dateModified" datetime="2025-05-19T18:39:29+08:00">2025-05-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">这是文章开头，显示在主页面，详情请点击此处。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>之前写过 huggingface 安装嵌入模型，其实这个网络安全领域的模型是一样的路数。</p>
<p>这里只写一下通过 huggingface 的使用提示，利用 chatgpt 或 deepseek 来实现yaml的改写。</p>
<p>以 <code>fdtn-ai/Foundation-Sec-8B</code> 网络安全模型为例子。</p>
<h1 id="读文档"><a href="#读文档" class="headerlink" title="读文档"></a>读文档</h1><p><img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E6%88%AA%E5%B1%8F2025-05-17%2020.50.49-7573165.jpg" alt="截屏2025-05-17 20.50.49"></p>
<p>我们使用 vllm ，点击 User this model 下的 vllm。</p>
<p><img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E6%88%AA%E5%B1%8F2025-05-17%2020.52.58-7573165.jpg" alt="截屏2025-05-17 20.52.58"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Deploy with docker on Linux:</span></span><br><span class="line">docker run --runtime nvidia --gpus all \</span><br><span class="line">	--name my_vllm_container \</span><br><span class="line">	-v ~/.cache/huggingface:/root/.cache/huggingface \</span><br><span class="line"> 	--<span class="built_in">env</span> <span class="string">&quot;HUGGING_FACE_HUB_TOKEN=&lt;secret&gt;&quot;</span> \</span><br><span class="line">	-p 8000:8000 \</span><br><span class="line">	--ipc=host \</span><br><span class="line">	vllm/vllm-openai:latest \</span><br><span class="line">	--model fdtn-ai/Foundation-Sec-8B</span><br></pre></td></tr></table></figure>



<h1 id="通过大语言模型改造出yaml文件"><a href="#通过大语言模型改造出yaml文件" class="headerlink" title="通过大语言模型改造出yaml文件"></a>通过大语言模型改造出yaml文件</h1><p>上面这个 docker 安装的例子中我们可以看见 不是 docker compose 的yaml 来实现的，而且默认了通过一个你的huggingface 的token 来实现下载新的模型的。</p>
<p>而我 习惯 先通过</p>
<p> <code>huggingface-cli download fdtn-ai/Foundation-Sec-8B --local-dir ./Foundation-Sec-8B</code>  </p>
<p>把模型下载到本地</p>
<p>（这样就不用这个<code>HUGGING_FACE_HUB_TOKEN</code>了）参考之前的安装嵌入模型的笔记 <a target="_blank" rel="noopener" href="https://tigerpop.github.io/2025/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/#huggingface%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B%EF%BC%8C">https://tigerpop.github.io/2025/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/#huggingface%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B，</a></p>
<p>然后通过宿主机文件夹映射容器，来实现对模型的部署，在yaml 中感觉看起来要直观很多，而且模块化一些。</p>
<h2 id="我的需求告知大模型"><a href="#我的需求告知大模型" class="headerlink" title="我的需求告知大模型"></a>我的需求告知大模型</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">官网给的建议是 这样</span><br><span class="line"># Deploy with docker on Linux:</span><br><span class="line">docker run --runtime nvidia --gpus all \</span><br><span class="line">	--name my_vllm_container \</span><br><span class="line">	-v ~/.cache/huggingface:/root/.cache/huggingface \</span><br><span class="line"> 	--env &quot;HUGGING_FACE_HUB_TOKEN=&lt;secret&gt;&quot; \</span><br><span class="line">	-p 8000:8000 \</span><br><span class="line">	--ipc=host \</span><br><span class="line">	vllm/vllm-openai:latest \</span><br><span class="line">	--model fdtn-ai/Foundation-Sec-8B</span><br><span class="line">再运行</span><br><span class="line"># Load and run the model:</span><br><span class="line">docker exec -it my_vllm_container bash -c &quot;vllm serve fdtn-ai/Foundation-Sec-8B&quot;</span><br><span class="line"></span><br><span class="line">我的需求：</span><br><span class="line">第一：我想要在宿主机的/home/cys/data/models/Foundation-Sec-8B 来映射 而不是用上面推荐的位置；</span><br><span class="line">第二：我想要改成 yaml 的形式 用 docker compose 来使用，这样使用方便一些。只需要先 docker compose up -d 然后再 进入容器中运行 vllm serve fdtn-ai/Foundation-Sec-8B 是不是就开启了这个模型？</span><br><span class="line">第三：能不能在 yaml 中加上一个 API key 这样用起来安全性高一些。</span><br><span class="line">第四：我不需要一键启动，</span><br><span class="line">第五：模型已经下载到了本地的 /home/cys/data/models/Foundation-Sec-8B，上面的HUGGING_FACE_HUB_TOKEN 是不是就不用了。</span><br><span class="line">请回答我，给我一个能用的yaml文件。</span><br></pre></td></tr></table></figure>

<p>把上面的内容发送给大语言模型。</p>
<p>大模型的回答的 <code>docker-compose.yml</code>是</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">vllm:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">vllm/vllm-openai:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">vllm_container</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1) 启用 NVIDIA GPU 支持,（Compose v1.28+）</span></span><br><span class="line">    <span class="attr">gpus:</span> <span class="string">all</span></span><br><span class="line">    <span class="comment">#runtime: nvidia</span></span><br><span class="line">    <span class="comment">#deploy:</span></span><br><span class="line">    <span class="comment">#  resources:</span></span><br><span class="line">    <span class="comment">#    reservations:</span></span><br><span class="line">    <span class="comment">#      devices:</span></span><br><span class="line">    <span class="comment">#        - driver: nvidia</span></span><br><span class="line">    <span class="comment">#          count: all</span></span><br><span class="line">    <span class="comment">#          capabilities: [gpu]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2) 挂载本地模型目录（将 models 目录映射到 /models）</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/cys/data/models/Foundation-Sec-8B:/models/Foundation-Sec-8B</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3) 暴露端口</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8000:8000&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4) 不自动启动 serve，保留为进入容器后手动执行</span></span><br><span class="line">    <span class="attr">entrypoint:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/bin/bash</span></span><br><span class="line">    <span class="attr">tty:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5) 注入 API Key（在 .env 文件中定义 VLLM_API_KEY=&lt;your_api_key&gt;）</span></span><br><span class="line">    <span class="attr">env_file:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">.env</span></span><br></pre></td></tr></table></figure>

<h2 id="自定义修改"><a href="#自定义修改" class="headerlink" title="自定义修改"></a>自定义修改</h2><p>我再根据我的实际情况（单机双卡3090ti）修改一下 yaml 文件，</p>
<p>从 Transformers v4.44 开始，vLLM 不再自动使用默认模板，所以你必须显式地通过 <code>--chat-template</code> 把你想要的对话模板传进来。否则所有 <code>/v1/chat/completions</code> 请求都会被拒绝。</p>
<p>所以我们需要先在 项目目录下新建一个名为 <code>openai_chat.jinja</code> 的文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;%- macro system_prompt(system) -%&#125;</span><br><span class="line">&lt;|system|&gt;</span><br><span class="line">&#123;&#123; system &#125;&#125;</span><br><span class="line">&lt;|endofsystem|&gt;</span><br><span class="line">&#123;%- endmacro -%&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- for msg in messages -%&#125;</span><br><span class="line">&lt;|&#123;&#123; msg.role &#125;&#125;|&gt;</span><br><span class="line">&#123;&#123; msg.content &#125;&#125;</span><br><span class="line">&lt;|endof&#123;&#123; msg.role &#125;&#125;|&gt;</span><br><span class="line">&#123;%- endfor -%&#125;</span><br></pre></td></tr></table></figure>

<p>yaml文件得出如下：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.8&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">vllm:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">vllm/vllm-openai:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">vllm_container</span></span><br><span class="line">    <span class="attr">ipc:</span> <span class="string">host</span>  <span class="comment"># 使用主机 IPC 命名空间</span></span><br><span class="line">    <span class="comment"># 1) 启用 NVIDIA GPU 支持（Compose v1.28+）</span></span><br><span class="line">    <span class="attr">gpus:</span> <span class="string">all</span></span><br><span class="line">    <span class="comment">#runtime: nvidia</span></span><br><span class="line">    <span class="comment">#deploy:</span></span><br><span class="line">    <span class="comment">#  resources:</span></span><br><span class="line">    <span class="comment">#    reservations:</span></span><br><span class="line">    <span class="comment">#      devices:</span></span><br><span class="line">    <span class="comment">#        - driver: nvidia</span></span><br><span class="line">    <span class="comment">#          count: all</span></span><br><span class="line">    <span class="comment">#          capabilities: [gpu]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2) 环境变量</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">CUDA_VISIBLE_DEVICES=0,1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">NCCL_DEBUG=INFO</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3) 挂载本地模型目录（models 目录映射到容器内 /models）</span></span><br><span class="line">    <span class="comment"># openai_chat.jinja 找到这个模版，在之后的命令中使用。</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/cys/data/models/Foundation-Sec-8B:/models/Foundation-Sec-8B</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./openai_chat.jinja:/templates/openai_chat.jinja:ro</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4) 暴露端口</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8000:8000&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5) 不自动启动 serve，保留为进入容器后手动执行</span></span><br><span class="line">    <span class="attr">entrypoint:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/bin/bash</span></span><br><span class="line">    <span class="attr">tty:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6) 注入 API Key（在 .env 文件中定义 VLLM_API_KEY=&lt;your_api_key&gt;）</span></span><br><span class="line">    <span class="attr">env_file:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">.env</span></span><br></pre></td></tr></table></figure>

<h2 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h2><ol>
<li><p>在项目yaml所在目录创建一个 <code>.env</code>，写入：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">VLLM_API_KEY=你的_api_key</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>启动容器（此时仅启动一个带有 Bash 的容器，不会自动跑服务）：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>
</li>
<li><p>进入容器并启动模型服务：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it vllm_container bash</span><br></pre></td></tr></table></figure>
</li>
<li><p>在容器内运行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 普通运行</span></span><br><span class="line"><span class="built_in">nohup</span> vllm serve /models/Foundation-Sec-8B \</span><br><span class="line">     --host 0.0.0.0 \</span><br><span class="line">     --port 8000 \</span><br><span class="line">     --api-key <span class="variable">$VLLM_API_KEY</span> \</span><br><span class="line">     &gt; vllm.log 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="comment"># 挂在后台，从vllm.log 中看日志。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 结合我的情况（单机双卡3090ti，并使用我们的chat模版）运行：</span></span><br><span class="line"><span class="built_in">nohup</span> vllm serve /models/Foundation-Sec-8B \</span><br><span class="line">     --host 0.0.0.0 \</span><br><span class="line">     --port 8000 \</span><br><span class="line">     --api-key <span class="string">&quot;<span class="variable">$VLLM_API_KEY</span>&quot;</span> \</span><br><span class="line">     --served-model-name Foundation-Sec-8B \</span><br><span class="line">     --chat-template /templates/openai_chat.jinja \</span><br><span class="line">     --tensor-parallel-size 2 \</span><br><span class="line">     --pipeline-parallel-size 1 \</span><br><span class="line">     --gpu-memory-utilization 0.90 \</span><br><span class="line">     --max-model-len 8192 \</span><br><span class="line">     --dtype half \</span><br><span class="line">     --swap-space 8 \</span><br><span class="line">     &gt; vllm.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<p>这样，vLLM 将加载 <code>/models/Foundation-Sec-8B</code> 下的本地模型，并以 OpenAI 兼容接口在 <code>http://localhost:8000</code> 提供服务。</p>
<p><img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518161721_699-7573165.png" alt="微信图片_20250518161721_699"></p>
<p>宿主机可见 两3090ti 都要跑满了。</p>
</li>
</ol>
<p><img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518160752_692-7573165.png" alt="微信图片_20250518160752_692"></p>
<p>容器内看到这个说明已经 正确开启了。</p>
<h1 id="通过Dify-发布"><a href="#通过Dify-发布" class="headerlink" title="通过Dify 发布"></a>通过Dify 发布</h1><p>现在dify的vllm插件中添加这个模型</p>
<p><img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518204609_714-7573165.png" alt="微信图片_20250518204609_714"></p>
<p><img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518204702_704-7573165.png" alt="微信图片_20250518204702_704"></p>
<p>然后测试一下</p>
<p><img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518204726_50-7573165.png" alt="微信图片_20250518204726_50"></p>
<p>以网页形式发布，这里注意一下 ，要点击“发布更新”，因为这个模型是在10.5.9.251机器 dify 在10.5.9.252机器，所以刚刚发布会特别傻这个模型，还可能没有改过来，要反复操作然后等一等。</p>
<p><img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250518204804_715-7573165.png" alt="微信图片_20250518204804_715"></p>
<p>上面是发布好的情况。</p>
<h1 id="标准交互"><a href="#标准交互" class="headerlink" title="标准交互"></a>标准交互</h1><p>从官网上推荐的例子中 改过来的，才是 最正的提问方法。</p>
<p>注意我们这里 把前文中jinji2文件改成了这样， 关闭 vllm serve 开启的进程，docker 中重启一下 vllm 。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&#123;% set system_message = &#x27;&#x27; %&#125;</span><br><span class="line">&#123;% if messages and messages[0].role == &#x27;system&#x27; %&#125;</span><br><span class="line">  &#123;% set system_message = messages[0].content | trim %&#125;</span><br><span class="line">  &#123;% set messages = messages[1:] %&#125;</span><br><span class="line">&#123;% endif %&#125;</span><br><span class="line"></span><br><span class="line">&lt;|system|&gt;&#123;&#123; system_message &#125;&#125;&lt;|end|&gt;</span><br><span class="line">&#123;% for msg in messages %&#125;</span><br><span class="line">  &#123;% if msg.role == &#x27;user&#x27; %&#125;</span><br><span class="line">&lt;|user|&gt;&#123;&#123; msg.content | trim &#125;&#125;&lt;|end|&gt;</span><br><span class="line">  &#123;% elif msg.role == &#x27;assistant&#x27; %&#125;</span><br><span class="line">&lt;|assistant|&gt;&#123;&#123; msg.content | trim &#125;&#125;&lt;|end|&gt;</span><br><span class="line">  &#123;% endif %&#125;</span><br><span class="line">&#123;% endfor %&#125;</span><br><span class="line">&lt;|assistant|&gt;&lt;|endofreply|&gt;</span><br></pre></td></tr></table></figure>

<p><strong>注意这个截止符 <code>&lt;|endofreply|&gt;</code>, 在标准交互提问中 要明确截止符“stop”。</strong></p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST <span class="string">&quot;http://10.5.9.251:8000/v1/completions&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer cisjeifujlnu123-ccc&quot;</span> \</span><br><span class="line">	-H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">	<span class="comment">--data &#x27;&#123;</span></span><br><span class="line">		<span class="string">&quot;model&quot;</span>: <span class="string">&quot;Foundation-Sec-8B&quot;</span>,</span><br><span class="line">		<span class="string">&quot;prompt&quot;</span>: <span class="string">&quot;please explain to me what Log4Shell is&quot;</span>,</span><br><span class="line">		<span class="string">&quot;max_tokens&quot;</span>: <span class="number">512</span>,</span><br><span class="line">		<span class="string">&quot;temperature&quot;</span>: <span class="number">0.5</span>,</span><br><span class="line">    <span class="string">&quot;stop&quot;</span>: [<span class="string">&quot;&lt;|endofreply|&gt;&quot;</span>]</span><br><span class="line">	&#125;&#x27;</span><br></pre></td></tr></table></figure>

<p><img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250519182104_778.png" alt="微信图片_20250519182104_778"></p>
<p>回答的话中 text 内容就是我们要的。<img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E6%88%AA%E5%B1%8F2025-05-19%2018.30.42.jpg" alt="截屏2025-05-19 18.30.42"></p>
<p>而使用 dify 强行关联上，经常生成出一大堆的不相关内容回答，</p>
<p>因为，我没有找到在dify 的哪里 去 实现 “stop”: [“&lt;|endofreply|&gt;”] ，</p>
<p>我看见dify 文档中有提到，但是我还是没找到在哪里去实现。</p>
<p><img src="/2025/05/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%AE%89%E8%A3%85%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/%E6%88%AA%E5%B1%8F2025-05-19%2018.25.39.jpg" alt="截屏2025-05-19 18.25.39"></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/dify/" rel="tag"># dify</a>
              <a href="/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9E%8B/" rel="tag">#  网络安全模型</a>
              <a href="/tags/chat-template/" rel="tag"># chat-template</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/05/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/open%20webUI%E6%95%B0%E6%8D%AE%E5%BA%93%E9%94%81%E5%A4%84%E7%90%86%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%81%E7%A7%BB/" rel="prev" title="OpenwebUI数据库锁处理以及数据库迁移">
                  <i class="fa fa-chevron-left"></i> OpenwebUI数据库锁处理以及数据库迁移
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/05/20/%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/flask_study/" rel="next" title="flask-study">
                  flask-study <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">陈宇韶chenyushao</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
