<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.13.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="这是文章开头，显示在主页面，详情请点击此处。">
<meta property="og:type" content="article">
<meta property="og:title" content="本地部署Deepseek实现RAG并联网搜索">
<meta property="og:url" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/index.html">
<meta property="og:site_name" content="Tiger_pop&#39;s Blog">
<meta property="og:description" content="这是文章开头，显示在主页面，详情请点击此处。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228144008.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E9%85%8D%E7%BD%AE.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E7%A4%BA%E4%BE%8B.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250304153451.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250308112806.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250304153445.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154513.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154507.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154516.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-02-28%2015.39.57.jpg">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154522.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154527.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-09%2017.43.47.jpg">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250309131910.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250309131717.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/dl.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095926.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095931.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095937.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095941.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095945-1658497.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095807.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250314105527.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250314105533.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-20%2009.33.12.jpg">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-20%2009.32.32.jpg">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-18%2020.42.40.jpg">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-18%2021.05.23.jpg">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-18%2021.07.18.jpg">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250318211815.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250320144426.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2008.58.17.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.02.04.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.40.40.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.07.42.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.08.23.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.11.50.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.15.37.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.20.15.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.22.01.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.35.18.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.53.01.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.56.58.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.04.10.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.05.33.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.45.28.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.46.19.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.53.38.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2013.55.39.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-30%2018.37.48.jpg">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330182312.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330222345.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250320155359.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250320155402.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250402181950-3589288.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250310084150.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330215009.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330215013.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330215145.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330220106.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330221123.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250402181036.png">
<meta property="og:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250402181950.png">
<meta property="article:published_time" content="2025-04-02T01:08:18.000Z">
<meta property="article:modified_time" content="2025-10-22T11:32:29.415Z">
<meta property="article:author" content="陈宇韶chenyushao">
<meta property="article:tag" content="嵌入模型">
<meta property="article:tag" content="Text Embeddings Inference">
<meta property="article:tag" content="docker">
<meta property="article:tag" content="docker compose">
<meta property="article:tag" content="NVIDIA Container Toolkit">
<meta property="article:tag" content="nvidia-cuda-toolkit">
<meta property="article:tag" content="搜索引擎">
<meta property="article:tag" content="反向代理">
<meta property="article:tag" content="SearXNG">
<meta property="article:tag" content="ollama">
<meta property="article:tag" content="anythingllm">
<meta property="article:tag" content="Nignx proxy manager">
<meta property="article:tag" content="openwebUI">
<meta property="article:tag" content="modelscope">
<meta property="article:tag" content="vllm">
<meta property="article:tag" content="容器">
<meta property="article:tag" content="deepseek">
<meta property="article:tag" content="集群">
<meta property="article:tag" content="swarm">
<meta property="article:tag" content="Ray">
<meta property="article:tag" content="bge-large-zh-v1.5">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228144008.png">


<link rel="canonical" href="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/","path":"2025/04/02/机器学习/本地部署Deepseek实现RAG并联网搜索/","title":"本地部署Deepseek实现RAG并联网搜索"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>本地部署Deepseek实现RAG并联网搜索 | Tiger_pop's Blog</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Tiger_pop's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Tiger_pop's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">tiger_pop 的博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E5%89%8D%E6%9C%9F%E5%87%86%E5%A4%87"><span class="nav-number">1.</span> <span class="nav-text">一、前期准备</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81%E7%B3%BB%E7%BB%9F%E3%80%81%E5%AD%98%E5%82%A8%E5%8F%8A%E9%A9%B1%E5%8A%A8%E6%83%85%E5%86%B5"><span class="nav-number">1.1.</span> <span class="nav-text">1、系统、存储及驱动情况</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E3%80%81%E5%9B%BD%E5%86%85%E5%AE%89%E8%A3%85docker"><span class="nav-number">1.2.</span> <span class="nav-text">2、国内安装docker</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1%E3%80%81%E5%AE%89%E8%A3%85docker"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1、安装docker</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2%E3%80%81%E5%AE%89%E8%A3%85docker-compose"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2、安装docker-compose</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">1.2.3.</span> <span class="nav-text"></span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3%E3%80%81Docker-%E8%B0%83%E7%94%A8%E5%AE%BF%E4%B8%BB%E6%9C%BANvidia%E5%8D%A1"><span class="nav-number">1.3.</span> <span class="nav-text">3、Docker 调用宿主机Nvidia卡</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1%E3%80%81%E5%AE%89%E8%A3%85NVIDIA-Container-Toolkit-NVIDIA%E5%AE%B9%E5%99%A8%E5%B7%A5%E5%85%B7%E5%8C%85"><span class="nav-number">1.3.1.</span> <span class="nav-text">3.1、安装NVIDIA Container Toolkit NVIDIA容器工具包</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2%E3%80%81nvidia-docker-%E4%B8%8E-NVIDIA-Container-Toolkit-%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">1.3.2.</span> <span class="nav-text">3.2、nvidia-docker 与 NVIDIA Container Toolkit 的关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3%E3%80%81%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%AE%89%E8%A3%85nvidia-cuda-toolkit"><span class="nav-number">1.3.3.</span> <span class="nav-text">3.3、宿主机安装nvidia-cuda-toolkit</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#-1"><span class="nav-number">1.3.4.</span> <span class="nav-text"></span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E8%87%AA%E5%BB%BA%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E"><span class="nav-number">2.</span> <span class="nav-text">二、自建搜索引擎</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81SearXNG-%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%EF%BC%88%E4%BA%8C%E9%80%89%E4%B8%80%EF%BC%89"><span class="nav-number">2.1.</span> <span class="nav-text">1、SearXNG 搜索引擎本地部署（二选一）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1%E3%80%81Docker-compose%E7%89%88%E6%9C%AC%EF%BC%88%E5%8F%AF%E6%B5%8F%E8%A7%88%E5%99%A8%E4%BD%BF%E7%94%A8%EF%BC%8C%E4%B8%8D%E5%8F%AF%E8%A2%ABAnythingLLM-x2F-open-webUI%E8%B0%83%E7%94%A8%EF%BC%89"><span class="nav-number">2.1.1.</span> <span class="nav-text">1.1、Docker compose版本（可浏览器使用，不可被AnythingLLM&#x2F;open webUI调用）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-1%E3%80%81yaml%EF%BC%9A"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">1.1.1、yaml：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-2%E3%80%81yaml%E8%A7%A3%E9%87%8A%EF%BC%9A"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">1.1.2、yaml解释：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-3%E3%80%81%E4%BF%AE%E6%94%B9setting-yml%E9%85%8D%E7%BD%AE"><span class="nav-number">2.1.1.3.</span> <span class="nav-text">1.1.3、修改setting.yml配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-4%E3%80%81%E7%99%BB%E5%BD%95searxng%E9%A1%B5%E9%9D%A2%E6%94%B9%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%EF%BC%9A"><span class="nav-number">2.1.1.4.</span> <span class="nav-text">1.1.4、登录searxng页面改搜索引擎：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2%E3%80%81Docker-%E7%89%88%E6%9C%AC%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A2%ABAnythingLLM-x2F-open-webUI%E8%B0%83%E7%94%A8%EF%BC%89"><span class="nav-number">2.1.2.</span> <span class="nav-text">1.2、Docker 版本（不可被AnythingLLM&#x2F;open webUI调用）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86"><span class="nav-number">3.</span> <span class="nav-text">三、反向代理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81%E5%AE%89%E8%A3%85Nginx-Proxy-Manager"><span class="nav-number">3.1.</span> <span class="nav-text">1、安装Nginx Proxy Manager</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E3%80%81npm%E7%9A%84Web%E7%AE%A1%E7%90%86%E6%8E%A7%E5%88%B6%E5%8F%B0"><span class="nav-number">3.2.</span> <span class="nav-text">2、npm的Web管理控制台</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E6%80%9D%E8%B7%AF%E4%B8%80%EF%BC%9AOllama%E9%83%A8%E7%BD%B2Deepseek"><span class="nav-number">4.</span> <span class="nav-text">四、思路一：Ollama部署Deepseek</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81%E5%AE%89%E8%A3%85ollama"><span class="nav-number">4.1.</span> <span class="nav-text">1、安装ollama</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1%E3%80%81%E6%96%B9%E6%A1%88%E4%B8%80%EF%BC%9A%EF%BC%88ollama-anythingllm-searxng-Nignx-proxy-manager%EF%BC%89"><span class="nav-number">4.2.</span> <span class="nav-text">2.1、方案一：（ollama+anythingllm+searxng+Nignx proxy manager）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-1%E3%80%81Docker%E4%B8%8B%E5%AE%89%E8%A3%85AnythingLLM"><span class="nav-number">4.2.1.</span> <span class="nav-text">2.1.1、Docker下安装AnythingLLM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-2%E3%80%81AnythingLLM%E6%8E%A7%E5%88%B6%E7%95%8C%E9%9D%A2%E9%85%8D%E7%BD%AE"><span class="nav-number">4.2.2.</span> <span class="nav-text">2.1.2、AnythingLLM控制界面配置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1%E3%80%81%E6%96%B9%E6%A1%88%E4%BA%8C%EF%BC%9A%EF%BC%88ollama-open-web-UI-searxng-Nignx-proxy-manager%EF%BC%89"><span class="nav-number">4.3.</span> <span class="nav-text">2.1、方案二：（ollama+open web UI+searxng+Nignx proxy manager）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-1%E3%80%81%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2%E9%83%A8%E7%BD%B2%E6%88%90%E5%8A%9F%E6%A1%88%E4%BE%8B"><span class="nav-number">4.3.1.</span> <span class="nav-text">2.1.1、联网搜索部署成功案例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-1%E3%80%81%E9%85%8D%E7%BD%AEsearxng"><span class="nav-number">4.3.1.1.</span> <span class="nav-text">2.1.1.1、配置searxng</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-2%E3%80%81%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-open-webUI"><span class="nav-number">4.3.1.2.</span> <span class="nav-text">2.1.1.2、安装配置 open webUI</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-3%E3%80%81%E7%BD%91%E9%A1%B5%E4%B8%AD%E9%85%8D%E7%BD%AE"><span class="nav-number">4.3.1.3.</span> <span class="nav-text">2.1.1.3、网页中配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-2%E3%80%81%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E%E9%83%A8%E5%88%86"><span class="nav-number">4.3.2.</span> <span class="nav-text">2.1.2、补充说明部分</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-1%E3%80%81%E6%9C%AC%E5%9C%B0%E6%95%B0%E6%8D%AE%E6%98%A0%E5%B0%84%E3%80%81%E8%BF%81%E7%A7%BB"><span class="nav-number">4.3.2.1.</span> <span class="nav-text">2.1.2.1、本地数据映射、迁移</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-2%E3%80%81%E6%97%A5%E5%BF%97"><span class="nav-number">4.3.2.2.</span> <span class="nav-text">2.1.2.2、日志</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-3%E3%80%81%E6%94%B9%E6%8D%A2%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.3.2.3.</span> <span class="nav-text">2.1.2.3、改换嵌入模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-4%E3%80%81RAG"><span class="nav-number">4.3.2.4.</span> <span class="nav-text">2.1.2.4、RAG</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-5%E3%80%81%E8%87%AA%E5%BB%BAsearxng%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%8F%92%E4%BB%B6%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%90%9C%E7%B4%A2"><span class="nav-number">4.3.2.5.</span> <span class="nav-text">2.1.2.5、自建searxng搜索引擎插件实现微信搜索</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-6%E3%80%81%E8%AE%A9%E7%94%A8%E6%88%B7%E8%83%BD%E5%A4%9F%E8%87%AA%E5%B7%B1%E6%B3%A8%E5%86%8C"><span class="nav-number">4.3.2.6.</span> <span class="nav-text">2.1.2.6、让用户能够自己注册</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E6%80%9D%E8%B7%AF%E4%BA%8C%EF%BC%9Avllm%E9%83%A8%E7%BD%B2Deepseek"><span class="nav-number">5.</span> <span class="nav-text">四、思路二：vllm部署Deepseek</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81%E6%96%B9%E6%A1%88%EF%BC%9A%EF%BC%88vllm-open-web-UI-searxng-Nignx-proxy-manager%EF%BC%89"><span class="nav-number">5.1.</span> <span class="nav-text">1、方案：（vllm+open web UI+searxng+Nignx proxy manager）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1%E3%80%81modelscope%E6%9C%AC%E5%9C%B0%E4%B8%8B%E8%BD%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.1.1.</span> <span class="nav-text">1.1、modelscope本地下载大模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2%E3%80%81vllm%E9%83%A8%E7%BD%B2"><span class="nav-number">5.1.2.</span> <span class="nav-text">1.2、vllm部署</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-1%E3%80%81vllm%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E9%83%A8%E7%BD%B2"><span class="nav-number">5.1.2.1.</span> <span class="nav-text">1.2.1、vllm单机多卡部署</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-2%E3%80%81vllm%E5%A4%9A%E6%9C%BA%E5%A4%9A%E5%8D%A1%E9%83%A8%E7%BD%B2"><span class="nav-number">5.1.2.2.</span> <span class="nav-text">1.2.2、vllm多机多卡部署</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-2-2-1%E3%80%81%E9%80%89%E9%A1%B9%E4%B8%80%EF%BC%9A%E9%80%9A%E8%BF%87swarm%E9%83%A8%E7%BD%B2"><span class="nav-number">5.1.2.2.1.</span> <span class="nav-text">1.2.2.1、选项一：通过swarm部署</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Docker-Swarm-%E9%9B%86%E7%BE%A4%E5%9F%BA%E7%A1%80"><span class="nav-number">5.1.2.2.2.</span> <span class="nav-text">Docker Swarm 集群基础</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%C2%B7-%E5%88%9D%E5%A7%8B%E5%8C%96%E9%9B%86%E7%BE%A4%EF%BC%9A"><span class="nav-number">5.1.2.2.2.1.</span> <span class="nav-text">· 初始化集群：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%C2%B7-%E5%8A%A0%E5%85%A5%E8%8A%82%E7%82%B9%EF%BC%9A"><span class="nav-number">5.1.2.2.2.2.</span> <span class="nav-text">· 加入节点：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%C2%B7-%E9%9B%86%E7%BE%A4%E8%A7%A3%E6%95%A3%EF%BC%9A"><span class="nav-number">5.1.2.2.2.3.</span> <span class="nav-text">· 集群解散：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%C2%B7-%E8%8A%82%E7%82%B9%E7%AE%A1%E7%90%86%EF%BC%9A"><span class="nav-number">5.1.2.2.2.4.</span> <span class="nav-text">· 节点管理：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%C2%B7-%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%EF%BC%9A"><span class="nav-number">5.1.2.2.2.5.</span> <span class="nav-text">· 服务管理：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%C2%B7-swarm%E9%9B%86%E7%BE%A4%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%EF%BC%9A"><span class="nav-number">5.1.2.2.2.6.</span> <span class="nav-text">· swarm集群弹性伸缩：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%C2%B7-swarm%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0%EF%BC%9A"><span class="nav-number">5.1.2.2.2.7.</span> <span class="nav-text">· swarm集群服务滚动更新：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%C2%B7-swarm%E9%9B%86%E7%BE%A4%E4%B8%AD%E4%BD%BF%E7%94%A8docker-compose%EF%BC%9A"><span class="nav-number">5.1.2.2.2.8.</span> <span class="nav-text">· swarm集群中使用docker compose：</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%85%B7%E4%BD%93%E6%93%8D%E4%BD%9C"><span class="nav-number">5.1.2.2.3.</span> <span class="nav-text">具体操作</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%C2%B7-docker-swarm-GPU%E6%94%AF%E6%8C%81"><span class="nav-number">5.1.2.2.3.1.</span> <span class="nav-text">· docker swarm GPU支持</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%EF%BC%9A"><span class="nav-number">5.1.2.2.3.2.</span> <span class="nav-text">问题：</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-2-2-2%E3%80%81%E9%80%89%E9%A1%B9%E4%BA%8C%EF%BC%9A%E9%80%9A%E8%BF%87-ray-%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="nav-number">5.1.2.2.4.</span> <span class="nav-text">1.2.2.2、选项二：通过 ray 集群部署</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3%E3%80%81%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2"><span class="nav-number">5.1.3.</span> <span class="nav-text">1.3、嵌入模型部署</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4%E3%80%81open-webUI%E8%B0%83%E7%94%A8vllm"><span class="nav-number">5.1.4.</span> <span class="nav-text">1.4、open webUI调用vllm</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%99%84%E5%8A%A0%EF%BC%9A%E5%8F%AF%E8%83%BD%E9%81%87%E5%88%B0%E7%9A%84%E8%8B%A5%E5%B9%B2%E9%97%AE%E9%A2%98%EF%BC%9A"><span class="nav-number">6.</span> <span class="nav-text">附加：可能遇到的若干问题：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-AnythingLLM%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB"><span class="nav-number">6.0.0.1.</span> <span class="nav-text">· AnythingLLM数据迁移</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-%E6%B5%8B%E8%AF%95%E5%AE%B9%E5%99%A8%E4%B9%8B%E9%97%B4%E6%98%AF%E5%90%A6%E7%9B%B8%E9%80%9A"><span class="nav-number">6.0.0.2.</span> <span class="nav-text">· 测试容器之间是否相通</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-%E9%81%87%E5%88%B0-%E9%98%BF%E9%87%8C%E4%BA%91-Docker-CE-%E9%95%9C%E5%83%8F%E6%BA%90-%E5%92%8C-GPG-%E5%AF%86%E9%92%A5%E8%BF%87%E6%97%B6"><span class="nav-number">6.0.0.3.</span> <span class="nav-text">· 遇到 阿里云 Docker CE 镜像源 和 GPG 密钥过时</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-open-webui-%E7%99%BD%E5%B1%8F%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3"><span class="nav-number">6.0.0.4.</span> <span class="nav-text">· open webui 白屏问题解决</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-searxng%E4%B8%AD%E9%95%BF%E5%8F%A5%E5%AD%90%E4%B8%8D%E8%83%BD%E6%90%9C%E7%B4%A2%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">6.0.0.5.</span> <span class="nav-text">· searxng中长句子不能搜索的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-%E5%AE%B9%E5%99%A8%E9%97%B4%E9%80%9A%E4%BF%A1%E9%97%AE%E9%A2%98%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5"><span class="nav-number">6.0.0.6.</span> <span class="nav-text">· 容器间通信问题的最佳实践</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-%E6%97%A0%E6%B3%95%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E4%BD%BF%E7%94%A8docker%E6%8A%80%E5%B7%A7"><span class="nav-number">6.0.0.7.</span> <span class="nav-text">· 无法科学上网使用docker技巧</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-vllm%E9%9B%86%E7%BE%A4%E9%81%87%E5%88%B0-GLOO%E3%80%81NCCL-%E6%8A%A5%E9%94%99"><span class="nav-number">6.0.0.8.</span> <span class="nav-text">· vllm集群遇到 GLOO、NCCL 报错</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-vllm%E9%9B%86%E7%BE%A4%E9%81%87%E5%88%B0-The-model%E2%80%99s-max-seq-%E6%8A%A5%E9%94%99"><span class="nav-number">6.0.0.9.</span> <span class="nav-text">· vllm集群遇到 The model’s max seq 报错</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-vllm%E9%9B%86%E7%BE%A4%E9%81%87%E5%88%B0-CUDA-out-of-memory-%E6%8A%A5%E9%94%99"><span class="nav-number">6.0.0.10.</span> <span class="nav-text">· vllm集群遇到 CUDA out of memory 报错</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-open-webUI%E7%9F%A5%E8%AF%86%E5%BA%93%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E9%81%87%E5%88%B0-%E4%B8%8A%E4%BC%A0-%E6%8A%A5%E9%94%99"><span class="nav-number">6.0.0.11.</span> <span class="nav-text">· open webUI知识库上传文件遇到 上传 报错</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-RAG-%E6%97%B6%E9%81%87%E5%88%B0%E4%BA%86-Please-reduce-the-length-of-the-messages-%E6%8A%A5%E9%94%99"><span class="nav-number">6.0.0.12.</span> <span class="nav-text">· RAG 时遇到了 Please reduce the length of the messages 报错</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%C2%B7-%E6%9B%B4%E6%96%B0%E5%AE%B9%E5%99%A8%E7%9A%84%E6%9C%8D%E5%8A%A1"><span class="nav-number">6.0.0.13.</span> <span class="nav-text">· 更新容器的服务</span></a></li></ol></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="陈宇韶chenyushao"
      src="/images/my.jpg">
  <p class="site-author-name" itemprop="name">陈宇韶chenyushao</p>
  <div class="site-description" itemprop="description">爱学习、爱工作、爱生活;         微信号: Tiger_and_master;         手机号码:18515678348 </div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">427</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">201</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my.jpg">
      <meta itemprop="name" content="陈宇韶chenyushao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tiger_pop's Blog">
      <meta itemprop="description" content="爱学习、爱工作、爱生活;         微信号: Tiger_and_master;         手机号码:18515678348 ">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="本地部署Deepseek实现RAG并联网搜索 | Tiger_pop's Blog">
      <meta itemprop="description" content="这是文章开头，显示在主页面，详情请点击此处。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          本地部署Deepseek实现RAG并联网搜索
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-02 09:08:18" itemprop="dateCreated datePublished" datetime="2025-04-02T09:08:18+08:00">2025-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-10-22 19:32:29" itemprop="dateModified" datetime="2025-10-22T19:32:29+08:00">2025-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">这是文章开头，显示在主页面，详情请点击此处。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>本地部署Deepseek有几种经典的做法，有借助ollama实现也有直接下载各种对应模型到本地用vllm调用等。我为了使用和部署方便，决定使用docker部署实现。</p>
<p>使用多种方案部署前，需要先做好准备工作。</p>
<h1 id="一、前期准备"><a href="#一、前期准备" class="headerlink" title="一、前期准备"></a>一、前期准备</h1><h2 id="1、系统、存储及驱动情况"><a href="#1、系统、存储及驱动情况" class="headerlink" title="1、系统、存储及驱动情况"></a>1、系统、存储及驱动情况</h2><p>我之前是ubuntu20.04的系统，Linux核心也是老版本的，但是Nvidia驱动和conda等环境不想变动还有很多数据不方便挪，所以选择了使用命令后台升级成了下面的版本（大约3小时），为了方便直接使用docker。以下是升级完成后我的机器情况。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">(base) cys@cysserver:~$ lsb_release -a </span><br><span class="line">No LSB modules are available.</span><br><span class="line">Distributor ID:	Ubuntu</span><br><span class="line">Description:	Ubuntu 24.04.2 LTS</span><br><span class="line">Release:	24.04</span><br><span class="line">Codename:	noble</span><br><span class="line">(base) cys@cysserver:~$ <span class="built_in">uname</span> -r </span><br><span class="line">6.8.0-53-generic</span><br><span class="line"></span><br><span class="line">(base) cys@cysserver:~$ free -h </span><br><span class="line">               total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           503Gi       5.9Gi       456Gi       7.3Mi        44Gi       497Gi</span><br><span class="line">Swap:          8.0Gi          0B       8.0Gi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(base) cys@cysserver:~$ nvidia-smi </span><br><span class="line">Fri Feb 28 06:36:49 2025       </span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |</span><br><span class="line">|-----------------------------------------+------------------------+----------------------+</span><br><span class="line">| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                                         |                        |               MIG M. |</span><br><span class="line">|=========================================+========================+======================|</span><br><span class="line">|   0  NVIDIA GeForce RTX 3090        Off |   00000000:47:00.0 Off |                  N/A |</span><br><span class="line">| 41%   27C    P8             22W /  350W |       4MiB /  24576MiB |      0%      Default |</span><br><span class="line">|                                         |                        |                  N/A |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   1  NVIDIA GeForce RTX 3090        Off |   00000000:5E:00.0 Off |                  N/A |</span><br><span class="line">| 41%   25C    P8             25W /  350W |       4MiB /  24576MiB |      0%      Default |</span><br><span class="line">|                                         |                        |                  N/A |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">                                                                                         </span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                              |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |</span><br><span class="line">|        ID   ID                                                               Usage      |</span><br><span class="line">|=========================================================================================|</span><br><span class="line">|  No running processes found                                                             |</span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>

<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228144008.png" alt="微信图片_20250228144008"></p>
<h2 id="2、国内安装docker"><a href="#2、国内安装docker" class="headerlink" title="2、国内安装docker"></a>2、国内安装docker</h2><h3 id="2-1、安装docker"><a href="#2-1、安装docker" class="headerlink" title="2.1、安装docker"></a>2.1、安装docker</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除</span></span><br><span class="line">sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-buildx-plugin</span><br><span class="line">sudo <span class="built_in">rm</span> -rf /var/lib/docker</span><br><span class="line">sudo <span class="built_in">rm</span> -rf /var/lib/containerd</span><br><span class="line">sudo <span class="built_in">rm</span> -rf /etc/docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">curl -fsSL https://get.docker.com | sudo sh</span><br><span class="line">    <span class="comment"># 或者</span></span><br><span class="line">    sudo apt-get update</span><br><span class="line">    sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin</span><br><span class="line">    <span class="comment"># 或者</span></span><br><span class="line">    sudo sed -i <span class="string">&#x27;s/noble/jammy/g&#x27;</span> /etc/apt/sources.list.d/docker.list</span><br><span class="line">    sudo apt update</span><br><span class="line">    sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置Docker环境</span></span><br><span class="line">    <span class="comment"># 添加用户到docker组</span></span><br><span class="line">    sudo usermod -aG docker <span class="variable">$USER</span></span><br><span class="line">    newgrp docker  <span class="comment"># 刷新组权限</span></span><br><span class="line">  	<span class="comment"># 配置镜像加速器（国内建议）</span></span><br><span class="line">    vim /etc/docker/daemon.json</span><br><span class="line">    ---------------------------------------------------</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;registry-mirrors&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;https://docker.m.daocloud.io&quot;</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">    ---------------------------------------------------</span><br><span class="line">    或</span><br><span class="line">    ---------------------------------------------------</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;registry-mirrors&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;https://docker.m.daocloud.io&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.ccs.tencentyun.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://func.ink&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://proxy.1panel.live&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.zhai.cm&quot;</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">    ---------------------------------------------------</span><br><span class="line">    </span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl <span class="built_in">enable</span> docker</span><br><span class="line">sudo systemctl restart docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检验国内是否可以正常拉取</span></span><br><span class="line">docker pull busybox</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-2、安装docker-compose"><a href="#2-2、安装docker-compose" class="headerlink" title="2.2、安装docker-compose"></a>2.2、安装docker-compose</h3><p>官方文档：    <a target="_blank" rel="noopener" href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 插件方式安装</span></span><br><span class="line">sudo apt-get install docker-compose-plugin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 插件方式安装 查看docker compose版本</span></span><br><span class="line">docker compose version</span><br><span class="line">docker compose -v</span><br></pre></td></tr></table></figure>

<h3 id><a href="#" class="headerlink" title></a></h3><h2 id="3、Docker-调用宿主机Nvidia卡"><a href="#3、Docker-调用宿主机Nvidia卡" class="headerlink" title="3、Docker 调用宿主机Nvidia卡"></a>3、Docker 调用宿主机Nvidia卡</h2><h3 id="3-1、安装NVIDIA-Container-Toolkit-NVIDIA容器工具包"><a href="#3-1、安装NVIDIA-Container-Toolkit-NVIDIA容器工具包" class="headerlink" title="3.1、安装NVIDIA Container Toolkit NVIDIA容器工具包"></a>3.1、安装NVIDIA Container Toolkit NVIDIA容器工具包</h3><p>参考 ：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/dw14132124/article/details/140534628">https://blog.csdn.net/dw14132124/article/details/140534628</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg</span><br><span class="line">curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | sed <span class="string">&#x27;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&#x27;</span> | sudo <span class="built_in">tee</span> /etc/apt/sources.list.d/nvidia-container-toolkit.list</span><br><span class="line"></span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line">sudo apt-get install -y nvidia-container-toolkit</span><br></pre></td></tr></table></figure>

<p>结合上面解决Docker CE的步骤，可能会导致 docker 在国内拉取不到镜像的情况，需要按照下面再搞一下。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建/编辑配置文件（注意 JSON 格式）</span></span><br><span class="line">sudo vim /etc/docker/daemon.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 粘贴以下内容（推荐组合多个镜像源）</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;https://docker.m.daocloud.io&quot;</span>,</span><br><span class="line">    <span class="string">&quot;https://mirror.ccs.tencentyun.com&quot;</span>,</span><br><span class="line">    <span class="string">&quot;https://func.ink&quot;</span>,</span><br><span class="line">    <span class="string">&quot;https://proxy.1panel.live&quot;</span>,</span><br><span class="line">    <span class="string">&quot;https://docker.zhai.cm&quot;</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl <span class="built_in">enable</span> docker</span><br><span class="line">sudo systemctl restart docker</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> /etc/docker/daemon.json</span><br><span class="line"><span class="comment"># ​预期配置：包含 nvidia 运行时定义（必须字段）：</span></span><br><span class="line">json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;runtimes&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;nvidia&quot;</span>: &#123;</span><br><span class="line">      <span class="string">&quot;path&quot;</span>: <span class="string">&quot;nvidia-container-runtime&quot;</span>,</span><br><span class="line">      <span class="string">&quot;runtimeArgs&quot;</span>: []</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 若缺失，执行 sudo nvidia-ctk runtime configure --runtime=docker 自动修复</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检验国内是否可以正常拉取</span></span><br><span class="line">docker pull busybox</span><br><span class="line">docker pull nvidia/cuda:12.0.1-base-ubuntu22.04</span><br></pre></td></tr></table></figure>

<p>检查 docker 能不能正常使用 Nvidia的GPU</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 看看应该要不是空的。</span></span><br><span class="line">dpkg -l | grep nvidia-container-toolkit</span><br><span class="line"></span><br><span class="line"><span class="comment"># 官方镜像标签规则为 &quot;主版本-子版本-基础环境&quot;</span></span><br><span class="line"><span class="comment"># 拉取 CUDA 12.0.1 开发镜像</span></span><br><span class="line">docker pull nvidia/cuda:12.0.1-devel-ubuntu22.04</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查测试，运行一个临时容器，显示应该是和 宿主机 一模一样才OK。</span></span><br><span class="line">docker run --<span class="built_in">rm</span> --gpus all nvidia/cuda:12.0.1-devel-ubuntu22.04 nvidia-smi</span><br><span class="line"></span><br><span class="line">docker run --<span class="built_in">rm</span> --gpus all nvidia/cuda:12.0.1-devel-ubuntu22.04 nvcc --version</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以额外测试。</span></span><br><span class="line"><span class="comment">#docker run --rm --gpus all nvidia/cuda:12.0.1-devel-ubuntu22.04 /bin/bash -c \</span></span><br><span class="line"><span class="string">&quot;apt update &amp;&amp; apt install -y cuda-samples-12-0 &amp;&amp; \</span></span><br><span class="line"><span class="string">cd /usr/local/cuda/samples/0_Simple/vectorAdd &amp;&amp; make &amp;&amp; ./vectorAdd&quot;</span></span><br><span class="line"><span class="comment"># 成功标志：输出 Test PASSED</span></span><br></pre></td></tr></table></figure>

<h3 id="3-2、nvidia-docker-与-NVIDIA-Container-Toolkit-的关系"><a href="#3-2、nvidia-docker-与-NVIDIA-Container-Toolkit-的关系" class="headerlink" title="3.2、nvidia-docker 与 NVIDIA Container Toolkit 的关系"></a>3.2、nvidia-docker 与 NVIDIA Container Toolkit 的关系</h3><p>nvidia-docker 与 NVIDIA Container Toolkit 的关系：<br>        NVIDIA Container Toolkit 的定位NVIDIA Container Toolkit 是一套工具集合，包含 nvidia-container-runtime、libnvidia-container 等组件，用于实现容器与 GPU 的深度集成。它取代了旧版 nvidia-docker 的核心功能。<br>是否需要单独安装 nvidia-docker？<br>        Docker ≥19.03 版本：无需安装 nvidia-docker。直接通过 Docker 的 –gpus 参数即可调用 GPU（例如 docker run –gpus all …），底层由 NVIDIA Container Toolkit 提供支持。旧版 Docker：需安装 nvidia-docker2 包作为插件，以兼容 GPU 调用。</p>
<h3 id="3-3、宿主机安装nvidia-cuda-toolkit"><a href="#3-3、宿主机安装nvidia-cuda-toolkit" class="headerlink" title="3.3、宿主机安装nvidia-cuda-toolkit"></a>3.3、宿主机安装nvidia-cuda-toolkit</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nvcc --version 如果没有就如下安装。</span></span><br><span class="line"><span class="comment"># sudo apt update </span></span><br><span class="line"><span class="comment"># sudo apt install nvidia-cuda-toolkit</span></span><br><span class="line">vim hello.cu</span><br><span class="line"><span class="comment"># _____________________________ hello.cu ____________________________________</span></span><br><span class="line"><span class="comment">#include &lt;cuda_runtime.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;stdio.h&gt;</span></span><br><span class="line"></span><br><span class="line">__global__ void <span class="function"><span class="title">hello</span></span>() &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello from GPU!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    hello&lt;&lt;&lt;<span class="string">1,1</span>&gt;&gt;&gt;();</span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># _____________________________ hello.cu ____________________________________</span></span><br><span class="line">nvcc --version <span class="comment">#  release 12.0, V12.0.140  Build cuda_12.0.r12.0/compiler.32267302_0</span></span><br><span class="line">nvcc -o hello hello.cu -<span class="built_in">arch</span>=sm_86 &amp;&amp; ./hello </span><br><span class="line"><span class="comment"># 输出 Hello from GPU! 算成功。</span></span><br></pre></td></tr></table></figure>

<h3 id="-1"><a href="#-1" class="headerlink" title></a></h3><h1 id="二、自建搜索引擎"><a href="#二、自建搜索引擎" class="headerlink" title="二、自建搜索引擎"></a>二、自建搜索引擎</h1><p>无论是 <code>DuckDuckGo</code> 还是 <code>Google Search Engine</code>，都需要科学上网才能正常使用。</p>
<p>所以我们就要自己搭建本地的搜索引擎。</p>
<h2 id="1、SearXNG-搜索引擎本地部署（二选一）"><a href="#1、SearXNG-搜索引擎本地部署（二选一）" class="headerlink" title="1、SearXNG 搜索引擎本地部署（二选一）"></a>1、SearXNG 搜索引擎本地部署（二选一）</h2><h3 id="1-1、Docker-compose版本（可浏览器使用，不可被AnythingLLM-x2F-open-webUI调用）"><a href="#1-1、Docker-compose版本（可浏览器使用，不可被AnythingLLM-x2F-open-webUI调用）" class="headerlink" title="1.1、Docker compose版本（可浏览器使用，不可被AnythingLLM&#x2F;open webUI调用）"></a>1.1、Docker compose版本（可浏览器使用，不可被AnythingLLM&#x2F;open webUI调用）</h3><p>我们还是用docker版本的，方便： </p>
<p>  <a target="_blank" rel="noopener" href="https://github.com/searxng/searxng-docker">https://github.com/searxng/searxng-docker</a><br>  <a target="_blank" rel="noopener" href="https://docs.searxng.org/">https://docs.searxng.org/</a><br>  <a target="_blank" rel="noopener" href="https://github.com/searxng/searxng/blob/master/searx/settings.yml">https://github.com/searxng/searxng/blob/master/searx/settings.yml</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 搞个存项目的文件夹，然后执行下面操作</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/searxng/searxng-docker.git</span><br><span class="line"><span class="built_in">cd</span> searxng-docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑.env文件以设置主机名和电子邮件</span></span><br><span class="line"><span class="comment"># 主机名可以写域名或者服务器IP，我这里写的 IP 和 Nginx Proxy Manager反向代理留的邮箱。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成密钥 </span></span><br><span class="line">sed -i <span class="string">&quot;s|ultrasecretkey|<span class="subst">$(openssl rand -hex 32)</span>|g&quot;</span> searxng/settings.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据需要编辑searchng/settings.yml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在第一次运行时，您必须从docker-compose.yaml文件中删除cap_drop：- ALL，以便searchng服务成功创建/etc/searxng/uwsgi. ini。这是必要的，因为cap_drop：- ALL指令将删除所有功能，包括创建uwsgi.ini文件所需的功能。在第一次运行后，出于安全原因，您应该将cap_drop：- ALL重新添加到docker-compose.yaml文件中。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除docker-compose.yaml中与caddy相关的部分，例如caddy服务及其卷。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将反向代理指向docker-compose.yml中为searchng服务设置的端口（默认为8080）</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过 docker compose down 命令停止当前运行的所有容器，同时清理网络和容器资源（默认保留数据卷）</span></span><br><span class="line">docker compose down</span><br><span class="line"><span class="comment"># 使用 docker compose up -d 重新构建并启动容器（自动应用最新配置）</span></span><br><span class="line">docker compose up -d</span><br></pre></td></tr></table></figure>

<h4 id="1-1-1、yaml："><a href="#1-1-1、yaml：" class="headerlink" title="1.1.1、yaml："></a>1.1.1、yaml：</h4><p><code>searxng/searxng-docker# cat docker-compose.yaml </code></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&quot;3.7&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="comment">#  caddy:</span></span><br><span class="line">  <span class="comment">#    container_name: caddy</span></span><br><span class="line">  <span class="comment">#    image: docker.io/library/caddy:2-alpine</span></span><br><span class="line">  <span class="comment"># network_mode: host</span></span><br><span class="line">  <span class="comment"># restart: unless-stopped</span></span><br><span class="line">  <span class="comment"># volumes:</span></span><br><span class="line">  <span class="comment">#   - ./Caddyfile:/etc/caddy/Caddyfile:ro</span></span><br><span class="line">  <span class="comment">#   - caddy-data:/data:rw</span></span><br><span class="line">  <span class="comment">#   - caddy-config:/config:rw</span></span><br><span class="line">  <span class="comment"># environment:</span></span><br><span class="line">  <span class="comment">#   - SEARXNG_HOSTNAME=$&#123;SEARXNG_HOSTNAME:-http://localhost&#125;</span></span><br><span class="line">  <span class="comment">#   - SEARXNG_TLS=$&#123;LETSENCRYPT_EMAIL:-internal&#125;</span></span><br><span class="line">  <span class="comment"># cap_drop:</span></span><br><span class="line">  <span class="comment">#   - ALL</span></span><br><span class="line">  <span class="comment"># cap_add:</span></span><br><span class="line">  <span class="comment">#   - NET_BIND_SERVICE</span></span><br><span class="line">  <span class="comment"># logging:</span></span><br><span class="line">  <span class="comment">#   driver: &quot;json-file&quot;</span></span><br><span class="line">  <span class="comment">#   options:</span></span><br><span class="line">  <span class="comment">#     max-size: &quot;1m&quot;</span></span><br><span class="line">  <span class="comment">#     max-file: &quot;1&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">redis</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker.io/valkey/valkey:8-alpine</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">valkey-server</span> <span class="string">--save</span> <span class="number">30</span> <span class="number">1</span> <span class="string">--loglevel</span> <span class="string">warning</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">unless-stopped</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">searxng</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">valkey-data2:/data</span></span><br><span class="line">    <span class="attr">cap_drop:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ALL</span></span><br><span class="line">    <span class="attr">cap_add:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SETGID</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SETUID</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">DAC_OVERRIDE</span></span><br><span class="line">    <span class="attr">logging:</span></span><br><span class="line">      <span class="attr">driver:</span> <span class="string">&quot;json-file&quot;</span></span><br><span class="line">      <span class="attr">options:</span></span><br><span class="line">        <span class="attr">max-size:</span> <span class="string">&quot;1m&quot;</span></span><br><span class="line">        <span class="attr">max-file:</span> <span class="string">&quot;1&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">searxng:</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">searxng</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker.io/searxng/searxng:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">unless-stopped</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">searxng</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;0.0.0.0:8080:8080&quot;</span>   <span class="comment"># 以后要改，测试给服务器以外的机器显示才这样写。</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./searxng:/etc/searxng:rw</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SEARXNG_BASE_URL=http://$&#123;SEARXNG_HOSTNAME:-localhost&#125;/</span>  <span class="comment"># 针对我的情况修改的。</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">UWSGI_WORKERS=$&#123;SEARXNG_UWSGI_WORKERS:-4&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">UWSGI_THREADS=$&#123;SEARXNG_UWSGI_THREADS:-4&#125;</span></span><br><span class="line"><span class="comment">#    cap_drop:            # 第一次 注释而已，之后启动 记得打开 。</span></span><br><span class="line"><span class="comment">#      - ALL</span></span><br><span class="line">    <span class="attr">cap_add:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">CHOWN</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SETGID</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SETUID</span></span><br><span class="line">    <span class="attr">logging:</span></span><br><span class="line">      <span class="attr">driver:</span> <span class="string">&quot;json-file&quot;</span></span><br><span class="line">      <span class="attr">options:</span></span><br><span class="line">        <span class="attr">max-size:</span> <span class="string">&quot;1m&quot;</span></span><br><span class="line">        <span class="attr">max-file:</span> <span class="string">&quot;1&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">searxng:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="comment">#caddy-data:</span></span><br><span class="line">  <span class="comment">#caddy-config:</span></span><br><span class="line">  <span class="attr">valkey-data2:</span></span><br></pre></td></tr></table></figure>

<h4 id="1-1-2、yaml解释："><a href="#1-1-2、yaml解释：" class="headerlink" title="1.1.2、yaml解释："></a>1.1.2、yaml解释：</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;127.0.0.1:8080:8080&quot;</span></span><br></pre></td></tr></table></figure>

<p>这表示将容器内部的 8080 端口映射到宿主机的 127.0.0.1 地址（即 localhost）的 8080 端口。<br><strong>含义</strong>：只有在服务器本机上访问 <code>127.0.0.1:8080</code> 才能看到服务。如果你在与服务器同一局域网的个人电脑上使用服务器 IP（例如 <code>192.168.1.100:8080</code>）访问，由于映射只绑定在 127.0.0.1 上，外部设备无法通过服务器外网 IP 访问到这个端口。<br>如果你希望局域网内的其他设备都能访问，可以将端口映射修改为：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;0.0.0.0:8080:8080&quot;</span></span><br></pre></td></tr></table></figure>

<p>环境变量</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">environment:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">SEARXNG_BASE_URL=https://$&#123;SEARXNG_HOSTNAME:-localhost&#125;/</span></span><br></pre></td></tr></table></figure>

<p>这表示默认使用 HTTPS 协议，并且如果环境变量 <code>SEARXNG_HOSTNAME</code> 没有设置，则使用 <code>localhost</code> 作为域名。</p>
<p>如果你的情况和我一样：</p>
<ul>
<li><p>你在局域网内做了 DNS 解析，但没有在公网做 DNS。</p>
</li>
<li><p>你设置了反向代理，但没有 TLS（即只提供 HTTP 访问）。</p>
<p>因此，你在局域网内通过 <code>http://局域网的域名</code> 来访问。<br>例如：</p>
</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">environment:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">SEARXNG_BASE_URL=http://$&#123;SEARXNG_HOSTNAME:-localhost&#125;/</span></span><br></pre></td></tr></table></figure>

<p>如果你不想使用域名，也可以直接使用服务器的 IP 地址，比如：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">environment:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">SEARXNG_BASE_URL=http://10.199.1.233/</span></span><br></pre></td></tr></table></figure>

<p>这里的 10.199.1.233  就是你服务器在局域网内的 IP 地址。</p>
<h4 id="1-1-3、修改setting-yml配置"><a href="#1-1-3、修改setting-yml配置" class="headerlink" title="1.1.3、修改setting.yml配置"></a>1.1.3、修改setting.yml配置</h4><p>找自己要添加的内容复制下来，黏贴进默认的setting.yml中就行了，这样好像不行。<br>选中国大陆能用的engine。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参考 https://github.com/searxng/searxng/blob/master/searx/settings.yml</span></span><br></pre></td></tr></table></figure>

<p>以下是我的 setting.yml 情况,加了一个 json 格式 和 bing engine。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">(base)</span> <span class="string">cys@cysserver:~/docker_data/searxng/searxng-docker$</span> <span class="string">cat</span> <span class="string">./searxng/settings.yml</span></span><br><span class="line"><span class="comment"># see https://docs.searxng.org/admin/settings/settings.html#settings-use-default-settings</span></span><br><span class="line"><span class="attr">use_default_settings:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="comment"># base_url is defined in the SEARXNG_BASE_URL environment variable, see .env and docker-compose.yml</span></span><br><span class="line">  <span class="attr">secret_key:</span> <span class="string">&quot;我的密钥&quot;</span>  <span class="comment"># change this!</span></span><br><span class="line">  <span class="attr">limiter:</span> <span class="literal">false</span>  <span class="comment">#true  # can be disabled for a private instance</span></span><br><span class="line">  <span class="attr">image_proxy:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">ui:</span></span><br><span class="line">  <span class="attr">static_use_hash:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">redis:</span></span><br><span class="line">  <span class="attr">url:</span> <span class="string">redis://redis:6379/0</span></span><br><span class="line"><span class="attr">engines:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">360search</span>      <span class="comment"># 适用于中国大陆</span></span><br><span class="line">    <span class="attr">engine:</span> <span class="string">360search</span></span><br><span class="line">    <span class="attr">shortcut:</span> <span class="string">360so</span></span><br><span class="line">    <span class="attr">disabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">bing</span></span><br><span class="line">    <span class="attr">engine:</span> <span class="string">bing</span></span><br><span class="line">    <span class="attr">shortcut:</span> <span class="string">bi</span></span><br><span class="line">    <span class="attr">disabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sogou</span></span><br><span class="line">    <span class="attr">engine:</span> <span class="string">sogou</span></span><br><span class="line">    <span class="attr">shortcut:</span> <span class="string">sogou</span></span><br><span class="line">    <span class="attr">disabled:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">search:</span></span><br><span class="line">  <span class="attr">formats:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">html</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">json</span>  <span class="comment"># 要能json格式，方便调用</span></span><br></pre></td></tr></table></figure>



<h4 id="1-1-4、登录searxng页面改搜索引擎："><a href="#1-1-4、登录searxng页面改搜索引擎：" class="headerlink" title="1.1.4、登录searxng页面改搜索引擎："></a>1.1.4、登录searxng页面改搜索引擎：</h4><p>因为大陆不方便用很多引擎，你懂的。所以我们用 中国大陆可以用的 bing 这些。</p>
<p>先登录 <a target="_blank" rel="noopener" href="http://ip:8080/">http://IP:8080</a>  在右上角配置。<img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E9%85%8D%E7%BD%AE.png" alt="配置"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E7%A4%BA%E4%BE%8B.png" alt="示例"></p>
<h3 id="1-2、Docker-版本（不可被AnythingLLM-x2F-open-webUI调用）"><a href="#1-2、Docker-版本（不可被AnythingLLM-x2F-open-webUI调用）" class="headerlink" title="1.2、Docker 版本（不可被AnythingLLM&#x2F;open webUI调用）"></a>1.2、Docker 版本（不可被AnythingLLM&#x2F;open webUI调用）</h3><p>参考：<br><a target="_blank" rel="noopener" href="https://docs.searxng.org/admin/installation-docker.html#installation-docker">https://docs.searxng.org/admin/installation-docker.html#installation-docker</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">sudo usermod -a -G docker <span class="variable">$USER</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">mkdir</span> my-instance</span><br><span class="line">$ <span class="built_in">cd</span> my-instance</span><br><span class="line">$ <span class="built_in">export</span> PORT=8080</span><br><span class="line">$ docker pull searxng/searxng</span><br><span class="line">$ docker run --<span class="built_in">rm</span> \</span><br><span class="line">             -d -p <span class="variable">$&#123;PORT&#125;</span>:8080 \</span><br><span class="line">             -v <span class="string">&quot;<span class="variable">$&#123;PWD&#125;</span>/searxng:/etc/searxng&quot;</span> \</span><br><span class="line">             -e <span class="string">&quot;BASE_URL=http://localhost:<span class="variable">$PORT</span>/&quot;</span> \</span><br><span class="line">             -e <span class="string">&quot;INSTANCE_NAME=my-instance&quot;</span> \</span><br><span class="line">             searxng/searxng</span><br><span class="line">2f998.... <span class="comment"># container&#x27;s ID</span></span><br><span class="line"><span class="comment"># --rm 选项的意思是“在容器退出后自动删除该容器”。这意味着一旦容器停止运行，Docker 会自动清理容器及其文件系统，这样可以防止系统中残留很多已停止的容器，从而节省存储空间和简化管理 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 环境变量UWSGI_WORKERS和UWSGI_THREADS将覆盖在/etc/searxng/uwsgi. ini中指定的UWSGI进程和UWSGI线程的默认数量。（可以不修改，也可以根据情况改）</span></span><br><span class="line"></span><br><span class="line">$ docker container <span class="built_in">ls</span></span><br><span class="line">CONTAINER ID   IMAGE             COMMAND                  CREATED         ...</span><br><span class="line">2f998d725993   searxng/searxng   <span class="string">&quot;/sbin/tini -- /usr/…&quot;</span>   7 minutes ago   ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改 setting.yml 文件，1.format 中加 json 格式；2.打开 bing 、sogou 等浏览器 disable false；然后重启。</span></span><br><span class="line">$ docker container restart 2f998</span><br><span class="line"></span><br><span class="line">xdg-open <span class="string">&quot;http://localhost:<span class="variable">$PORT</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ docker container stop 2f998</span><br><span class="line">$ docker container <span class="built_in">rm</span> 2f998</span><br></pre></td></tr></table></figure>





<h1 id="三、反向代理"><a href="#三、反向代理" class="headerlink" title="三、反向代理"></a>三、反向代理</h1><h2 id="1、安装Nginx-Proxy-Manager"><a href="#1、安装Nginx-Proxy-Manager" class="headerlink" title="1、安装Nginx Proxy Manager"></a>1、安装Nginx Proxy Manager</h2><p>官方文档：    <a target="_blank" rel="noopener" href="https://nginxproxymanager.com/guide/">https://nginxproxymanager.com/guide/</a> </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">vim docker-compose.yml</span><br><span class="line"></span><br><span class="line">version: <span class="string">&#x27;3.8&#x27;</span></span><br><span class="line">services:</span><br><span class="line">  app:</span><br><span class="line">    image: <span class="string">&#x27;jc21/nginx-proxy-manager:latest&#x27;</span></span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&#x27;80:80&#x27;</span></span><br><span class="line">      - <span class="string">&#x27;81:81&#x27;</span></span><br><span class="line">      - <span class="string">&#x27;443:443&#x27;</span></span><br><span class="line">    volumes:</span><br><span class="line">      - ./data:/data</span><br><span class="line">      - ./letsencrypt:/etc/letsencrypt</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>version: ‘3.8’<br>指定了 Compose 文件的版本。这里使用的是 3.8 版，这个版本支持的一些特性和语法在 Docker Compose v2.33.0 中是兼容的。</p>
<p>services:<br>定义了将要运行的容器服务。每个服务都是一个独立的容器。</p>
<p>app:<br>这是服务的名字，可以随意定义。这里用 “app” 来表示运行 Nginx Proxy Manager 的容器。</p>
<p>image: ‘jc21&#x2F;nginx-proxy-manager:latest’<br>指定了该服务使用的 Docker 镜像。</p>
<p>jc21&#x2F;nginx-proxy-manager 是镜像名称，:latest 表示使用最新版本的镜像。Docker 会自动从仓库中拉取该镜像（如果本地不存在的话）。<br>restart: unless-stopped<br>定义了容器的重启策略。</p>
<p>当容器异常退出时会自动重启，除非用户主动停止容器。<br>ports:<br>用于将容器内部的端口映射到主机的端口，使外部可以通过主机访问容器中的服务。</p>
<p>‘80:80’ 表示将主机的 80 端口映射到容器的 80 端口。<br>‘81:81’ 表示将主机的 81 端口映射到容器的 81 端口。<br>‘443:443’ 表示将主机的 443 端口映射到容器的 443 端口。<br>volumes:<br>用于将主机上的目录挂载到容器中，这样可以持久化数据和配置文件。</p>
<p>.&#x2F;data:&#x2F;data 将当前目录下的 data 文件夹挂载到容器内的 &#x2F;data 目录。<br>.&#x2F;letsencrypt:&#x2F;etc&#x2F;letsencrypt 将当前目录下的 letsencrypt 文件夹挂载到容器内的 &#x2F;etc&#x2F;letsencrypt 目录，用于存储 SSL 证书等数据。</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照 yml 给docker配置。</span></span><br><span class="line">docker compose up -d  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 独立安装则用 docker-compose up -d</span></span><br></pre></td></tr></table></figure>

<h2 id="2、npm的Web管理控制台"><a href="#2、npm的Web管理控制台" class="headerlink" title="2、npm的Web管理控制台"></a>2、npm的Web管理控制台</h2><p>一旦容器启动，你可以通过浏览器访问Nginx Proxy Manager的Web界面。默认地址是<code>http://&lt;your-server-ip&gt;:81</code>。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始密码：</span></span><br><span class="line">Email: admin@example.com</span><br><span class="line">Password: changeme</span><br><span class="line"></span><br><span class="line"><span class="comment"># 先做一个 DNS 解析，局域网的DNS 就在局域网访问，公网的DNS就在公网访问。下面代理中会用到DNS解析的域名Domain Names。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Nginx Proxy Manager 中设置您自己的域名</span></span><br><span class="line"><span class="comment"># 添加一个代理 add proxy host</span></span><br><span class="line"><span class="comment"># 下面的截图就是例子，以后点击 http://[域名] 就相当于 http://IP:port。  我这里咩有添加ssl，不能https访问。</span></span><br></pre></td></tr></table></figure>

<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250304153451.png" alt="微信图片_20250304153451"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250308112806.png" alt="微信图片_20250308112806"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250304153445.png" alt="微信图片_20250304153445"></p>
<p>可以测试一下 ，在局域网或者公网中能不能用 域名访问了。</p>
<p>可能需要等待一下才能生效。</p>
<blockquote>
<p>补充：免费域名注册 和 Cloudflare 域名解析</p>
<p>参考： <a target="_blank" rel="noopener" href="https://blog.csdn.net/u010522887/article/details/140786338">https://blog.csdn.net/u010522887/article/details/140786338</a><br>          <a target="_blank" rel="noopener" href="https://www.freedidi.com/17434.html">https://www.freedidi.com/17434.html</a><br>如果已经有了本地的 DNS 解析 也就不用了，局域网的DNS解析局域网用，公网的DNS解析公网用。</p>
</blockquote>
<h1 id="四、思路一：Ollama部署Deepseek"><a href="#四、思路一：Ollama部署Deepseek" class="headerlink" title="四、思路一：Ollama部署Deepseek"></a>四、思路一：Ollama部署Deepseek</h1><h2 id="1、安装ollama"><a href="#1、安装ollama" class="headerlink" title="1、安装ollama"></a>1、安装ollama</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://ollama.com/install.sh | sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我想要指定ollama下载模型的存放位置到系统盘，因为数据盘有80T，系统只有500G。</span></span><br><span class="line">sudo <span class="built_in">chown</span> -R ollama:ollama /home/cys/data/models</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改ollama服务配置，加几个环境参数Environment，实现访问指定文件夹、外机访问.</span></span><br><span class="line"><span class="comment"># 生产环境中，为了安全起见，建议将 OLLAMA_ORIGINS 设置为特定的域名或 IP 地址，以限制只有授权的来源才能访问服务.</span></span><br><span class="line">sudo vim /etc/systemd/system/ollama.service</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">[Unit]</span><br><span class="line">Description=Ollama Service</span><br><span class="line">After=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/local/bin/ollama serve</span><br><span class="line">User=ollama</span><br><span class="line">Group=ollama</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=3</span><br><span class="line">Environment=<span class="string">&quot;PATH=/home/cys/.local/bin:/home/cys/.local/bin:/home/cys/miniconda3/bin:/home/cys/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin&quot;</span></span><br><span class="line">Environment=<span class="string">&quot;OLLAMA_MODELS=/home/cys/data/models&quot;</span></span><br><span class="line">Environment=<span class="string">&quot;OLLAMA_HOST=0.0.0.0:11434&quot;</span></span><br><span class="line">Environment=<span class="string">&quot;OLLAMA_ORIGINS=*&quot;</span></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl <span class="built_in">enable</span> ollama</span><br><span class="line">sudo systemctl start ollama</span><br><span class="line">sudo systemctl status ollama</span><br><span class="line"></span><br><span class="line">ollama pull deepseek-r1:1.5b</span><br><span class="line">ollama list</span><br><span class="line"><span class="comment"># 查看指定文件夹中是否有了下载的新模型</span></span><br><span class="line">ll /home/cys/data/models/blobs/</span><br><span class="line"></span><br><span class="line">ollama run deepseek-r1:70b</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="2-1、方案一：（ollama-anythingllm-searxng-Nignx-proxy-manager）"><a href="#2-1、方案一：（ollama-anythingllm-searxng-Nignx-proxy-manager）" class="headerlink" title="2.1、方案一：（ollama+anythingllm+searxng+Nignx proxy manager）"></a>2.1、方案一：（ollama+anythingllm+searxng+Nignx proxy manager）</h2><p>用ollama在本地部署 deepseek-r1-70b模型，然后安装docker，在docker 中方便的下载镜像 AnythingLLM，容器化AnythingLLM实现RAG。</p>
<h3 id="2-1-1、Docker下安装AnythingLLM"><a href="#2-1-1、Docker下安装AnythingLLM" class="headerlink" title="2.1.1、Docker下安装AnythingLLM"></a>2.1.1、Docker下安装AnythingLLM</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker pull mintplexlabs/anythingllm</span></span><br><span class="line"><span class="comment"># 下面这样不好，还是要像官网一样指定容器到宿主机的映射好，这样更新了容器镜像啥的，数据可以从本地继承。</span></span><br><span class="line"><span class="comment"># docker run -d -p 3001:3001 --name AnythingLLM mintplexlabs/anythingllm</span></span><br><span class="line">docker pull mintplexlabs/anythingllm:latest</span><br><span class="line"></span><br><span class="line">docker stop AnythingLLM &amp;&amp; docker <span class="built_in">rm</span> AnythingLLM  <span class="comment"># 清理旧容器</span></span><br><span class="line"><span class="built_in">export</span> STORAGE_LOCATION=/home/cys/docker_data/anythingllm  <span class="comment"># 确保与原路径一致</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$STORAGE_LOCATION</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;STORAGE_LOCATION&#125;</span></span><br><span class="line"><span class="built_in">touch</span> .<span class="built_in">env</span></span><br><span class="line"></span><br><span class="line">docker run -d -p 3001:3001 \</span><br><span class="line">  --name AnythingLLM \</span><br><span class="line">  --network host \</span><br><span class="line">  --cap-add SYS_ADMIN \</span><br><span class="line">  -v <span class="variable">$&#123;STORAGE_LOCATION&#125;</span>:/app/server/storage \</span><br><span class="line">  -v <span class="variable">$&#123;STORAGE_LOCATION&#125;</span>/.env:/app/server/.env \</span><br><span class="line">  -e STORAGE_DIR=<span class="string">&quot;/app/server/storage&quot;</span> \</span><br><span class="line">  mintplexlabs/anythingllm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 外部用3001端口访问docker容器内部的3001端口，# 外部用3002端口访问docker容器内部的3001端口</span></span><br><span class="line"><span class="comment"># 同一个镜像做成了两个不同的容器，外部用不同的端口访问。实际部署记得分配好cpu内存等资源，怕两个容器打架抢。</span></span><br><span class="line"><span class="comment"># docker run -d -p 3001:3001 --name AnythingLLM mintplexlabs/anythingllm</span></span><br><span class="line"><span class="comment"># docker run -d -p 3002:3001 --name AnythingLLM2 mintplexlabs/anythingllm</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查容器运行</span></span><br><span class="line">docker ps | grep AnythingLLM  <span class="comment"># 应显示Up状态</span></span><br><span class="line"></span><br><span class="line">docker start AnythingLLM</span><br><span class="line">docker stop AnythingLLM</span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br></pre></td></tr></table></figure>

<h3 id="2-1-2、AnythingLLM控制界面配置"><a href="#2-1-2、AnythingLLM控制界面配置" class="headerlink" title="2.1.2、AnythingLLM控制界面配置"></a>2.1.2、AnythingLLM控制界面配置</h3><p>在外部机器，比如一台Windows机器，浏览器访问 Ubuntu机器的 IP:3001。</p>
<p>进入一步一步设置，推荐 选团队使用，可以添加使用成员。</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154513.png" alt="微信图片_20250228154513"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154507.png" alt="微信图片_20250228154507"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154516.png" alt="微信图片_20250228154516"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-02-28%2015.39.57.jpg" alt="截屏2025-02-28 15.39.57"></p>
<p>点击这一个workspace中的 上传 文件可以实现 RAG。</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154522.png" alt="微信图片_20250228154522"></p>
<p>点击这一个workspace中的设置按钮，在聊天设置可以把 这个workspace选择 chat模式或者查询模式，查询模式优先从知识库中找内容回答，chat 则优先使用 自己训练的模型为主，但是也会参考知识库。</p>
<p>点击下方 扳手🔧，可以进入agent代理打开联网搜索功能，但是注意有的是国内用不了的，有的要收费，推荐使用开源的本地部署的搜索引擎。</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250228154527.png" alt="微信图片_20250228154527"></p>
<p>tor浏览器的DuckDuckGo 浏览器在国内就不方便用。</p>
<h2 id="2-1、方案二：（ollama-open-web-UI-searxng-Nignx-proxy-manager）"><a href="#2-1、方案二：（ollama-open-web-UI-searxng-Nignx-proxy-manager）" class="headerlink" title="2.1、方案二：（ollama+open web UI+searxng+Nignx proxy manager）"></a>2.1、方案二：（ollama+open web UI+searxng+Nignx proxy manager）</h2><p>前提也是在安装好ollama 的基础上进行的。<br>参考：<br><a target="_blank" rel="noopener" href="https://github.com/open-webui/open-webui">https://github.com/open-webui/open-webui</a><br><a target="_blank" rel="noopener" href="https://www.composerize.com/">https://www.composerize.com/</a><br><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1MS9BYaEa5/?spm_id_from=333.337.search-card.all.click&amp;vd_source=a07523372ea1438247b770c295f20822">https://www.bilibili.com/video/BV1MS9BYaEa5/?spm_id_from=333.337.search-card.all.click&amp;vd_source=a07523372ea1438247b770c295f20822</a></p>
<p>先安装    【NVIDIA Container Toolkit NVIDIA容器工具包】<br>参考： <a target="_blank" rel="noopener" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p openwebui</span><br><span class="line"><span class="built_in">cd</span> openwebui </span><br><span class="line"></span><br><span class="line"><span class="comment"># 推荐还是用docker 方便管理，在open webUI 官网的GitHub 找到 本地有ollama 的安装命令，然后用composerize网站把这个命令转成 docker-compose.yml 的格式，方便管理。</span></span><br><span class="line"><span class="comment"># docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个 docker-compose.yml 的格式 文件，把刚才的 内容贴上去(见下方截图)。</span></span><br><span class="line">vim docker-compose.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据这个 docker-compose.yml  内容拉取</span></span><br><span class="line">docker compose pull </span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新构建并启动容器</span></span><br><span class="line">docker compose up -d </span><br><span class="line"><span class="comment"># 如果提示没有 volume 就建立一个 </span></span><br><span class="line"><span class="comment"># docker volume create open-webui</span></span><br><span class="line"><span class="comment"># docker restart open-webui</span></span><br><span class="line"><span class="comment"># 这一步需要等待2分钟，如果网络访问不到 openai官网的话。可参考下方补充内容《open webUI白屏问题解决》</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查容器内 日志 100行。(看看有没有启动，然后用浏览器进入3000端口检查一下)</span></span><br><span class="line">docker compose logs -f --<span class="built_in">tail</span>=100</span><br></pre></td></tr></table></figure>

<p>docker-compose.yml截图<br><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-09%2017.43.47.jpg" alt="截屏2025-03-09 17.43.47"></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">&lt;your</span> <span class="string">project</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">    <span class="attr">open-webui:</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="number">3000</span><span class="string">:8080</span></span><br><span class="line">        <span class="attr">deploy:</span></span><br><span class="line">            <span class="attr">resources:</span></span><br><span class="line">                <span class="attr">reservations:</span></span><br><span class="line">                    <span class="attr">devices:</span></span><br><span class="line">                        <span class="bullet">-</span> <span class="attr">driver:</span> <span class="string">nvidia</span></span><br><span class="line">                          <span class="attr">count:</span> <span class="string">all</span></span><br><span class="line">                          <span class="attr">capabilities:</span></span><br><span class="line">                              <span class="bullet">-</span> <span class="string">gpu</span></span><br><span class="line">        <span class="attr">extra_hosts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">host.docker.internal:host-gateway</span></span><br><span class="line">        <span class="attr">volumes:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">open-webui:/app/backend/data</span></span><br><span class="line">        <span class="attr">container_name:</span> <span class="string">open-webui</span></span><br><span class="line">        <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">ghcr.io/open-webui/open-webui:cuda</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">    <span class="attr">open-webui:</span></span><br><span class="line">        <span class="attr">external:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">open-webui</span></span><br></pre></td></tr></table></figure>

<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250309131910.png" alt="微信图片_20250309131910"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250309131717.png" alt="微信图片_20250309131717"></p>
<p> <img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/dl.png" alt="dl"></p>
<h3 id="2-1-1、联网搜索部署成功案例"><a href="#2-1-1、联网搜索部署成功案例" class="headerlink" title="2.1.1、联网搜索部署成功案例"></a>2.1.1、联网搜索部署成功案例</h3><p>参考：</p>
<p>​       <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Fgwn9DYit65sw7ql1S3Pfw">https://mp.weixin.qq.com/s/Fgwn9DYit65sw7ql1S3Pfw</a></p>
<h4 id="2-1-1-1、配置searxng"><a href="#2-1-1-1、配置searxng" class="headerlink" title="2.1.1.1、配置searxng"></a>2.1.1.1、配置searxng</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/cys/docker_data/searxng/searxng</span><br><span class="line"><span class="built_in">cd</span> /home/cys/docker_data/searxng/searxng</span><br><span class="line"></span><br><span class="line">vim settings.yml</span><br><span class="line"><span class="comment"># ---------------------------- settings.yml --------------------------------</span></span><br><span class="line">use_default_settings: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">general:</span><br><span class="line">  debug: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">engines:</span><br><span class="line">  <span class="comment"># 启用默认禁用的引擎</span></span><br><span class="line">  <span class="comment">#  - name: bing</span></span><br><span class="line">  <span class="comment">#  disabled: false</span></span><br><span class="line">  <span class="comment">#  delay: 5  # 每次请求间隔5秒</span></span><br><span class="line">  <span class="comment">#  enable_http: true    # 允许 HTTP 协议</span></span><br><span class="line">  <span class="comment">#  request_timeout: 30  # 延长超时至 30 秒（网页5建议45-60秒）</span></span><br><span class="line">  <span class="comment">#  url: https://cn.bing.com/search?q=&#123;query&#125;  # 强制使用国内版 </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  - name: bing</span></span><br><span class="line"><span class="comment">#   disabled: false</span></span><br><span class="line">  - name: bing</span><br><span class="line">    engine: bing</span><br><span class="line">    shortcut: bi</span><br><span class="line">    disabled: <span class="literal">false</span></span><br><span class="line"><span class="comment">#    request_timeout: 30</span></span><br><span class="line"></span><br><span class="line">  - name: bilibili</span><br><span class="line">    engine: bilibili</span><br><span class="line">    shortcut: bil</span><br><span class="line">    disabled: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 禁用默认启用的引擎</span></span><br><span class="line">  - name: archlinuxwiki</span><br><span class="line">    engine: archlinux</span><br><span class="line">    disabled: <span class="literal">true</span></span><br><span class="line">  - name: duckduckgo</span><br><span class="line">    engine: duckduckgo</span><br><span class="line">    distabled: <span class="literal">true</span></span><br><span class="line">  - name: github</span><br><span class="line">    engine: github</span><br><span class="line">    shortcut: gh</span><br><span class="line">    disabled: <span class="literal">true</span></span><br><span class="line">  - name: wikipedia</span><br><span class="line">    engine: wikipedia</span><br><span class="line">    disabled: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">server:</span><br><span class="line">  <span class="comment"># base_url is defined in the SEARXNG_BASE_URL environment variable, see .env and docker-compose.yml</span></span><br><span class="line">  secret_key: <span class="string">&quot;ultrasecretkkkkey&quot;</span>  <span class="comment"># change this! 这里一定要修改!!!!!!!!!</span></span><br><span class="line">  limiter: <span class="literal">false</span>  <span class="comment"># can be disabled for a private instance</span></span><br><span class="line">  image_proxy: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">search:</span><br><span class="line">  formats:</span><br><span class="line">    - html</span><br><span class="line">    - json  <span class="comment"># 允许以 json 形式返回结果</span></span><br><span class="line"></span><br><span class="line">ui:</span><br><span class="line">  static_use_hash: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">redis:</span><br><span class="line">  url: redis://redis:6379/0</span><br><span class="line"><span class="comment"># ------------------------------ settings.yml ------------------------------</span></span><br><span class="line"></span><br><span class="line">vim limiter.toml <span class="comment"># 该文件用于访问限制（反爬虫）。</span></span><br><span class="line"><span class="comment"># ------------------------------ limiter.toml ------------------------------</span></span><br><span class="line"><span class="comment"># See https://github.com/searxng/searxng/blob/master/searx/limiter.toml</span></span><br><span class="line">[botdetection.ip_limit]</span><br><span class="line"><span class="comment"># activate link_token method in the ip_limit method</span></span><br><span class="line">link_token = <span class="literal">false</span></span><br><span class="line"><span class="comment"># ------------------------------ limiter.toml ------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /home/cys/docker_data/searxng/</span><br><span class="line">vim docker-compose.yml</span><br><span class="line"><span class="comment"># ------------------------------ docker-compose.yml ------------------------------</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  redis:</span><br><span class="line">    container_name: redis</span><br><span class="line">    image: hub.mirrorify.net/valkey/valkey:8-alpine</span><br><span class="line">    <span class="built_in">command</span>: valkey-server --save 301 --loglevel warning</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    networks:</span><br><span class="line">      - searxng</span><br><span class="line">    volumes:</span><br><span class="line">      - valkey-data2:/data</span><br><span class="line">    cap_drop:</span><br><span class="line">      - ALL</span><br><span class="line">    cap_add:</span><br><span class="line">      - SETGID</span><br><span class="line">      - SETUID</span><br><span class="line">      - DAC_OVERRIDE</span><br><span class="line">    logging:</span><br><span class="line">      driver: <span class="string">&quot;json-file&quot;</span></span><br><span class="line">      options:</span><br><span class="line">        max-size: <span class="string">&quot;1m&quot;</span></span><br><span class="line">        max-file: <span class="string">&quot;1&quot;</span></span><br><span class="line"></span><br><span class="line">  searxng:</span><br><span class="line">    container_name: searxng</span><br><span class="line">    image: searxng/searxng:latest</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    networks:</span><br><span class="line">      - searxng</span><br><span class="line">    ports:</span><br><span class="line">      <span class="comment"># 这里设置 8081 端口</span></span><br><span class="line">      - 8081:8080</span><br><span class="line">    volumes:</span><br><span class="line">      - ./searxng:/etc/searxng:rw</span><br><span class="line">    environment:</span><br><span class="line">      - SEARXNG_BASE_URL=http://10.5.9.252:8081 <span class="comment"># https://$&#123;SEARXNG_HOSTNAME:-localhost&#125;/</span></span><br><span class="line">      - UWSGI_WORKERS=<span class="variable">$&#123;SEARXNG_UWSGI_WORKERS:-4&#125;</span></span><br><span class="line">      - UWSGI_THREADS=<span class="variable">$&#123;SEARXNG_UWSGI_THREADS:-4&#125;</span></span><br><span class="line">    <span class="comment"># 将容器的所有 Linux capabilities 去除，确保安全性。 再加入一些容器权限</span></span><br><span class="line">    cap_drop:    </span><br><span class="line">      - ALL</span><br><span class="line">    cap_add:</span><br><span class="line">      - CHOWN</span><br><span class="line">      - SETGID</span><br><span class="line">      - SETUID</span><br><span class="line">    logging:    </span><br><span class="line">      driver: <span class="string">&quot;json-file&quot;</span> <span class="comment"># 使用 JSON 文件格式保存日志</span></span><br><span class="line">      options:</span><br><span class="line">        max-size: <span class="string">&quot;1m&quot;</span>    <span class="comment"># 每个日志文件最大 1 MB</span></span><br><span class="line">        max-file: <span class="string">&quot;1&quot;</span>     <span class="comment"># 最多保留 1 个日志文件，防止日志无限增长导致磁盘占满。</span></span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  searxng:</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  valkey-data2:</span><br><span class="line"><span class="comment"># ------------------------------ docker-compose.yml ------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先停止已启动的服务</span></span><br><span class="line">docker compose down</span><br><span class="line"><span class="comment"># 启动服务 - 后台守护进程模式</span></span><br><span class="line">sudo docker compose up -d</span><br><span class="line"><span class="comment"># 启动服务 - 前台模式，当遇到问题需要结合日志即时分析时，可用这种模式启动</span></span><br><span class="line">sudo docker compose up </span><br></pre></td></tr></table></figure>

<blockquote>
<p>redis 服务中的 volumes，searxng 服务中的 volumes，以searxng为例。<br><strong>作用：</strong> 将宿主机当前目录下的 <code>./searxng</code> 文件夹挂载到 searxng 容器内部的 <code>/etc/searxng</code> 目录，并以读写模式（rw）挂载。<strong>意义：</strong> 这样可以直接在宿主机上编辑 searxng 的配置文件（比如 <code>settings.yml</code> 等），容器内会自动同步更新，从而方便管理和调试。</p>
<p>最底部的 volumes 部分</p>
<p><strong>作用：</strong> 在 Compose 文件的顶层声明一个名为 <code>valkey-data2</code> 的命名卷。<strong>意义：</strong> 这告诉 Docker Compose，这个卷由 Docker 管理，用于持久化存储。服务（比如 redis）在使用挂载时会自动关联到这个已声明的卷。<br>这行配置只是声明了一个名字叫 <code>valkey-data2</code> 的卷，Docker 会自动为它分配一个默认的存储位置（在 Linux 上通常是 <code>/var/lib/docker/volumes/valkey-data2/_data</code> 也可能有服务作为前缀）。</p>
<p>容器内的映射位置不是在这里指定的，而是在各个服务的 <code>volumes</code> 挂载时确定的。</p>
</blockquote>
<p>浏览器中访问 <a target="_blank" rel="noopener" href="http://10.5.9.252/">http://10.5.9.252</a> 的8081端口即可访问网页版本的searxng。</p>
<h4 id="2-1-1-2、安装配置-open-webUI"><a href="#2-1-1-2、安装配置-open-webUI" class="headerlink" title="2.1.1.2、安装配置 open webUI"></a>2.1.1.2、安装配置 open webUI</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拉取嵌入模型</span></span><br><span class="line">ollama pull bge-m3</span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p /home/cys/docker_data/openwebui2</span><br><span class="line"><span class="built_in">cd</span> /home/cys/docker_data/openwebui2</span><br><span class="line"></span><br><span class="line">vim docker-compose.yml</span><br><span class="line"><span class="comment"># ------------------------------ docker-compose.yml ------------------------------</span></span><br><span class="line">services:</span><br><span class="line">  open-webui:</span><br><span class="line">    <span class="comment"># image: ghcr.io/open-webui/open-webui:main</span></span><br><span class="line">    image: ghcr.io/open-webui/open-webui:cuda</span><br><span class="line">    <span class="comment">#image: ghcr.mirrorify.net/open-webui/open-webui:main</span></span><br><span class="line">    environment:</span><br><span class="line">      <span class="comment"># 日志全局为全局 DEBUG 模式，可以打印更多的信息。在需分析问题时可配置，其他时间可注释</span></span><br><span class="line">      - GLOBAL_LOG_LEVEL=DEBUG</span><br><span class="line">      <span class="comment"># ollama 访问地址。请确保已安装了 ollama</span></span><br><span class="line">      - OLLAMA_API_BASE_URL=http://10.5.9.252:11434</span><br><span class="line">      <span class="comment"># 自定义 HF 国内代理地址</span></span><br><span class="line">      - HF_ENDPOINT=https://hf-mirror.com</span><br><span class="line">      <span class="comment"># 自定义网站名称</span></span><br><span class="line">      <span class="comment"># - WEBUI_NAME=&quot;OWU&quot;</span></span><br><span class="line">      <span class="comment"># 禁用 openAI，否则登录时会因为请求它超时而白屏</span></span><br><span class="line">      - ENABLE_OPENAI_API=<span class="literal">false</span></span><br><span class="line">      <span class="comment"># 如果有 open AI 服务的代理地址，可以通过这里指定</span></span><br><span class="line">      - OPENAI_API_BASE_URL=https://api.openai.com/v1</span><br><span class="line">      <span class="comment"># 允许所有来源的站点跨域请求服务 API。若服务部署到了互联网访问，不要这么配置</span></span><br><span class="line">      - CORS_ALLOW_ORIGIN=*</span><br><span class="line">      <span class="comment"># 指定默认嵌入模型，请注意先拉取该模型：ollama pull bge-m3</span></span><br><span class="line">      - RAG_EMBEDDING_MODEL=bge-m3</span><br><span class="line">      <span class="comment"># 指定默认使用的模型。请先拉取该模型：ollama pull deepseek-r1:8b</span></span><br><span class="line">      - DEFAULT_MODELS=deepseek-r1:70b</span><br><span class="line">      <span class="comment"># 允许新用户注册</span></span><br><span class="line">      - ENABLE_OAUTH_SIGNUP=<span class="literal">true</span></span><br><span class="line">    ports:</span><br><span class="line">      - 8080:8080</span><br><span class="line">    volumes:</span><br><span class="line">      - ./open_webui_data:/app/backend/data</span><br><span class="line"><span class="comment"># ------------------------------ docker-compose.yml ------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先停止已启动的服务</span></span><br><span class="line">docker compose down</span><br><span class="line"><span class="comment"># 启动服务 - 后台守护进程模式</span></span><br><span class="line">sudo docker compose up -d</span><br><span class="line"><span class="comment"># 启动服务 - 前台模式，当遇到问题需要结合日志即时分析时，可用这种模式启动</span></span><br><span class="line">sudo docker compose up </span><br></pre></td></tr></table></figure>

<h4 id="2-1-1-3、网页中配置"><a href="#2-1-1-3、网页中配置" class="headerlink" title="2.1.1.3、网页中配置"></a>2.1.1.3、网页中配置</h4><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095926.png" alt="微信图片_20250311095926"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095931.png" alt="微信图片_20250311095931"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095937.png" alt="微信图片_20250311095937"></p>
<p>在配置【Searxng 查询 URL】</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://10.5.9.252:8081/search?time_range=&amp;categories=general&amp;language=auto&amp;locale=zh-Hans-CN&amp;image_proxy=1&amp;safesearch=0&amp;theme=simple&amp;disabled_engines=currency__general,wikidata__general,duckduckgo__general,google__general,lingva__general,qwant__general&amp;enabled_engines=bing__general,brave__general</span><br></pre></td></tr></table></figure>

<blockquote>
<p>可查看如下地址中 Open-WebUI 接入 SearXNG 的实现源码了解其具体逻辑：</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/open-webui/open-webui/blob/main/backend/open_webui/retrieval/web/searxng.py">https://github.com/open-webui/open-webui/blob/main/backend/open_webui/retrieval/web/searxng.py</a></p>
</blockquote>
</blockquote>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095941.png" alt="微信图片_20250311095941"></p>
<p>效果图如下：</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095945-1658497.png" alt="微信图片_20250311095945"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250311095807.png" alt="微信图片_20250311095807"></p>
<p>效果并不好，经常会出现搜不到的情况。</p>
<h3 id="2-1-2、补充说明部分"><a href="#2-1-2、补充说明部分" class="headerlink" title="2.1.2、补充说明部分"></a>2.1.2、补充说明部分</h3><h4 id="2-1-2-1、本地数据映射、迁移"><a href="#2-1-2-1、本地数据映射、迁移" class="headerlink" title="2.1.2.1、本地数据映射、迁移"></a>2.1.2.1、本地数据映射、迁移</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">valkey-data2:/data</span></span><br><span class="line">    </span><br><span class="line">  <span class="attr">searxng:</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./searxng:/etc/searxng:rw</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">searxng:</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">valkey-data2:</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>以前面配置 searxng 为例<br>redis 服务中的 volumes映射 以及searxng 服务中的 volumes 映射，以searxng为例。<br><strong>作用：</strong> 将宿主机当前目录下的 <code>./searxng</code> 文件夹挂载到 searxng 容器内部的 <code>/etc/searxng</code> 目录，并以读写模式（rw）挂载。<strong>意义：</strong> 这样可以直接在宿主机上编辑 searxng 的配置文件（比如 <code>settings.yml</code> 等），容器内会自动同步更新，从而方便管理和调试。</p>
<p>最底部的 volumes 部分</p>
<p><strong>作用：</strong> 在 Compose 文件的顶层声明一个名为 <code>valkey-data2</code> 的命名卷（没有指定映射到容器中的某个位置）。<strong>意义：</strong> 这告诉 Docker Compose，这个卷由 Docker 管理，用于持久化存储。服务（比如 redis）在使用挂载时会自动关联到这个已声明的卷。<br>这行配置只是声明了一个名字叫 <code>valkey-data2</code> 的卷，Docker 会自动为它分配一个默认的存储位置（在 Linux 上通常是 <code>/var/lib/docker/volumes/valkey-data2/_data</code> 也可能有服务作为前缀）。</p>
<p>容器内的映射位置不是在这里指定的，而是在各个服务的 <code>volumes</code> 挂载时确定的。</p>
</blockquote>
<p>命名卷 valkey-data2 挂载到 redis 容器内的 &#x2F;data 目录。也就是说，redis 在 &#x2F;data 下写入的数据都会存储到这个命名卷中。</p>
<p>如果服务运行很久产生大量数据，这些数据会写入到容器中被映射的目录（比如 redis 的 &#x2F;data），而最终存放在宿主机上对应命名卷的默认位置（如 &#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;valkey-data2&#x2F;_data）。</p>
<p>如果你想自定义宿主机上的存储位置（例如改为 <code>/data/docker-data/sear</code>），你不能在顶层的 <code>volumes</code> 声明里直接指定宿主机目录，而是需要在服务的 <code>volumes</code> 映射中使用绑定挂载的方式。例如，对于 searxng 服务，如果原来是这样写：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">./searxng:/etc/searxng:rw</span></span><br><span class="line"><span class="comment"># 以及</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">valkey-data2:/data</span></span><br></pre></td></tr></table></figure>

<p>你可以修改为：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/data/docker-data/sear:/etc/searxng:rw</span></span><br><span class="line"><span class="comment"># 以及</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/data/docker-data/redis:/data</span></span><br></pre></td></tr></table></figure>

<p>这样，容器中 <code>/etc/searxng</code> 的所有数据就会直接存储在宿主机的 <code>/data/docker-data/sear</code> 目录中，而不再使用默认的 <code>./searxng</code> 目录。（需要提前有这个文件夹且权限打开）<br><strong>注意：radis要频繁 IO 操作，不建议修改位置到别的磁盘。</strong></p>
<p>把原来的 文件夹 cp 过去，然后 在改yaml 文件，重新 docker compose up -d ，可以迁移了，如果还是不成功，可以在docker logs 【容器名&#x2F;id】 看看日志提示。</p>
<h4 id="2-1-2-2、日志"><a href="#2-1-2-2、日志" class="headerlink" title="2.1.2.2、日志"></a>2.1.2.2、日志</h4><p>日志文件默认存储在宿主机的 <code>/var/lib/docker/containers/&lt;container-id&gt;/</code> 目录中。<br>日志文件由 Docker 引擎管理，<strong>与容器共存亡</strong>。当容器被删除（如执行 <code>docker compose down</code>）后，其日志文件也会被清理。</p>
<p>如果希望将日志文件存储在特定的宿主机目录中，您可以使用 Docker 的 <code>local</code> 日志驱动程序，并指定 <code>log-path</code>。</p>
<p>请注意，直接将 Redis 的日志输出到文件可能会影响性能，不建议。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">open-webui:</span></span><br><span class="line">    <span class="comment"># ...（其他配置）</span></span><br><span class="line">    <span class="attr">logging:</span></span><br><span class="line">      <span class="attr">driver:</span> <span class="string">&quot;json-file&quot;</span></span><br><span class="line">      <span class="attr">options:</span></span><br><span class="line">        <span class="attr">max-size:</span> <span class="string">&quot;10m&quot;</span></span><br><span class="line">        <span class="attr">max-file:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./open_webui_data:/app/backend/data</span></span><br></pre></td></tr></table></figure>



<h4 id="2-1-2-3、改换嵌入模型"><a href="#2-1-2-3、改换嵌入模型" class="headerlink" title="2.1.2.3、改换嵌入模型"></a>2.1.2.3、改换嵌入模型</h4><p>见 目录《思路二：vllm部署Deepseek》</p>
<h4 id="2-1-2-4、RAG"><a href="#2-1-2-4、RAG" class="headerlink" title="2.1.2.4、RAG"></a>2.1.2.4、RAG</h4><p>点击工作空间；点击“知识库”选项；传好文件；再点击模型；在编辑中选择关联上哪些知识库即可。</p>
<h4 id="2-1-2-5、自建searxng搜索引擎插件实现微信搜索"><a href="#2-1-2-5、自建searxng搜索引擎插件实现微信搜索" class="headerlink" title="2.1.2.5、自建searxng搜索引擎插件实现微信搜索"></a>2.1.2.5、自建searxng搜索引擎插件实现微信搜索</h4><p>要读源码自己仿写，暂时没写，难度不大。</p>
<h4 id="2-1-2-6、让用户能够自己注册"><a href="#2-1-2-6、让用户能够自己注册" class="headerlink" title="2.1.2.6、让用户能够自己注册"></a>2.1.2.6、让用户能够自己注册</h4><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250314105527.png" alt="微信图片_20250314105527"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250314105533.png" alt="微信图片_20250314105533"></p>
<h1 id="四、思路二：vllm部署Deepseek"><a href="#四、思路二：vllm部署Deepseek" class="headerlink" title="四、思路二：vllm部署Deepseek"></a>四、思路二：vllm部署Deepseek</h1><h2 id="1、方案：（vllm-open-web-UI-searxng-Nignx-proxy-manager）"><a href="#1、方案：（vllm-open-web-UI-searxng-Nignx-proxy-manager）" class="headerlink" title="1、方案：（vllm+open web UI+searxng+Nignx proxy manager）"></a>1、方案：（vllm+open web UI+searxng+Nignx proxy manager）</h2><h3 id="1-1、modelscope本地下载大模型"><a href="#1-1、modelscope本地下载大模型" class="headerlink" title="1.1、modelscope本地下载大模型"></a>1.1、modelscope本地下载大模型</h3><p>国内用modelscope本地下载大模型，为vllm调用作铺垫。</p>
<p><a target="_blank" rel="noopener" href="https://www.modelscope.cn/models/">https://www.modelscope.cn/models/</a><br><strong>注意</strong>：如果多GPU需下载 <strong>DeepSeek-R1-70B-AWQ</strong> 分片版模型（支持张量并行），以下只是演示没有选AWQ版本。<br>假如下载的模型是不带AWQ的，即便是你在 yml 文件中写的 使用多卡GPU，也会实际用一个GPU的显存，极有可能出现暴显存的情况。<img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-20%2009.33.12.jpg" alt="截屏2025-03-20 09.33.12"><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-20%2009.32.32.jpg" alt="截屏2025-03-20 09.32.32"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-18%2020.42.40.jpg" alt="截屏2025-03-18 20.42.40"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-18%2021.05.23.jpg" alt="截屏2025-03-18 21.05.23"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-18%2021.07.18.jpg" alt="截屏2025-03-18 21.07.18"></p>
<p>推荐使用modelscope 下载到指定位置。</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250318211815.png" alt="微信图片_20250318211815"></p>
<h3 id="1-2、vllm部署"><a href="#1-2、vllm部署" class="headerlink" title="1.2、vllm部署"></a>1.2、vllm部署</h3><h4 id="1-2-1、vllm单机多卡部署"><a href="#1-2-1、vllm单机多卡部署" class="headerlink" title="1.2.1、vllm单机多卡部署"></a>1.2.1、vllm单机多卡部署</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/cys/docker_data/vLLM</span><br><span class="line"><span class="built_in">cd</span> /home/cys/docker_data/vLLM</span><br><span class="line"></span><br><span class="line"><span class="comment"># nvcc --version 如果没有就如下安装。</span></span><br><span class="line"><span class="comment"># sudo apt update </span></span><br><span class="line"><span class="comment"># sudo apt install nvidia-cuda-toolkit</span></span><br><span class="line">vim hello.cu</span><br><span class="line"><span class="comment"># _____________________________ hello.cu ____________________________________</span></span><br><span class="line"><span class="comment">#include &lt;cuda_runtime.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;stdio.h&gt;</span></span><br><span class="line"></span><br><span class="line">__global__ void <span class="function"><span class="title">hello</span></span>() &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello from GPU!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    hello&lt;&lt;&lt;<span class="string">1,1</span>&gt;&gt;&gt;();</span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># _____________________________ hello.cu ____________________________________</span></span><br><span class="line">nvcc --version <span class="comment">#  release 12.0, V12.0.140  Build cuda_12.0.r12.0/compiler.32267302_0</span></span><br><span class="line">nvcc -o hello hello.cu -<span class="built_in">arch</span>=sm_86 &amp;&amp; ./hello </span><br><span class="line"><span class="comment"># 输出 Hello from GPU! 算成功。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个外部网络</span></span><br><span class="line">docker network create vllm-network</span><br><span class="line"></span><br><span class="line">vim docker-compose.yml</span><br><span class="line"><span class="comment"># _____________________________ docker-compose.yml ____________________________________</span></span><br><span class="line">services:</span><br><span class="line">  vllm-openai:</span><br><span class="line">    runtime: nvidia</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    container_name: deepseek-container</span><br><span class="line">    ipc: host  <span class="comment"># 使用主机 IPC 命名空间</span></span><br><span class="line">    image: vllm/vllm-openai:latest</span><br><span class="line">    volumes:</span><br><span class="line">      - /home/cys/data/models/deepseek-r1-70b-AWQ:/models/deepseek-r1-70b:ro</span><br><span class="line">    <span class="built_in">command</span>:</span><br><span class="line">      - <span class="string">&quot;--model=/models/deepseek-r1-70b&quot;</span></span><br><span class="line">      - <span class="string">&quot;--tensor_parallel_size=2&quot;</span></span><br><span class="line">      - <span class="string">&quot;--pipeline_parallel_size=1&quot;</span></span><br><span class="line">      - <span class="string">&quot;--gpu_memory_utilization=0.95&quot;</span>  <span class="comment"># 调高利用率以增加 KV Cache 内存</span></span><br><span class="line">      - <span class="string">&quot;--max_model_len=8192&quot;</span>         <span class="comment"># 根据需要调整最大序列长度</span></span><br><span class="line">      - <span class="string">&quot;--served-model-name=deepseek-r1-70b-AWQ&quot;</span></span><br><span class="line">      - <span class="string">&quot;--dtype=half&quot;</span></span><br><span class="line">      - <span class="string">&quot;--api-key=jisudf*&amp;QW123&quot;</span></span><br><span class="line">      - <span class="string">&quot;--swap_space=8&quot;</span></span><br><span class="line">    environment:</span><br><span class="line">      - CUDA_VISIBLE_DEVICES=0,1</span><br><span class="line">      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True</span><br><span class="line">      - NCCL_DEBUG=INFO</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;8000:8000&quot;</span></span><br><span class="line">    deploy:  <span class="comment"># 非 docker Swarm 内置集群 模式下，deploy 部分的配置通常不会被应用</span></span><br><span class="line">      resources:</span><br><span class="line">        reservations:</span><br><span class="line">          devices:</span><br><span class="line">            - driver: nvidia</span><br><span class="line">              count: 2</span><br><span class="line">              capabilities: [gpu]</span><br><span class="line">    networks:</span><br><span class="line">      - my-network</span><br><span class="line">    logging:</span><br><span class="line">      driver: json-file</span><br><span class="line">      options:</span><br><span class="line">        max-size: <span class="string">&quot;100m&quot;</span></span><br><span class="line">        max-file: <span class="string">&quot;3&quot;</span></span><br><span class="line">networks:</span><br><span class="line">  my-network:</span><br><span class="line">    external: <span class="literal">true</span></span><br><span class="line">    name: vllm-network</span><br><span class="line"><span class="comment"># _____________________________ docker-compose.yml ____________________________________</span></span><br><span class="line"></span><br><span class="line">docker compose up -d </span><br><span class="line">docker logs deepseek-container <span class="comment"># 检查容器日志，还可以检查一下。nvidia-smi</span></span><br></pre></td></tr></table></figure>

<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250320144426.png" alt="微信图片_20250320144426"></p>
<p>显卡跑起来了，看见 显存被搞起来了，说明调用成功。</p>
<h4 id="1-2-2、vllm多机多卡部署"><a href="#1-2-2、vllm多机多卡部署" class="headerlink" title="1.2.2、vllm多机多卡部署"></a>1.2.2、vllm多机多卡部署</h4><p>参考：</p>
<p><a target="_blank" rel="noopener" href="https://docs.vllm.ai/en/latest/serving/distributed_serving.html">https://docs.vllm.ai/en/latest/serving/distributed_serving.html</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/tdubYmXNt98ZN6SB7iMIrw">https://mp.weixin.qq.com/s/tdubYmXNt98ZN6SB7iMIrw</a></p>
<p>先在另一台机器中安装好和第一台机器一样的 环境（推荐docker 搞），当从节点。</p>
<p>从第一台机器（主节点）中把模型复制过来。</p>
<p>下载一个vllm 官方的脚本（cluster启动脚本）。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/vllm-project/vllm/blob/main/examples/online_serving/run_cluster.sh</span><br></pre></td></tr></table></figure>

<h5 id="1-2-2-1、选项一：通过swarm部署"><a href="#1-2-2-1、选项一：通过swarm部署" class="headerlink" title="1.2.2.1、选项一：通过swarm部署"></a>1.2.2.1、选项一：通过swarm部署</h5><h5 id="Docker-Swarm-集群基础"><a href="#Docker-Swarm-集群基础" class="headerlink" title="Docker Swarm 集群基础"></a>Docker Swarm 集群基础</h5><p>参考：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1ZM4m1Z75k/?spm_id_from=333.337.search-card.all.click&amp;vd_source=a07523372ea1438247b770c295f20822">https://www.bilibili.com/video/BV1ZM4m1Z75k/?spm_id_from=333.337.search-card.all.click&amp;vd_source=a07523372ea1438247b770c295f20822</a></p>
<p>docker swarm 和 docker compose一样都是为了简化 容器化程序的部署、管理和扩展的工具。</p>
<p>docker compose 单机上用而已。</p>
<p>docker swarm 集群用。</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2008.58.17.png" alt="截屏2025-03-27 08.58.17"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.02.04.png" alt="截屏2025-03-27 09.02.04"></p>
<p>下面的例子 是 两个 manager 节点 两个 worker 节点 组成的4个 node 的 swarm集群例子。</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.40.40.png" alt="截屏2025-03-27 09.40.40"></p>
<h6 id="·-初始化集群："><a href="#·-初始化集群：" class="headerlink" title="· 初始化集群："></a>· 初始化集群：<img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.07.42.png" alt="截屏2025-03-27 09.07.42"></h6><h6 id="·-加入节点："><a href="#·-加入节点：" class="headerlink" title="· 加入节点："></a>· 加入节点：</h6><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.08.23.png" alt="截屏2025-03-27 09.08.23"></p>
<p>docker node ls 查看 有哪些节点。</p>
<h6 id="·-集群解散："><a href="#·-集群解散：" class="headerlink" title="· 集群解散："></a>· 集群解散：</h6><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.11.50.png" alt="截屏2025-03-27 09.11.50"></p>
<h6 id="·-节点管理："><a href="#·-节点管理：" class="headerlink" title="· 节点管理："></a>· 节点管理：</h6><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.15.37.png" alt="截屏2025-03-27 09.15.37"></p>
<h6 id="·-服务管理："><a href="#·-服务管理：" class="headerlink" title="· 服务管理："></a>· 服务管理：</h6><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.20.15.png" alt="截屏2025-03-27 09.20.15"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.22.01.png" alt="截屏2025-03-27 09.22.01"></p>
<blockquote>
<p>replicas 是 2 说明 搞了两个副本容器在集群中，但是具体分配给了哪两个节点 由调度策略来决定，注意一共就是 两个容器 ，副本的意思不是 说再复制出2个一共3个，别误会了。</p>
<p>source 是 宿主机的映射目录，target是 容器内部的 目录，用bing直接映射挂载。</p>
</blockquote>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.35.18.png" alt="截屏2025-03-27 09.35.18"></p>
<blockquote>
<p>docker service ls 看见 属性中的 replicas 2&#x2F;2 3&#x2F;3 1&#x2F;1 5&#x2F;5 前后数字一致 说明有2个replicas副本，有2个成功运行，以此类推。前后不一致说明没有正常运行。</p>
</blockquote>
<blockquote>
<p> 服务定义好以后，是在集群中的全部 node 都能访问的，但是容器并不是在每一个节点中运行，仅仅是在调度分配的节点中运行。</p>
</blockquote>
<h6 id="·-swarm集群弹性伸缩："><a href="#·-swarm集群弹性伸缩：" class="headerlink" title="· swarm集群弹性伸缩："></a>· swarm集群弹性伸缩：</h6><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.53.01.png" alt="截屏2025-03-27 09.53.01"></p>
<h6 id="·-swarm集群服务滚动更新："><a href="#·-swarm集群服务滚动更新：" class="headerlink" title="· swarm集群服务滚动更新："></a>· swarm集群服务滚动更新：</h6><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2009.56.58.png" alt="截屏2025-03-27 09.56.58"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker service update --replicas=5</span><br><span class="line">--image mysql:8.0</span><br><span class="line">--update-delay 60s</span><br><span class="line">--update-parallelism 5</span><br><span class="line">mydb</span><br></pre></td></tr></table></figure>

<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.04.10.png" alt="截屏2025-03-27 10.04.10"></p>
<p>60秒后 4个node 中出现了5个更新到 mysql8.0的服务容器。</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.05.33.png" alt="截屏2025-03-27 10.05.33"></p>
<h6 id="·-swarm集群中使用docker-compose："><a href="#·-swarm集群中使用docker-compose：" class="headerlink" title="· swarm集群中使用docker compose："></a>· swarm集群中使用docker compose：</h6><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.45.28.png" alt="截屏2025-03-27 10.45.28"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.46.19.png" alt="截屏2025-03-27 10.46.19"></p>
<blockquote>
<p>可以把 这么多个副本全部落到指定的node 节点中。</p>
<p>docker compose up 是单机启动方式，会忽略 deploy 内容。</p>
</blockquote>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2010.53.38.png" alt="截屏2025-03-27 10.53.38"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stack deploy -c yml文件名 自定义stack名</span><br></pre></td></tr></table></figure>

<p>docker swarm 中不支持 name 属性的定义<br><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-27%2013.55.39.png" alt="截屏2025-03-27 13.55.39"></p>
<p>docker swarm 和 k8s 是竞争关系，但是 docker swarm 没有竞争过k8s，但是docker swarm依然有它的意义。</p>
<h5 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h5><p>在 Docker Swarm 的集群架构中，<strong>所有 YAML 文件都需要在主节点上运行</strong>。</p>
<h6 id="·-docker-swarm-GPU支持"><a href="#·-docker-swarm-GPU支持" class="headerlink" title="· docker swarm GPU支持"></a>· docker swarm GPU支持</h6><p>参考  <a target="_blank" rel="noopener" href="https://gist.github.com/coltonbh/374c415517dbeb4a6aa92f462b9eb287">https://gist.github.com/coltonbh/374c415517dbeb4a6aa92f462b9eb287</a></p>
<p>对主从节点每一台机器作如下操作：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi -a <span class="comment"># 查看 GPU的具体 uuid</span></span><br><span class="line"></span><br><span class="line">sudo vim /etc/docker/daemon.json</span><br><span class="line"><span class="comment"># 改成如下</span></span><br><span class="line"><span class="comment"># NVIDIA-GPU 名字是可以自定义的，调用的时候注意点。</span></span><br><span class="line">------------------------------------ daemon.json ------------------------------------</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;registry-mirrors&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;https://docker.m.daocloud.io&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.ccs.tencentyun.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://func.ink&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://proxy.1panel.live&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.zhai.cm&quot;</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;default-runtime&quot;</span>: <span class="string">&quot;nvidia&quot;</span>,</span><br><span class="line">    <span class="string">&quot;runtimes&quot;</span>: &#123;</span><br><span class="line">      <span class="string">&quot;nvidia&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;path&quot;</span>: <span class="string">&quot;nvidia-container-runtime&quot;</span>,</span><br><span class="line">        <span class="string">&quot;runtimeArgs&quot;</span>: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;node-generic-resources&quot;</span>: [</span><br><span class="line">      <span class="string">&quot;NVIDIA-GPU=GPU-c8fcc40e-7aef-0401-1519-2e8b2ef1521b&quot;</span>,</span><br><span class="line">      <span class="string">&quot;NVIDIA-GPU=GPU-a27b8ea5-b0bf-3a21-90ff-e9417f58ff11&quot;</span></span><br><span class="line">      ]</span><br><span class="line">&#125;</span><br><span class="line">------------------------------------ daemon.json ------------------------------------</span><br></pre></td></tr></table></figure>

<p>在主节点机器中 编辑 vllm-head.yml vllm-worker1.yml vllm-worker1.yml 等</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">vim vllm-head.yml </span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  vllm-head:</span><br><span class="line">    image: vllm/vllm-openai:latest</span><br><span class="line">    <span class="comment">#container_name: vllm-head</span></span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    <span class="built_in">command</span>:</span><br><span class="line">      - <span class="string">&quot;--head&quot;</span></span><br><span class="line">      - <span class="string">&quot;--model=/models/deepseek-r1-70b&quot;</span></span><br><span class="line">      - <span class="string">&quot;--tensor_parallel_size=2&quot;</span>         <span class="comment"># 单机 GPU 数（2卡并行）</span></span><br><span class="line">      - <span class="string">&quot;--pipeline_parallel_size=2&quot;</span>       <span class="comment"># 总节点数（主+1从）</span></span><br><span class="line">      - <span class="string">&quot;--served-model-name=deepseek-r1-70b-AWQ&quot;</span></span><br><span class="line">      - <span class="string">&quot;--max-model-len=8192&quot;</span></span><br><span class="line">      - <span class="comment"># 加上一些约束条件，让 显存不要跑爆了，才能正常启动，可以参考单机情况。</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /home/cys/data/models/deepseek-r1-70b-AWQ:/models/deepseek-r1-70b-AWQ:ro</span><br><span class="line">    environment:</span><br><span class="line">      <span class="comment">#- NVIDIA_VISIBLE_DEVICES=all         # 让容器能访问所有 GPU</span></span><br><span class="line">      <span class="comment">#- NVIDIA_DRIVER_CAPABILITIES=all</span></span><br><span class="line">      - CUDA_VISIBLE_DEVICES=0,1           <span class="comment"># 只使用 0 和 1 号 GPU</span></span><br><span class="line">      <span class="comment">#- NVIDIA_VISIBLE_DEVICES=0,1</span></span><br><span class="line">      - VLLM_HOST_IP=10.5.9.252            <span class="comment"># 主节点 IP</span></span><br><span class="line">      - RAY_HEAD_IP=10.5.9.252             <span class="comment"># Ray 通信地址</span></span><br><span class="line">      - RAY_HEAD_PORT=6379</span><br><span class="line">      - NCCL_SOCKET_IFNAME=enp1s0          <span class="comment"># 跨节点通信接口</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;8000:8000&quot;</span></span><br><span class="line">      - <span class="string">&quot;6379:6379&quot;</span></span><br><span class="line">    networks:</span><br><span class="line">      vllm-cluster:</span><br><span class="line">        ipv4_address: 10.10.0.100</span><br><span class="line">    deploy:</span><br><span class="line">      placement:</span><br><span class="line">        constraints:</span><br><span class="line">          - node.hostname == cysserver     <span class="comment"># # 只在 指定  的节点上运行</span></span><br><span class="line">      resources:</span><br><span class="line">        reservations:</span><br><span class="line">          generic_resources:</span><br><span class="line">            - discrete_resource_spec:</span><br><span class="line">                kind: <span class="string">&quot;nvidia-gpu&quot;</span>         <span class="comment">#&quot;NVIDIA-GPU&quot;</span></span><br><span class="line">                value: 2</span><br><span class="line">networks:</span><br><span class="line">  vllm-cluster:</span><br><span class="line">    driver: overlay</span><br><span class="line">    ipam:</span><br><span class="line">      config:</span><br><span class="line">        - subnet: 10.10.0.0/24</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">vim vllm-worker.yml</span><br><span class="line"><span class="comment"># 对 deploy 部分 做类似上面的修改。</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  vllm-worker:</span><br><span class="line">    runtime: nvidia</span><br><span class="line">    image: vllm/vllm-openai:latest</span><br><span class="line">    <span class="comment">#container_name: vllm-worker</span></span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    <span class="built_in">command</span>:</span><br><span class="line">      - <span class="string">&quot;--worker&quot;</span></span><br><span class="line">      - <span class="string">&quot;--model=/models/deepseek-r1-70b&quot;</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /home/cys/models/deepseek-r1-70b-AWQ:/models/deepseek-r1-70b:ro</span><br><span class="line">    environment:</span><br><span class="line">      - CUDA_VISIBLE_DEVICES=1             <span class="comment"># 仅使用第二块 GPU</span></span><br><span class="line">      - RAY_HEAD_IP=10.5.9.252:6379        <span class="comment"># 指向主节点</span></span><br><span class="line">      - NCCL_SOCKET_IFNAME=eno1            <span class="comment"># 通信网卡接口</span></span><br><span class="line">    networks:</span><br><span class="line">      vllm-cluster:</span><br><span class="line">        ipv4_address: 10.10.0.101          <span class="comment"># 不同从节点需修改 IP</span></span><br><span class="line">    deploy:</span><br><span class="line">      placement:</span><br><span class="line">        constraints:</span><br><span class="line">          - node.hostname == cys           <span class="comment"># 强制只在名为cys的节点运行</span></span><br><span class="line">          <span class="comment">#- node.labels.gpu == 1           # 确保从节点有 1 块 GPU</span></span><br><span class="line">       <span class="comment"># 对 deploy 部分 做类似上面主节点的修改。</span></span><br><span class="line">networks:</span><br><span class="line">  vllm-cluster:</span><br><span class="line">    external: <span class="literal">true</span>                         <span class="comment"># 复用主节点网络</span></span><br><span class="line">    name: vllm-cluster</span><br></pre></td></tr></table></figure>

<p>加标签，yml 文件中有通过标签 指定服务具体落在的哪个节点。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker node update --label-add node.hostname=cys cys</span><br><span class="line">docker node update --label-add node.hostname=cysserver cysserver</span><br></pre></td></tr></table></figure>

<p>在主节点机器上 作 swarm 初始化，然后在各个从节点 以worker身份加入 warm 集群。</p>
<p>具体操作 参考 什么的Docker Swarm基础。</p>
<h6 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h6><p>通过 docker swarm 集群部署的 大模型，并没有实现 对算力资源的 汇总，而仅仅是像一个普通的分布式应用一样选择把服务部署在哪一个节点中运行，顶多只是 这个节点坏了，有一个 新节点 补充 类似这样。</p>
<p>如果每一个节点的GPU 资源都不足以部署此大模型， 那这样的 docker swarm 集群部署 大模型无法成功，所以这种 集群分布式部署不是我们要的 方式。</p>
<p>那我们应该用哪一种 分布式的部署方式呢？</p>
<p>答案就在vllm 的官网中，其实 下载 vllm github 中的 分布式部署脚本，可以用它自带的ray 集群实现对资源的整合调度。</p>
<h5 id="1-2-2-2、选项二：通过-ray-集群部署"><a href="#1-2-2-2、选项二：通过-ray-集群部署" class="headerlink" title="1.2.2.2、选项二：通过 ray 集群部署"></a>1.2.2.2、选项二：通过 ray 集群部署</h5><p>参考：<a target="_blank" rel="noopener" href="https://docs.vllm.ai/en/latest/serving/distributed_serving.html">https://docs.vllm.ai/en/latest/serving/distributed_serving.html</a><br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/fflQZOcNCAcltpzm6hB7AA">https://mp.weixin.qq.com/s/fflQZOcNCAcltpzm6hB7AA</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/tdubYmXNt98ZN6SB7iMIrw">https://mp.weixin.qq.com/s/tdubYmXNt98ZN6SB7iMIrw</a></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E6%88%AA%E5%B1%8F2025-03-30%2018.37.48.jpg" alt="截屏2025-03-30 18.37.48"></p>
<p>上面的swarm集群部署解决不了资源整合的 问题导致了单个节点资源不足就无法在这个节点部署服务。</p>
<p>为了解决此问题，我们用vllm 推荐的 分布式部署方式。（我在swarm 集群部署上面绕了一个好大的弯，以后都优先使用官网推荐的最佳实践，不要自己折腾，费劲不讨好。）</p>
<p>下载官方多节点脚本到本地</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/cys/docker_data/vLLM</span><br><span class="line"></span><br><span class="line"><span class="comment"># 网页上的 blob 改成 raw 就能直接哟个 wget 下载下来。</span></span><br><span class="line"><span class="comment"># https://github.com/vllm-project/vllm/blob/main/examples/online_serving/run_cluster.sh</span></span><br><span class="line">wget https://github.com/vllm-project/vllm/raw/main/examples/online_serving/run_cluster.sh</span><br></pre></td></tr></table></figure>

<p><strong>部署ray集群</strong></p>
<p><strong>主节点10.5.9.252</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bash run_cluster.sh \</span><br><span class="line">                vllm/vllm-openai \</span><br><span class="line">                10.5.9.252 \</span><br><span class="line">                --<span class="built_in">head</span> \</span><br><span class="line">                /home/cys/data/models/deepseek-r1-70b-AWQ \</span><br><span class="line">                -v /home/cys/data/models/deepseek-r1-70b-AWQ/:/model/deepseek-r1-70b-AWQ/ \</span><br><span class="line">                -e VLLM_HOST_IP=10.5.9.252 \</span><br><span class="line">                -e GLOO_SOCKET_IFNAME=enp1s0 \</span><br><span class="line">                -e NCCL_SOCKET_IFNAME=enp1s0</span><br></pre></td></tr></table></figure>

<blockquote>
<p>enp1s0 是 看ip 走那个网口 得出的</p>
</blockquote>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330182312.png" alt="微信图片_20250330182312"></p>
<p>此时再开一个窗口，进入主节点的容器中查看ray 集群。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it f474c557b8a6 /bin/bash</span><br><span class="line">root@cysserver:/vllm-workspace<span class="comment"># ray status </span></span><br><span class="line">======== Autoscaler status: 2025-03-30 03:27:55.102175 ========</span><br><span class="line">Node status</span><br><span class="line">---------------------------------------------------------------</span><br><span class="line">Active:</span><br><span class="line"> 1 node_8e51bfc57e87e7c4c7c44817444eabd64c1b2fd109e67d065110c5a1</span><br><span class="line">Pending:</span><br><span class="line"> (no pending nodes)</span><br><span class="line">Recent failures:</span><br><span class="line"> (no failures)</span><br><span class="line"></span><br><span class="line">Resources</span><br><span class="line">---------------------------------------------------------------</span><br><span class="line">Usage:</span><br><span class="line"> 0.0/24.0 CPU</span><br><span class="line"> 0.0/2.0 GPU</span><br><span class="line"> 0B/484.01GiB memory</span><br><span class="line"> 0B/9.73GiB object_store_memory</span><br><span class="line"></span><br><span class="line">Demands:</span><br><span class="line"> (no resource demands)</span><br></pre></td></tr></table></figure>

<p><strong>从节点10.5.9.253</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">先统一 ray 版本</span><br><span class="line"><span class="comment"># 主从节点之间，vllm-openai 镜像版本差异导致 Ray 版本不同，推荐 </span></span><br><span class="line"><span class="comment"># docker save -o vllm.tar vllm/vllm-openai:ddddddd版本在docker ps -a查看，可以是latest</span></span><br><span class="line"><span class="comment"># md5sum vllm.tar &gt; vllm.tar.md5</span></span><br><span class="line"><span class="comment"># 传输过，连带着md5文件。scp vllm.tar* cys@10.5.9.252:/home/cys/data/models/docker-images-warehouse</span></span><br><span class="line"><span class="comment"># 在机器2执行</span></span><br><span class="line"><span class="comment"># cd /home/cys/data/models/docker-images-warehouse</span></span><br><span class="line"><span class="comment"># 验证 md5sum -c vllm.tar.md5 看看ok不ok。</span></span><br><span class="line"><span class="comment"># 删除 老的版本的 vllm ，docker rmi XXXXXXX  </span></span><br><span class="line"><span class="comment"># docker load -i vllm.tar</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bash run_cluster.sh \</span><br><span class="line">                vllm/vllm-openai \</span><br><span class="line">                10.5.9.252 \</span><br><span class="line">                --worker \</span><br><span class="line">                /home/cys/models/deepseek-r1-70b-AWQ \</span><br><span class="line">                -v /home/cys/models/deepseek-r1-70b-AWQ/:/model/deepseek-r1-70b-AWQ/ \</span><br><span class="line">                -e VLLM_HOST_IP=10.5.9.253 \</span><br><span class="line">                -e GLOO_SOCKET_IFNAME=eno1 \</span><br><span class="line">                -e NCCL_SOCKET_IFNAME=eno1</span><br></pre></td></tr></table></figure>

<blockquote>
<p>eno1 是 看ip 走那个网口 得出的</p>
</blockquote>
<p>此时再开一个窗口，进入主节点的容器中查看ray 集群。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it f474c557b8a6 /bin/bash</span><br><span class="line">root@cysserver:/vllm-workspace<span class="comment"># ray status </span></span><br><span class="line">======== Autoscaler status: 2025-03-30 11:21:02.211262 ========</span><br><span class="line">Node status</span><br><span class="line">---------------------------------------------------------------</span><br><span class="line">Active:</span><br><span class="line"> 1 node_921f86c035112492b0daccabd0f373361ea3a721370c3cbcc1dc32ea</span><br><span class="line"> 1 node_4260699a5c1bfdf24d9a886b7aec5e38b7f5e42ab38a2427c13e8366</span><br><span class="line">Pending:</span><br><span class="line"> (no pending nodes)</span><br><span class="line">Recent failures:</span><br><span class="line"> (no failures)</span><br><span class="line"></span><br><span class="line">Resources</span><br><span class="line">---------------------------------------------------------------</span><br><span class="line">Usage:</span><br><span class="line"> 0.0/48.0 CPU</span><br><span class="line"> 0.0/4.0 GPU</span><br><span class="line"> 0B/725.54GiB memory</span><br><span class="line"> 0B/19.46GiB object_store_memory</span><br><span class="line"></span><br><span class="line">Demands:</span><br><span class="line"> (no resource demands)</span><br></pre></td></tr></table></figure>

<p>在ray集群部署好之后可以看见，在一台机器上可以调用整个集群的资源了。<br>在主节点进入vllm的容器，启动 vllm 服务</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it f474c557b8a6 /bin/bash</span><br><span class="line"><span class="comment"># --tensor-parallel-size 单台机器的GPU数量，--pipeline-parallel-size 节点数量，vllm GPU只能1 2 4 8 这样的总数量运行。</span></span><br><span class="line"> vllm serve /model/deepseek-r1-70b-AWQ \</span><br><span class="line">     --tensor-parallel-size 2 \</span><br><span class="line">     --pipeline-parallel-size 2 \</span><br><span class="line">     --max-model-len 53520 \</span><br><span class="line">     --gpu-memory-utilization 0.8 \</span><br><span class="line">     --served-model-name deepseek-r1-70b-AWQ \</span><br><span class="line">     --api-key <span class="string">&#x27;jisudf*&amp;QW123&#x27;</span></span><br><span class="line">     </span><br><span class="line"><span class="comment"># 更推荐这样 先在这个容器中建立一个 logs 文件夹然后搞一个 vllm.log 文件存日志。</span></span><br><span class="line"><span class="built_in">nohup</span> vllm serve /model/deepseek-r1-70b-AWQ \</span><br><span class="line">     --tensor-parallel-size 2 \</span><br><span class="line">     --pipeline-parallel-size 2 \</span><br><span class="line">     --max-model-len 53520 \</span><br><span class="line">     --gpu-memory-utilization 0.8 \</span><br><span class="line">     --served-model-name deepseek-r1-70b-AWQ \</span><br><span class="line">     --api-key <span class="string">&#x27;jisudf*&amp;QW123&#x27;</span> \</span><br><span class="line">  &gt; ./logs/vllm.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330222345.png" alt="微信图片_20250330222345"></p>
<blockquote>
<p>如果换模型为千问，上面一步一步改成这样</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># host机器</span></span><br><span class="line">bash run_cluster.sh     vllm/vllm-openai     10.5.9.252     --<span class="built_in">head</span>     /home/cys/data/models/Qwen2.5-72B-Instruct-AWQ     -v /home/cys/data/models/Qwen2.5-72B-Instruct-AWQ:/model/Qwen2.5-72B-Instruct-AWQ     -e VLLM_HOST_IP=10.5.9.252     -e GLOO_SOCKET_IFNAME=enp1s0     -e NCCL_SOCKET_IFNAME=enp1s0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 奴隶机器</span></span><br><span class="line">bash run_cluster.sh     vllm/vllm-openai     10.5.9.252     --worker     /home/cys/data/models/Qwen2.5-72B-Instruct-AWQ     -v /home/cys/data/models/Qwen2.5-72B-Instruct-AWQ:/model/Qwen2.5-72B-Instruct-AWQ     -e VLLM_HOST_IP=10.5.9.251     -e GLOO_SOCKET_IFNAME=eno3np0     -e NCCL_SOCKET_IFNAME=eno3np0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># host机器进入容器</span></span><br><span class="line"><span class="built_in">nohup</span> vllm serve /model/Qwen2.5-72B-Instruct-AWQ \</span><br><span class="line">  --tensor-parallel-size 2 \</span><br><span class="line">  --pipeline-parallel-size 2 \</span><br><span class="line">  --max-model-len 21104 \</span><br><span class="line">  --gpu-memory-utilization 0.8 \</span><br><span class="line">  --served-model-name Qwen2.5-72B-Instruct-AWQ \</span><br><span class="line">  --api-key <span class="string">&#x27;jisudf*&amp;QW123&#x27;</span> \</span><br><span class="line">  &gt; ./logs/vllm.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="1-3、嵌入模型部署"><a href="#1-3、嵌入模型部署" class="headerlink" title="1.3、嵌入模型部署"></a>1.3、嵌入模型部署</h3><p>参考： <a target="_blank" rel="noopener" href="https://blog.csdn.net/make_progress/article/details/146051006">https://blog.csdn.net/make_progress/article/details/146051006</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/huggingface/text-embeddings-inference">https://github.com/huggingface/text-embeddings-inference</a></p>
<p>文本嵌入推理（TEI，Text Embeddings Inference ）是HuggingFace研发的一个用于部署和服务开源文本嵌入和序列<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B&spm=1001.2101.3001.7020">分类模型</a>的工具包。TEI兼容OpenAI的嵌入模型的规范。 我们用到的就是它。<br>我们选用 bge-large-zh-v1.5 模型。</p>
<p>先在国内的ModelScope上下载BAAI&#x2F;bge-reranker-large模型；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modelscope download --model BAAI/bge-large-zh-v1.5 --local_dir /home/cys/data/models/embeddingModel/.    </span><br></pre></td></tr></table></figure>

<p>建立一个 docker 容器专门提供嵌入服务；</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/cys/docker_data/embeddingModel</span><br><span class="line"><span class="built_in">mkdir</span> -p bge-large-zh-v1.5</span><br><span class="line"><span class="built_in">cd</span> /home/cys/docker_data/embeddingModel/bge-large-zh-v1.5</span><br><span class="line"></span><br><span class="line">vim docker-compose.yml</span><br><span class="line">------------------------------ docker-compose.yml ------------------------------</span><br><span class="line">services:</span><br><span class="line">  text-embeddings-inference:</span><br><span class="line">    user: <span class="string">&quot;0:0&quot;</span></span><br><span class="line">    image: ghcr.io/huggingface/text-embeddings-inference:1.6</span><br><span class="line">    <span class="comment">#runtime: nvidia</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;8002:80&quot;</span></span><br><span class="line">    volumes:</span><br><span class="line">      - <span class="string">&quot;/home/cys/data/models/embeddingModel:/data&quot;</span>  <span class="comment"># bge-large-zh-v1.5:/data&quot;</span></span><br><span class="line">    environment:</span><br><span class="line">      - EMBEDDING_API_KEY=wiekdoid@JIDj124123</span><br><span class="line">    <span class="built_in">command</span>: [<span class="string">&quot;--model-id&quot;</span>, <span class="string">&quot;/data/bge-large-zh-v1.5&quot;</span>, <span class="string">&quot;--auto-truncate&quot;</span>]</span><br><span class="line">    networks:</span><br><span class="line">      - my-network  <span class="comment"># 直接引用已存在的网络</span></span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  my-network:</span><br><span class="line">    external: <span class="literal">true</span>  <span class="comment"># 只引用外部已存在的网络</span></span><br><span class="line">    name: vllm-network</span><br><span class="line">------------------------------ docker-compose.yml ------------------------------</span><br><span class="line"></span><br><span class="line">docker compose up -d</span><br></pre></td></tr></table></figure>

<p>检查是否可用</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST <span class="string">&quot;http://localhost:8002/embed&quot;</span> -H <span class="string">&quot;Content-Type: application/json&quot;</span> -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;inputs&quot;: [&quot;你好，世界&quot;],</span></span><br><span class="line"><span class="string">  &quot;truncate&quot;: false</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 看看 会不会返回false。</span></span><br></pre></td></tr></table></figure>

<p>注意：TEI当前不会自动截断输入。您可以通过在请求中设置<code>truncate: true</code>来启用此功能。</p>
<p>在官网github中可见 </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--auto-truncate</span><br><span class="line">    Automatically <span class="built_in">truncate</span> inputs that are longer than the maximum supported size</span><br><span class="line"></span><br><span class="line">    Unused <span class="keyword">for</span> gRPC servers</span><br><span class="line"></span><br><span class="line">    [<span class="built_in">env</span>: AUTO_TRUNCATE=]</span><br></pre></td></tr></table></figure>



<h3 id="1-4、open-webUI调用vllm"><a href="#1-4、open-webUI调用vllm" class="headerlink" title="1.4、open webUI调用vllm"></a>1.4、open webUI调用vllm</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/cys/docker_data/openwebui2</span><br><span class="line"><span class="built_in">cd</span> /home/cys/docker_data/openwebui2</span><br><span class="line"></span><br><span class="line">vim docker-compose.yml </span><br><span class="line"><span class="comment"># _____________________________ docker-compose.yml ____________________________________</span></span><br><span class="line">services:</span><br><span class="line">  open-webui:</span><br><span class="line">    image: ghcr.io/open-webui/open-webui:cuda</span><br><span class="line">    environment:</span><br><span class="line">      <span class="comment"># 禁用 ollama 连接（注释或删除该行）</span></span><br><span class="line">      <span class="comment"># - OLLAMA_API_BASE_URL=http://10.5.9.252:11434</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 启用 OpenAI 兼容 API（必须开启）</span></span><br><span class="line">      - ENABLE_OPENAI_API=<span class="literal">true</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 指向本地 vLLM 的 OpenAI 兼容接口,即使你设置 container_name 为 deepseek-container，Docker内部仍然会将这个容器注册为服务名 vllm-openai，所以其他同网络的容器可以通过 “vllm-openai” 访问它</span></span><br><span class="line">      <span class="comment"># 这里看前面vllm中怎么写，如果写了http://10.5.9.252:8000/v1 这里也要写这个。</span></span><br><span class="line">      - OPENAI_API_BASE_URL=http://vllm-openai:8000/v1     </span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 设置与 vLLM 一致的 API 密钥</span></span><br><span class="line">      - OPENAI_API_KEYS=jisudf*&amp;QW123</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 其他原有配置保持不变</span></span><br><span class="line">      - GLOBAL_LOG_LEVEL=DEBUG</span><br><span class="line">      - HF_ENDPOINT=https://hf-mirror.com</span><br><span class="line">      - CORS_ALLOW_ORIGIN=*</span><br><span class="line">      - RAG_EMBEDDING_MODEL=bge-m3</span><br><span class="line">      - DEFAULT_MODELS=deepseek-r1-70b-AWQ  <span class="comment"># 需与 vLLM 的 --served-model-name 参数一致</span></span><br><span class="line">      - ENABLE_OAUTH_SIGNUP=<span class="literal">true</span></span><br><span class="line">    ports:</span><br><span class="line">      - 8080:8080</span><br><span class="line">    volumes:</span><br><span class="line">      - /home/cys/data/docker-data/open_webui_data:/app/backend/data</span><br><span class="line">    networks:</span><br><span class="line">      - my-network</span><br><span class="line">networks:</span><br><span class="line">  my-network:</span><br><span class="line">    external: <span class="literal">true</span></span><br><span class="line">    name: vllm-network</span><br><span class="line"><span class="comment"># _____________________________ docker-compose.yml ____________________________________</span></span><br><span class="line"></span><br><span class="line">docker compose up -d </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>再在web页面配置一下连接上 vllm 。<br><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250320155359.png" alt="微信图片_20250320155359"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250320155402.png" alt="微信图片_20250320155402"></p>
<p>分布式vllm ，open webUI如下：</p>
<p>docker-compose.yml</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">open-webui:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ghcr.io/open-webui/open-webui:cuda</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="comment"># 禁用 ollama 连接（注释或删除该行）</span></span><br><span class="line">      <span class="comment"># - OLLAMA_API_BASE_URL=http://10.5.9.252:11434</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 启用 OpenAI 兼容 API（必须开启）</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ENABLE_OPENAI_API=true</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 指向本地 vLLM 的 OpenAI 兼容接口,即使你设置 container_name 为 deepseek-container，Docker内部仍然会将这个容器注册为服务名 vllm-openai，所以其他同网络的容器可以通过 “vllm-openai” 访问它</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">OPENAI_API_BASE_URL=http://vllm-openai:8000/v1</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 设置与 vLLM 一致的 API 密钥</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">OPENAI_API_KEYS=jisudf*&amp;QW123</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 其他原有配置保持不变</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">GLOBAL_LOG_LEVEL=DEBUG</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">HF_ENDPOINT=https://hf-mirror.com</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">CORS_ALLOW_ORIGIN=*</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RAG_EMBEDDING_MODEL=bge-m3</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">DEFAULT_MODELS=deepseek-r1-70b-AWQ</span>  <span class="comment"># 需与 vLLM 的 --served-model-name 参数一致</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ENABLE_OAUTH_SIGNUP=true</span></span><br><span class="line">      <span class="comment"># 设置默认的 Embedding 模型名称（用于内部记录或日志）</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RAG_EMBEDDING_MODEL=bge-large-zh-v1.5</span></span><br><span class="line">      <span class="comment"># 指定 Embedding API 服务的地址，确保该地址在同一网络内可访问</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">EMBEDDING_API_BASE_URL=http://10.5.9.252:8002/v1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">EMBEDDING_API_KEYS=wiekdoid@JIDj124123</span>     <span class="comment"># 这里用相同的 Key 关联上</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8080</span><span class="string">:8080</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/cys/data/docker-data/open_webui_data:/app/backend/data</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">my-network</span></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">my-network:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">vllm-network</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>以上加入了 嵌入模型的调用，别的没有太大变化。</p>
</blockquote>
<p>记得在open webUI web管理界面添加 嵌入模型。</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250402181950-3589288.png" alt="微信图片_20250402181950"></p>
<h1 id="附加：可能遇到的若干问题："><a href="#附加：可能遇到的若干问题：" class="headerlink" title="附加：可能遇到的若干问题："></a>附加：可能遇到的若干问题：</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过 docker compose down 命令停止当前运行的所有容器，同时清理网络和容器资源（默认保留数据卷）</span></span><br><span class="line">docker compose down</span><br><span class="line"><span class="comment"># 使用 docker compose up -d 重新构建并启动容器（自动应用最新配置）</span></span><br><span class="line">docker compose up -d</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 停止所有容器</span></span><br><span class="line">docker compose stop</span><br><span class="line"><span class="comment"># 修改 YAML 文件后重启</span></span><br><span class="line">docker compose up -d</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 若仅修改某一服务的配置，可单独重启该服务（避免影响其他服务）</span></span><br><span class="line">docker compose up -d --no-deps &lt;服务名&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 看看 此项目文件夹下有哪些 docker compose 服务在运行</span></span><br><span class="line"><span class="string">docker</span> <span class="string">compose</span> <span class="string">ps</span></span><br></pre></td></tr></table></figure>

<h4 id="·-AnythingLLM数据迁移"><a href="#·-AnythingLLM数据迁移" class="headerlink" title="· AnythingLLM数据迁移"></a>· AnythingLLM数据迁移</h4><p>如果是 之前 拉取anythingllm 没有做本地的映射，在更新anythingllm 的时候，一定要做好 数据的转移。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">docker start AnythingLLM</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建临时备份目录</span></span><br><span class="line"><span class="built_in">mkdir</span> ~/anythingllm_backup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将容器内数据拷贝到宿主机（需容器仍在运行）</span></span><br><span class="line">docker <span class="built_in">cp</span> AnythingLLM:/app/server/storage XXXXXXXXX/anythingllm</span><br><span class="line"><span class="comment"># 注意：一定要将 .env 文件单独 挪到 XXXXXXXXX/anythingllm 并检查几个sig_key sig_salt其他密钥。</span></span><br><span class="line"><span class="built_in">cp</span> XXXXX/XXXX/.env XXXXXXXXX/anythingllm  <span class="comment"># 重要！！！！！</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> STORAGE_LOCATION=XXXXXXXXX/anythingllm  <span class="comment"># 定义存储路径变量</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$STORAGE_LOCATION</span> &amp;&amp; <span class="built_in">chmod</span> -R 777 <span class="variable">$STORAGE_LOCATION</span>  <span class="comment"># 创建目录并赋权</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">cp</span> -r ~/anythingllm_backup/* <span class="variable">$STORAGE_LOCATION</span>/</span><br><span class="line"><span class="built_in">cp</span> -r ~/anythingllm_backup/storage/* <span class="variable">$STORAGE_LOCATION</span>/</span><br><span class="line"></span><br><span class="line">docker ps -a  <span class="comment"># 显示所有容器</span></span><br><span class="line">docker stop AnythingLLM </span><br><span class="line"></span><br><span class="line">docker <span class="built_in">rm</span> AnythingLLM</span><br><span class="line"></span><br><span class="line">docker images</span><br><span class="line">docker rmi &lt;旧镜像ID&gt;</span><br><span class="line"></span><br><span class="line">docker stop AnythingLLM &amp;&amp; docker <span class="built_in">rm</span> AnythingLLM  <span class="comment"># 清理旧容器</span></span><br><span class="line">docker pull mintplexlabs/anythingllm:latest</span><br><span class="line"><span class="built_in">export</span> STORAGE_LOCATION=/home/cys/docker_data/anythingllm  <span class="comment"># 确保与原路径一致</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$STORAGE_LOCATION</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;STORAGE_LOCATION&#125;</span></span><br><span class="line"><span class="built_in">touch</span> .<span class="built_in">env</span></span><br><span class="line"></span><br><span class="line">docker run -d -p 3001:3001 \</span><br><span class="line">  --name AnythingLLM \</span><br><span class="line">  --network host \</span><br><span class="line">  --cap-add SYS_ADMIN \</span><br><span class="line">  -v <span class="variable">$&#123;STORAGE_LOCATION&#125;</span>:/app/server/storage \</span><br><span class="line">  -v <span class="variable">$&#123;STORAGE_LOCATION&#125;</span>/.env:/app/server/.env \</span><br><span class="line">  -e STORAGE_DIR=<span class="string">&quot;/app/server/storage&quot;</span> \</span><br><span class="line">  mintplexlabs/anythingllm</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="·-测试容器之间是否相通"><a href="#·-测试容器之间是否相通" class="headerlink" title="· 测试容器之间是否相通"></a>· 测试容器之间是否相通</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it AnythingLLM /bin/bash</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl <span class="string">&quot;http://宿主机IP:端口/search?q=测试&amp;format=json&quot;</span> </span><br><span class="line"><span class="comment"># 看看从一个容器中调用另一个容器到宿主机的功能是不是能用，因为searxng容器已经映射了自己的搜索功能到宿主机的8080端口，所以这里用宿主机8080端口即可测试。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="·-遇到-阿里云-Docker-CE-镜像源-和-GPG-密钥过时"><a href="#·-遇到-阿里云-Docker-CE-镜像源-和-GPG-密钥过时" class="headerlink" title="· 遇到 阿里云 Docker CE 镜像源 和 GPG 密钥过时"></a>· 遇到 <strong>阿里云 Docker CE 镜像源</strong> 和 <strong>GPG 密钥过时</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update </span><br><span class="line"></span><br><span class="line"><span class="comment"># 遇到报错</span></span><br><span class="line">W: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: https://mirrors.aliyun.com/docker-ce/linux/ubuntu noble InRelease: The following signatures couldn<span class="string">&#x27;t be verified because the public key is not available: NO_PUBKEY 7EA0A9C3F273FCD8</span></span><br><span class="line"><span class="string">W: https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu/dists/noble/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.</span></span><br><span class="line"><span class="string">W: Failed to fetch https://mirrors.aliyun.com/docker-ce/linux/ubuntu/dists/noble/InRelease  The following signatures couldn&#x27;</span>t be verified because the public key is not available: NO_PUBKEY 7EA0A9C3F273FCD8</span><br><span class="line">W: Some index files failed to download. They have been ignored, or old ones used instead.</span><br></pre></td></tr></table></figure>

<p>处理</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">grep -ri <span class="string">&quot;mirrors.aliyun.com&quot;</span> /etc/apt/sources.list.d/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 sed 注释相关行（以备份文件形式操作）</span></span><br><span class="line">sudo sed -i.bak <span class="string">&#x27;/mirrors.aliyun.com/docker-ce/d&#x27;</span> /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导出旧密钥到新路径</span></span><br><span class="line">sudo apt-key <span class="built_in">export</span> 7EA0A9C3F273FCD8 | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg</span><br><span class="line"></span><br><span class="line">sudo sed -i <span class="string">&#x27;s#deb [arch=amd64]#deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg]#g&#x27;</span> /etc/apt/sources.list.d/docker-ce.list</span><br><span class="line"></span><br><span class="line">sudo <span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除残留的阿里云源文件</span></span><br><span class="line">sudo <span class="built_in">rm</span> -f /etc/apt/sources.list.d/third-party.sources /etc/apt/sources.list.d/docker.list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 确保 /etc/apt/sources.list 中无阿里云 Docker CE 相关行：</span></span><br><span class="line">sudo sed -i <span class="string">&#x27;/mirrors.aliyun.com/docker-ce/d&#x27;</span> /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迁移旧密钥到新路径</span></span><br><span class="line"><span class="comment"># 导出旧密钥并转换为新格式</span></span><br><span class="line">sudo apt-key <span class="built_in">export</span> 7EA0A9C3F273FCD8 | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg</span><br><span class="line"><span class="comment"># 删除旧密钥</span></span><br><span class="line">sudo apt-key del 7EA0A9C3F273FCD8</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新清华源配置​ 修改 /etc/apt/sources.list.d/docker-ce.list，确保 signed-by 参数指向新密钥路径：</span></span><br><span class="line">sudo sed -i <span class="string">&#x27;s#signed-by=/etc/apt/keyrings/docker.gpg#signed-by=/usr/share/keyrings/docker-archive-keyring.gpg#g&#x27;</span> /etc/apt/sources.list.d/docker-ce.list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 强制刷新仓库缓存</span></span><br><span class="line">sudo <span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 导出旧密钥到新路径</span></span><br><span class="line">sudo apt-key <span class="built_in">export</span> 7EA0A9C3F273FCD8 | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 删除旧密钥</span></span><br><span class="line">sudo apt-key del 7EA0A9C3F273FCD8</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 更新 Docker 源配置</span></span><br><span class="line">sudo sed -i <span class="string">&#x27;s#deb \[arch=amd64#deb \[arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg#g&#x27;</span> /etc/apt/sources.list.d/docker-ce.list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证修复效果</span></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt update</span><br><span class="line"><span class="comment"># 确认 Docker CE 源状态</span></span><br><span class="line">apt-cache policy docker-ce</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示候选版本为 5:28.0.1-1~ubuntu.24.04~noble，且源地址指向清华镜像，说明配置已生效</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="·-open-webui-白屏问题解决"><a href="#·-open-webui-白屏问题解决" class="headerlink" title="· open webui 白屏问题解决"></a>· open webui 白屏问题解决</h4><p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/xianciSele/article/details/145340554">https://blog.csdn.net/xianciSele/article/details/145340554</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.kazoottt.top/posts/openwebui-long-loading-white-screen-solution/">https://blog.kazoottt.top/posts/openwebui-long-loading-white-screen-solution/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/open-webui/open-webui/discussions/7769">https://github.com/open-webui/open-webui/discussions/7769</a></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250310084150.png" alt="微信图片_20250310084150"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从网页访问 3000端口 网页白板，要等2分钟，其实是因为 访问 openip 获取模型失败，网不通。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 解决方法1:</span></span><br><span class="line"><span class="comment"># 在docker-compose.yml 中加外部host。</span></span><br><span class="line"> extra_hosts:</span><br><span class="line">      - <span class="string">&quot;api.openai.com:127.0.0.1&quot;</span>  </span><br><span class="line">      </span><br><span class="line"><span class="comment"># 解决方法2:</span></span><br><span class="line"><span class="comment"># docker run命令启动的时候配置环境变量 </span></span><br><span class="line"> -e ENABLE_OPENAI_API=0 \  </span><br><span class="line"> <span class="comment"># 或者docker compose 时如下</span></span><br><span class="line"> environment:</span><br><span class="line">   - ENABLE_OPENAI_API=0</span><br><span class="line">-------------------------------------------------------------</span><br><span class="line">name: openwebui</span><br><span class="line">services:</span><br><span class="line">    open-webui:</span><br><span class="line">        ports:</span><br><span class="line">            - 3000:8080</span><br><span class="line">        deploy:</span><br><span class="line">            resources:</span><br><span class="line">                reservations:</span><br><span class="line">                    devices:</span><br><span class="line">                        - driver: nvidia</span><br><span class="line">                          count: all</span><br><span class="line">                          capabilities:</span><br><span class="line">                              - gpu</span><br><span class="line">        extra_hosts:</span><br><span class="line">            - host.docker.internal:host-gateway</span><br><span class="line">        volumes:</span><br><span class="line">            - open-webui:/app/backend/data</span><br><span class="line">        container_name: open-webui</span><br><span class="line">        restart: always</span><br><span class="line">        image: ghcr.io/open-webui/open-webui:cuda</span><br><span class="line">        environment:</span><br><span class="line">            - ENABLE_OPENAI_API=0</span><br><span class="line">volumes:</span><br><span class="line">    open-webui:</span><br><span class="line">        external: <span class="literal">true</span></span><br><span class="line">        name: open-webui</span><br></pre></td></tr></table></figure>

<p>以上的例子都是在ollama下载的deepseek的处理办法，在vllm 直接下载 deepseek模型到本地的方法中一定要打开openaai 的支持，只不过在具体的url 要指定要本地就好了。可以看看前面vllm的部署例子。</p>
<h4 id="·-searxng中长句子不能搜索的问题"><a href="#·-searxng中长句子不能搜索的问题" class="headerlink" title="· searxng中长句子不能搜索的问题"></a>· searxng中长句子不能搜索的问题</h4><p>开启 多个国内能用的搜索引擎，而不是只开一个bing。可以解决。bing 搜索引擎好像不支持长句的搜索。</p>
<h4 id="·-容器间通信问题的最佳实践"><a href="#·-容器间通信问题的最佳实践" class="headerlink" title="· 容器间通信问题的最佳实践"></a>· 容器间通信问题的最佳实践</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个外部网络</span></span><br><span class="line">docker network create vllm-network</span><br></pre></td></tr></table></figure>

<p>在每个 docker-compose 文件中引用这个网络。例如，在 vllm 的 docker-compose.yml 文件中添加：</p>
<p>external: true 表示使用已存在的外部网络，而不是由当前的 Compose 文件创建新的网络。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">my-network:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span> </span><br><span class="line">    <span class="attr">name:</span> <span class="string">my-shared-network</span></span><br></pre></td></tr></table></figure>

<p>然后在对应的服务配置中加入：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">open-webui:</span></span><br><span class="line">    <span class="comment"># ...现有配置...</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">my-network</span></span><br></pre></td></tr></table></figure>

<p><strong>修改 open-webui 的 API 地址</strong>：<br>将 <code>OPENAI_API_BASE_URL</code> 设置为 <code>http://vllm-openai:8000/v1</code>。这样 open-webui 容器会通过 DNS 查找同一网络中的 vllm-openai 服务。</p>
<blockquote>
<p>这种方法比较稳定，服务间互访不依赖宿主机 IP。<br>在 Docker Compose 中，服务名称（在 yml 文件中 services 下的键名）就是容器在同一网络中的 DNS 名称。也就是说，即使你设置了 container_name 为 deepseek-container，Docker 内部仍然会将这个容器注册为服务名 <strong>vllm-openai</strong>，所以其他同网络的容器可以通过 “vllm-openai” 来访问它。</p>
</blockquote>
<p>将多个容器加入同一个自定义网络后：</p>
<ol>
<li><strong>容器与宿主机之间的端口映射：</strong> 自定义网络不会影响容器与宿主机之间的端口映射。端口映射是在容器启动时通过 <code>-p</code> 参数或在 Compose 文件中通过 <code>ports</code> 指定的，用于将宿主机的特定端口转发到容器的端口。这些映射在自定义网络中仍然有效。</li>
<li><strong>容器连接互联网：</strong> 默认情况下，Docker 使用 <code>bridge</code> 网络驱动程序创建的自定义网络允许容器访问外部互联网。因此，容器加入自定义网络后，通常仍能连接互联网。但如果使用其他网络驱动程序（如 <code>macvlan</code>），可能需要额外配置以确保互联网连接。</li>
</ol>
<h4 id="·-无法科学上网使用docker技巧"><a href="#·-无法科学上网使用docker技巧" class="headerlink" title="· 无法科学上网使用docker技巧"></a>· 无法科学上网使用docker技巧</h4><p>在能科学上网的机器 下载下来镜像，打包成 .tar 文件，复制到不能科学上网的机器中；</p>
<p>按照下面例子操作</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在能科学上网的机器 下载下来镜像，打包成 .tar 文件</span></span><br><span class="line">docker save -o vllm.tar vllm/vllm-openai:dddddddddddd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在不能科学上网的机器执行</span></span><br><span class="line">docker load -i vllm.tar</span><br></pre></td></tr></table></figure>

<h4 id="·-vllm集群遇到-GLOO、NCCL-报错"><a href="#·-vllm集群遇到-GLOO、NCCL-报错" class="headerlink" title="· vllm集群遇到 GLOO、NCCL 报错"></a>· vllm集群遇到 GLOO、NCCL 报错</h4><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330215009.png" alt="微信图片_20250330215009"></p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330215013.png" alt="微信图片_20250330215013"></p>
<p>先看看ip 用的哪个网口；</p>
<p>然后在 run_cluster.sh 脚本中加入 <code>-e GLOO_SOCKET_IFNAME=对应网口  -e NCCL_SOCKET_IFNAME=对应网口</code> 环境变量。</p>
<h4 id="·-vllm集群遇到-The-model’s-max-seq-报错"><a href="#·-vllm集群遇到-The-model’s-max-seq-报错" class="headerlink" title="· vllm集群遇到 The model’s max seq 报错"></a>· vllm集群遇到 The model’s max seq 报错</h4><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330215145.png" alt="微信图片_20250330215145"></p>
<p>给我们提示了 <code> Try increasing gpu_memory_utilization or decreasing max_model_len when initializing the engine. [repeated 2x across cluster]</code></p>
<p>可以从运行 vllm serve 后的 提示中看到全部的 args 参数表中</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330220106.png" alt="微信图片_20250330220106"></p>
<p>找 gpu_memory_utilization、max_model_len。</p>
<p>如上图显示，硬件只能支持到  <code> KV cache (69040)</code> 于是我们把 参数加上</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vllm serve /model/deepseek-r1-70b-AWQ \</span><br><span class="line">    --tensor-parallel-size 2 \</span><br><span class="line">    --pipeline-parallel-size 2 \</span><br><span class="line">    --max_model_len 69040</span><br></pre></td></tr></table></figure>

<h4 id="·-vllm集群遇到-CUDA-out-of-memory-报错"><a href="#·-vllm集群遇到-CUDA-out-of-memory-报错" class="headerlink" title="· vllm集群遇到 CUDA out of memory 报错"></a>· vllm集群遇到 CUDA out of memory 报错</h4><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250330221123.png" alt="微信图片_20250330221123"></p>
<p>杀死占用显存多的进程，然后</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vllm serve /model/deepseek-r1-70b-AWQ \</span><br><span class="line">    --tensor-parallel-size 2 \</span><br><span class="line">    --pipeline-parallel-size 2 \</span><br><span class="line">    --max_model_len 69040 \</span><br><span class="line">    --gpu-memory-utilization 0.8</span><br></pre></td></tr></table></figure>

<h4 id="·-open-webUI知识库上传文件遇到-上传-报错"><a href="#·-open-webUI知识库上传文件遇到-上传-报错" class="headerlink" title="· open webUI知识库上传文件遇到 上传 报错"></a>· open webUI知识库上传文件遇到 上传 报错</h4><p><code>Extracted content is not available for this file. Please ensure that the file is processed before proceeding.</code></p>
<p>进入 嵌入式模型容器中，查看日志，有可能是 truncate 没有切，导致的 超过了 最大承受token。</p>
<p>在 嵌入模型容器的 yml 文件中 配置 自动切分功能参数，参考 HuggingFace Text Embeddings Inference 官网GitHub 即可。</p>
<h4 id="·-RAG-时遇到了-Please-reduce-the-length-of-the-messages-报错"><a href="#·-RAG-时遇到了-Please-reduce-the-length-of-the-messages-报错" class="headerlink" title="· RAG 时遇到了 Please reduce the length of the messages 报错"></a>· RAG 时遇到了 Please reduce the length of the messages 报错</h4><p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250402181036.png" alt="微信图片_20250402181036"></p>
<p>我们即使在vLLM中设置了<code>max-model-len 53520</code>，也可能在rag时报这样的错误；</p>
<p>因为：</p>
<p><strong>RAG的上下文叠加特性</strong><br>RAG系统会将检索到的知识库内容直接拼接到用户输入中（称为“增强”）。若知识库文档分块过大或检索结果过多，即使原始用户提问很短，最终输入也会呈现“用户问题+多篇长文档”的结构。例如：</p>
<ul>
<li>用户输入：50 tokens</li>
<li>检索到3篇文档，每篇2000 tokens</li>
<li>总输入量：50 + 3×2000 &#x3D; 6050 tokens</li>
</ul>
<p>解决办法：</p>
<p><strong>滑动窗口分块</strong>：将长文档按500-800 tokens为单位分割，重叠率建议15%，如每块保留前一块的75 tokens。</p>
<p><strong>限制召回内容规模</strong>：设置Top-K阈值，仅保留相关性最高的3-5个知识块。</p>
<p>在open webUI 中设置。</p>
<p><img src="/2025/04/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2Deepseek%E5%AE%9E%E7%8E%B0RAG%E5%B9%B6%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20250402181950.png" alt="微信图片_20250402181950"></p>
<p>然后重新传一下 知识库中的文档。</p>
<h4 id="·-更新容器的服务"><a href="#·-更新容器的服务" class="headerlink" title="· 更新容器的服务"></a>· 更新容器的服务</h4><p>以open webUI的yaml文件为例子</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">open-webui:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">ghcr.io/open-webui/open-webui:cuda</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="comment"># 禁用 ollama 连接（注释或删除该行）</span></span><br><span class="line">      <span class="comment"># - OLLAMA_API_BASE_URL=http://10.5.9.252:11434</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 启用 OpenAI 兼容 API（必须开启）</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ENABLE_OPENAI_API=true</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 指向本地 vLLM 的 OpenAI 兼容接口,即使你设置 container_name 为 deepseek-container，Docker内部仍然会将这个容器注册为服务名 vllm-openai，所以其他同网络的容器可以通过 “vllm-openai” 访问它</span></span><br><span class="line">      <span class="comment"># 这里看前面vllm中怎么写，如果写了http://10.5.9.252:8000/v1 这里也要写这个。</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">OPENAI_API_BASE_URL=http://vllm-openai:8000/v1</span>     </span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 设置与 vLLM 一致的 API 密钥</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">OPENAI_API_KEYS=jisudf*&amp;QW123</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 其他原有配置保持不变</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">GLOBAL_LOG_LEVEL=DEBUG</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">HF_ENDPOINT=https://hf-mirror.com</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">CORS_ALLOW_ORIGIN=*</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">RAG_EMBEDDING_MODEL=bge-m3</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">DEFAULT_MODELS=deepseek-r1-70b-AWQ</span>  <span class="comment"># 需与 vLLM 的 --served-model-name 参数一致</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">ENABLE_OAUTH_SIGNUP=true</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8080</span><span class="string">:8080</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/home/cys/data/docker-data/open_webui_data:/app/backend/data</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">my-network</span></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">my-network:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">vllm-network</span></span><br></pre></td></tr></table></figure>

<p>open webUI在昨天进行了版本更新，我们也更新一下。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份一份数据文件</span></span><br><span class="line">tar -czvf openwebui-bak-$(<span class="built_in">date</span> +%Y%m%d).tar.gz \</span><br><span class="line">  /home/cys/data/docker-data/open_webui_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入yml 文件所在文件夹</span></span><br><span class="line"><span class="built_in">cd</span> ~/docker_data/openwebui2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止容器</span></span><br><span class="line">docker compose down</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拉取最新的 Open WebUI 镜像</span></span><br><span class="line">docker pull ghcr.io/open-webui/open-webui:cuda</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新启动容器</span></span><br><span class="line">docker compose up -d</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/" rel="tag"># 嵌入模型</a>
              <a href="/tags/Text-Embeddings-Inference/" rel="tag"># Text Embeddings Inference</a>
              <a href="/tags/docker/" rel="tag"># docker</a>
              <a href="/tags/docker-compose/" rel="tag"># docker compose</a>
              <a href="/tags/NVIDIA-Container-Toolkit/" rel="tag"># NVIDIA Container Toolkit</a>
              <a href="/tags/nvidia-cuda-toolkit/" rel="tag"># nvidia-cuda-toolkit</a>
              <a href="/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/" rel="tag"># 搜索引擎</a>
              <a href="/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/" rel="tag"># 反向代理</a>
              <a href="/tags/SearXNG/" rel="tag"># SearXNG</a>
              <a href="/tags/ollama/" rel="tag"># ollama</a>
              <a href="/tags/anythingllm/" rel="tag"># anythingllm</a>
              <a href="/tags/Nignx-proxy-manager/" rel="tag"># Nignx proxy manager</a>
              <a href="/tags/openwebUI/" rel="tag"># openwebUI</a>
              <a href="/tags/modelscope/" rel="tag"># modelscope</a>
              <a href="/tags/vllm/" rel="tag"># vllm</a>
              <a href="/tags/%E5%AE%B9%E5%99%A8/" rel="tag"># 容器</a>
              <a href="/tags/deepseek/" rel="tag"># deepseek</a>
              <a href="/tags/%E9%9B%86%E7%BE%A4/" rel="tag"># 集群</a>
              <a href="/tags/swarm/" rel="tag"># swarm</a>
              <a href="/tags/Ray/" rel="tag"># Ray</a>
              <a href="/tags/bge-large-zh-v1-5/" rel="tag"># bge-large-zh-v1.5</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/02/15/%E8%A3%85%E6%9C%BA/%E6%96%AD%E7%94%B5%E6%8E%89ISCS%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/" rel="prev" title="断电掉ISCS共享存储解决办法">
                  <i class="fa fa-chevron-left"></i> 断电掉ISCS共享存储解决办法
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/huggingface%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/" rel="next" title="huggingface嵌入模型">
                  huggingface嵌入模型 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">陈宇韶chenyushao</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
